[[["5a323793-6a88-468c-92bb-4788bbca583a",{"pageContent":"Chain-of-Thought Prompting Elicits Reasoning \nin Large Language Models \nJason Wei Xuezhi Wang Dale Schuurmans Maarten Bosma \nBrian Ichter Fei Xia Ed H. Chi Quoc V. Le Denny Zhou \nGoogle Research, Brain Team \n{jasonwei,dennyzhou}@google.com \nAbstract \nWe explore how generating a chain of thought —a series of intermediate reasoning \nsteps—significantly improves the ability of large language models to perform \ncomplex reasoning. In particular, we show how such reasoning abilities emerge \nnaturally in sufficiently large language models via a simple method called chain-of- \nthought prompting , where a few chain of thought demonstrations are provided as \nexemplars in prompting. \nExperiments on three large language models show that chain-of-thought prompting \nimproves performance on a range of arithmetic,  commonsense,  and symbolic \nreasoning tasks.  The empirical gains can be striking.  For instance, prompting a","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":1,"lines":{"from":1,"to":16}}}}],["067b4fca-9edd-42dc-8340-ff106110c4e2",{"pageContent":"reasoning tasks.  The empirical gains can be striking.  For instance, prompting a \nPaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art \naccuracy on the GSM8K benchmark of math word problems, surpassing even \nfinetuned GPT-3 with a verifier. \nA:  The cafeteria had 23 apples originally. They used  \n20 to make lunch. So they had 23 - 20 = 3. They  \nbought 6 more apples, so they have 3 + 6 = 9.  The  \nanswer is 9. \nChain-of-Thought Prompting \nQ: Roger has 5 tennis balls. He buys 2 more cans of  \ntennis balls. Each can has 3 tennis balls. How many  \ntennis balls does he have now?   \nA: The answer is 11.   \nQ: The cafeteria had 23 apples. If they used 20 to  \nmake lunch and bought 6 more, how many apples  \ndo they have? \nA: The answer is 27. \nStandard Prompting \nQ: Roger has 5 tennis balls. He buys 2 more cans of  \ntennis balls. Each can has 3 tennis balls. How many  \ntennis balls does he have now?   \nA:  Roger started with 5 balls. 2 cans of 3 tennis balls","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":1,"lines":{"from":16,"to":37}}}}],["662b7a80-6989-4aac-9b05-462a915ced23",{"pageContent":"tennis balls does he have now?   \nA:  Roger started with 5 balls. 2 cans of 3 tennis balls  \neach is 6 tennis balls. 5 + 6 = 11.  The answer is 11.   \nQ: The cafeteria had 23 apples. If they used 20 to  \nmake lunch and bought 6 more, how many apples  \ndo they have? \nModel Input \nModel Output \nModel Output \nModel Input \nFigure 1:  Chain-of-thought prompting enables large language models to tackle complex arithmetic, \ncommonsense, and symbolic reasoning tasks. Chain-of-thought reasoning processes are highlighted. \n36th Conference on Neural Information Processing Systems (NeurIPS 2022). \narXiv:2201.11903v6  [cs.CL]  10 Jan 2023","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":1,"lines":{"from":36,"to":49}}}}],["2b1a36ad-83d9-4628-bcc4-d794a5f0e63d",{"pageContent":"1    Introduction \nMath Word Problems (GSM8K) \n0 \n20 \n40 \n60 \n80 \n100 \n33 \n55 \n18 \n57 \nSolve rate (%) \nFinetuned GPT-3 175B \nPrior best \nPaLM 540B: standard prompting \nPaLM 540B: chain-of-thought prompting \nFigure 2:    PaLM 540B uses chain-of- \nthought prompting to achieve new state- \nof-the-art performance on the GSM8K \nbenchmark  of  math  word  problems. \nFinetuned GPT-3 and prior best are from \nCobbe et al. (2021). \nThe NLP landscape has recently been revolutionized by \nlanguage models (Peters et al., 2018; Devlin et al., 2019; \nBrown et al., 2020, inter alia ). Scaling up the size of lan- \nguage models has been shown to confer a range of benefits, \nsuch as improved performance and sample efficiency (Ka- \nplan et al., 2020; Brown et al., 2020, inter alia ). However, \nscaling up model size alone has not proved sufficient for \nachieving high performance on challenging tasks such as \narithmetic, commonsense, and symbolic reasoning (Rae \net al., 2021).","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":2,"lines":{"from":1,"to":33}}}}],["76b11398-cf15-4c8c-9109-51c35d9aefd4",{"pageContent":"arithmetic, commonsense, and symbolic reasoning (Rae \net al., 2021). \nThis  work  explores  how  the  reasoning  ability  of  large \nlanguage models can be unlocked by a simple method \nmotivated by two ideas.  First, techniques for arithmetic \nreasoning can benefit from generating natural language \nrationales that lead to the final answer.  Prior work has \ngiven models the ability to generate natural language inter- \nmediate steps by training from scratch (Ling et al., 2017) \nor finetuning a pretrained model (Cobbe et al., 2021), in \naddition to neuro-symbolic methods that use formal lan- \nguages instead of natural language (Roy and Roth, 2015; \nChiang and Chen, 2019; Amini et al., 2019; Chen et al., \n2019). Second, large language models offer the exciting \nprospect of in-context few-shot learning via prompting .  That is, instead of finetuning a separate \nlanguage model checkpoint for each new task,  one can simply “prompt” the model with a few","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":2,"lines":{"from":32,"to":47}}}}],["d4fa0698-cb85-4895-8274-01a0be87c027",{"pageContent":"language model checkpoint for each new task,  one can simply “prompt” the model with a few \ninput–output exemplars demonstrating the task. Remarkably, this has been successful for a range of \nsimple question-answering tasks (Brown et al., 2020). \nBoth of the above ideas,  however,  have key limitations.   For rationale-augmented training and \nfinetuning methods, it is costly to create a large set of high quality rationales, which is much more \ncomplicated than simple input–output pairs used in normal machine learning. For the traditional few- \nshot prompting method used in Brown et al. (2020), it works poorly on tasks that require reasoning \nabilities, and often does not improve substantially with increasing language model scale (Rae et al., \n2021). In this paper, we combine the strengths of these two ideas in a way that avoids their limitations. \nSpecifically, we explore the ability of language models to perform few-shot prompting for reasoning","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":2,"lines":{"from":47,"to":56}}}}],["7490db50-6757-4e85-946c-4c58402ca62c",{"pageContent":"tasks, given a prompt that consists of triples: 〈 input, chain of thought , output 〉 . A chain of thought is \na series of intermediate natural language reasoning steps that lead to the final output, and we refer to \nthis approach as chain-of-thought prompting . An example prompt is shown in Figure 1. \nWe present empirical evaluations on arithmetic, commonsense, and symbolic reasoning benchmarks, \nshowing that chain-of-thought prompting outperforms standard prompting, sometimes to a striking \ndegree.  Figure 2 illustrates one such result—on the GSM8K benchmark of math word problems \n(Cobbe et al., 2021), chain-of-thought prompting with PaLM 540B outperforms standard prompting \nby a large margin and achieves new state-of-the-art performance.  A prompting only approach is \nimportant because it does not require a large training dataset and because a single model checkpoint \ncan perform many tasks without loss of generality. This work underscores how large language models","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":2,"lines":{"from":57,"to":66}}}}],["93069a15-be84-4d54-9dd3-a3f8fb8fa9b2",{"pageContent":"can perform many tasks without loss of generality. This work underscores how large language models \ncan learn via a few examples with natural language data about the task (c.f. automatically learning \nthe patterns underlying inputs and outputs via a large training dataset). \n2    Chain-of-Thought Prompting \nConsider one’s own thought process when solving a complicated reasoning task such as a multi-step \nmath word problem. It is typical to decompose the problem into intermediate steps and solve each \nbefore giving the final answer: “After Jane gives 2 flowers to her mom she has 10 ... then after she \ngives 3 to her dad she will have 7 ... so the answer is 7.” The goal of this paper is to endow language \nmodels with the ability to generate a similar chain of thought —a coherent series of intermediate \nreasoning steps that lead to the final answer for a problem.  We will show that sufficiently large \n2","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":2,"lines":{"from":66,"to":76}}}}],["36856f99-dab0-4be8-b77a-60a7274a59f3",{"pageContent":"language models can generate chains of thought if demonstrations of chain-of-thought reasoning are \nprovided in the exemplars for few-shot prompting. \nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem \nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution \nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it \nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations \ntypically come after the final answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al., \n2022, inter alia )). \nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning \nin language models. \n1. \nFirst, chain of thought, in principle, allows models to decompose multi-step problems into \nintermediate steps, which means that additional computation can be allocated to problems","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":3,"lines":{"from":1,"to":13}}}}],["344a3b5d-831e-444a-9db0-799e52549898",{"pageContent":"intermediate steps, which means that additional computation can be allocated to problems \nthat require more reasoning steps. \n2. Second, a chain of thought provides an interpretable window into the behavior of the model, \nsuggesting how it might have arrived at a particular answer and providing opportunities \nto debug where the reasoning path went wrong (although fully characterizing a model’s \ncomputations that support an answer remains an open question). \n3. \nThird,  chain-of-thought reasoning can be used for tasks such as math word problems, \ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least \nin principle) to any task that humans can solve via language. \n4. Finally, chain-of-thought reasoning can be readily elicited in sufficiently large off-the-shelf \nlanguage models simply by including examples of chain of thought sequences into the \nexemplars of few-shot prompting.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":3,"lines":{"from":13,"to":25}}}}],["a4e61888-5fc2-4fe4-a31d-8d42e1416a09",{"pageContent":"exemplars of few-shot prompting. \nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic \nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5). \n3    Arithmetic Reasoning \nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic \nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where \nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain- \nof-thought prompting when used with the 540B parameter language model performs comparably with \ntask-specific finetuned models on several tasks, even achieving new state of the art on the challenging \nGSM8K benchmark (Cobbe et al., 2021). \n3.1    Experimental Setup \nWe explore chain-of-thought prompting for various language models on multiple benchmarks. \nBenchmarks.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":3,"lines":{"from":25,"to":37}}}}],["46a0a88e-8bda-4398-8fbe-4a70ebabc932",{"pageContent":"Benchmarks. \nWe consider the following five math word problem benchmarks: (1) the GSM8K \nbenchmark of math word problems (Cobbe et al., 2021), (2) the SVAMP dataset of math word \nproblems with varying structures (Patel et al., 2021), (3) the ASDiv dataset of diverse math word \nproblems (Miao et al., 2020), (4) the AQuA dataset of algebraic word problems, and (5) the MAWPS \nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12. \nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by \nBrown et al. (2020), in which a language model is given in-context exemplars of input–output pairs \nbefore outputting a prediction for a test-time example.  Exemplars are formatted as questions and \nanswers. The model gives the answer directly, as shown in Figure 1 (left). \nChain-of-thought prompting. \nOur proposed approach is to augment each exemplar in few-shot","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":3,"lines":{"from":37,"to":48}}}}],["803eb8ab-f8fa-493d-b444-ab548ad28e6b",{"pageContent":"Chain-of-thought prompting. \nOur proposed approach is to augment each exemplar in few-shot \nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most \nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars \nwith chains of thought for prompting—Figure 1 (right) shows one chain of thought exemplar, and the \nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo \nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether \nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of \n3","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":3,"lines":{"from":47,"to":55}}}}],["93bc4d7d-882e-4d8b-a8e7-aba10d1d01e4",{"pageContent":"Q: Roger has 5 tennis balls. He buys  \n2 more cans of tennis balls. Each can  \nhas 3 tennis balls. How many tennis  \nballs does he have now?   \nA:  Roger started with 5 balls. 2 cans  \nof 3 tennis balls each is 6 tennis  \nballs. 5 + 6 = 11.  The answer is 11. \nQ: Sammy wanted to go to where the  \npeople were. Where might he go?   \nOptions: (a) race track (b) populated areas  \n(c) desert (d) apartment (e) roadblock   \nA:  The answer must be a place with a  \nlot of people. Race tracks, desert,  \napartments, and roadblocks don't  \nhave a lot of people, but populated  \nareas do.  So the answer is (b).  \nQ: Yes or no: Would a pear sink in  \nwater?   \nA:  The density of a pear is about 0.6  \ng/cm^3, which is less than water.  \nThus, a pear would float.  So the  \nanswer is no. \nQ: The concert was scheduled to be  \non 06/01/1943, but was delayed by  \none day to today. What is the date 10  \ndays ago in MM/DD/YYYY?    \nA:  One day after 06/01/1943 is  \n06/02/1943, so today is 06/02/1943.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":4,"lines":{"from":1,"to":28}}}}],["8adc40d8-d6c3-4b0f-95bf-3ad3923aad27",{"pageContent":"days ago in MM/DD/YYYY?    \nA:  One day after 06/01/1943 is  \n06/02/1943, so today is 06/02/1943.  \n10 days before today is 05/23/1943.   \nSo the answer is 05/23/1943.  \nQ: Is the following sentence  \nplausible? \"Joao Moutinho caught the  \nscreen pass in the NFC  \nchampionship.\"    \nA:  Joao Moutinho is a soccer player.  \nThe NFC championship is part of  \nAmerican football, not soccer.  So the  \nanswer is no. \nQ: Take the last letters of the words  \nin “Lady Gaga” and concatenate  \nthem.   \nA:  The last letter of “Lady” is “y”. The  \nlast letter of “Gaga” is “a”.  \nConcatenating them is “ya”.  So the  \nanswer is ya. \nQ: A coin is heads up. Maybelle flips  \nthe coin. Shalonda does not flip the  \ncoin. Is the coin still heads up?   \nA:  The coin was flipped by Maybelle.  \nSo the coin was flipped 1 time, which  \nis an odd number. The coin started  \nheads up, so after an odd number of  \nflips, it will be tails up.  So the answer  \nis no. \nMath Word Problems (free response)","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":4,"lines":{"from":26,"to":55}}}}],["064cd279-7d12-4ef2-b083-52894ef13d3c",{"pageContent":"flips, it will be tails up.  So the answer  \nis no. \nMath Word Problems (free response) \nMath Word Problems (multiple choice) \nCSQA (commonsense) \nStrategyQA Date Understanding Sports Understanding \nLast Letter Concatenation Coin Flip (state tracking) \nQ: How many keystrokes are needed  \nto type the numbers from 1 to 500? \nAnswer Choices: (a) 1156 (b) 1392 (c) 1480  \n(d) 1562 (e) 1788   \nA:  There are 9 one-digit numbers  \nfrom 1 to 9. There are 90 two-digit  \nnumbers from 10 to 99. There are  \n401 three-digit numbers from 100 to  \n500. 9 + 90(2) + 401(3) = 1392.  The  \nanswer is (b). \nSayCan (Instructing a robot) \nHuman: How would you bring me  \nsomething that isn’t a fruit?   \nExplanation: the user wants  \nsomething to eat that isn’t a fruit. An  \nenergy bar is not a fruit, so I will bring  \nthe user an energy bar.     \nPlan: 1. find(energy bar) 2.  \npick(energy bar) 3. find(user) 4.  \nput(energy bar) 5. done().","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":4,"lines":{"from":53,"to":79}}}}],["113ec91b-d939-4cf6-bb57-f399eee6757e",{"pageContent":"Plan: 1. find(energy bar) 2.  \npick(energy bar) 3. find(user) 4.  \nput(energy bar) 5. done(). \nFigure 3:  Examples of 〈 input, chain of thought, output 〉 triples for arithmetic, commonsense, and \nsymbolic reasoning benchmarks. Chains of thought are highlighted. Full prompts in Appendix G. \nmath word problems, we used this single set of eight chain of thought exemplars for all benchmarks \nexcept AQuA, which is multiple choice instead of free response. For AQuA, we used four exemplars \nand solutions from the training set, as given in Appendix Table 21. \nLanguage models. We evaluate five large language models.   The first is GPT-3 (Brown et al., \n2020), for which we use text-ada-001, text-babbage-001, text-curie-001, and text-davinci-002, which \npresumably correspond to InstructGPT models of 350M, 1.3B, 6.7B, and 175B parameters (Ouyang \net al., 2022).The second is LaMDA (Thoppilan et al., 2022), which has models of 422M, 2B, 8B,","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":4,"lines":{"from":77,"to":88}}}}],["c2e0b5d5-3ae4-4da1-966e-726df4239762",{"pageContent":"et al., 2022).The second is LaMDA (Thoppilan et al., 2022), which has models of 422M, 2B, 8B, \n68B, and 137B parameters. The third is PaLM , which has models of 8B, 62B, and 540B parameters. \nThe fourth is UL2 20B (Tay et al., 2022), and the fifth is Codex (Chen et al., 2021, code-davinci-002 \nin the OpenAI API). We sample from the models via greedy decoding (though follow-up work shows \nchain-of-thought prompting can be improved by taking the majority final answer over many sampled \ngenerations (Wang et al., 2022a)). For LaMDA, we report averaged results over five random seeds, \nwhere each seed had a different randomly shuffled order of exemplars.  As LaMDA experiments \ndid not show large variance among different seeds, to save compute we report results for a single \nexemplar order for all other models. \n3.2    Results \nThe strongest results of chain-of-thought prompting are summarized in Figure 4, with all experimental","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":4,"lines":{"from":88,"to":98}}}}],["29811b1f-c7c9-4fe9-be33-03a87e516d31",{"pageContent":"outputs for each model collection, model size, and benchmark shown in Table 2 in the Appendix. \nThere are three key takeaways. First, Figure 4 shows that chain-of-thought prompting is an emergent \nability of model scale (Wei et al., 2022b). That is, chain-of-thought prompting does not positively \nimpact performance for small models, and only yields performance gains when used with models of \n∼ 100B parameters. We qualitatively found that models of smaller scale produced fluent but illogical \nchains of thought, leading to lower performance than standard prompting. \n4","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":4,"lines":{"from":99,"to":105}}}}],["8785db32-edae-4eba-8c45-0796d4997eaf",{"pageContent":"0 \n20 \n40 \n60 \nGSM8K \nsolve rate (%) \nLaMDA GPT PaLM \nStandard prompting \nChain-of-thought prompting \nPrior supervised best \n0 \n20 \n40 \n60 \n80 \nSVAMP \nsolve rate (%) \n0.4 8 137 \n0 \n25 \n50 \n75 \n100 \nMAWPS \nsolve rate (%) \n0.4 \n7 \n175 8 62 540 \nModel scale (# parameters in billions) \nFigure 4:    Chain-of-thought prompting enables \nlarge language models to solve challenging math \nproblems.   Notably,  chain-of-thought  reasoning \nis an emergent ability of increasing model scale. \nPrior best numbers are from Cobbe et al. (2021) \nfor GSM8K, Jie et al. (2022) for SVAMP, and Lan \net al. (2021) for MAWPS. \nSecond, chain-of-thought prompting has larger \nperformance gains for more-complicated prob- \nlems.   For instance,  for GSM8K (the dataset \nwith the lowest baseline performance), perfor- \nmance more than doubled for the largest GPT \nand PaLM models. On the other hand, for Sin- \ngleOp, the easiest subset of MAWPS which only \nrequires a single step to solve, performance im-","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":5,"lines":{"from":1,"to":44}}}}],["a1965dcc-789a-4f86-8a7e-2a569ca964dc",{"pageContent":"gleOp, the easiest subset of MAWPS which only \nrequires a single step to solve, performance im- \nprovements were either negative or very small \n(see Appendix Table 3). \nThird, chain-of-thought prompting via GPT-3 \n175B and PaLM 540B compares favorably to \nprior state of the art, which typically finetunes a \ntask-specific model on a labeled training dataset. \nFigure 4 shows how PaLM 540B uses chain-of- \nthought prompting to achieve new state of the art \non GSM8K, SVAMP, and MAWPS (though note \nthat standard prompting already passed the prior \nbest for SVAMP). On the other two datasets, \nAQuA and ASDiv, PaLM with chain-of-thought \nprompting reaches within 2% of the state of the \nart (Appendix Table 2). \nTo  better  understand  why  chain-of-thought \nprompting works, we manually examined model- \ngenerated chains of thought by LaMDA 137B \nfor GSM8K. Of 50 random examples where the \nmodel returned the correct final answer, all of \nthe generated chains of thought were also log-","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":5,"lines":{"from":43,"to":64}}}}],["11a179c2-86de-4ab9-b79d-9ae5c1255a8c",{"pageContent":"model returned the correct final answer, all of \nthe generated chains of thought were also log- \nically and mathematically correct except two \nthat coincidentally arrived at the correct answer \n(see Appendix D.1, and Table 8 for examples \nof correct model-generated chains of thought). \nWe also randomly examined 50 random sam- \nples for which the model gave the wrong answer. \nThe summary of this analysis is that 46% of the \nchains of thought were almost correct, barring \nminor mistakes (calculator error, symbol map- \nping error, or one reasoning step missing), and that the other 54% of the chains of thought had major \nerrors in semantic understanding or coherence (see Appendix D.2). To provide a small insight into \nwhy scaling improves chain-of-thought reasoning ability, we performed a similar analysis of errors \nmade by PaLM 62B and whether those errors were fixed by scaling to PaLM 540B. The summary","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":5,"lines":{"from":63,"to":77}}}}],["f5f79304-2867-4af9-9b7c-316f2e802946",{"pageContent":"made by PaLM 62B and whether those errors were fixed by scaling to PaLM 540B. The summary \nis that scaling PaLM to 540B fixes a large portion of one-step missing and semantic understanding \nerrors in the 62B model (see Appendix A.1). \n3.3    Ablation Study \nThe observed benefits of using chain-of-thought prompting raises the natural question of whether the \nsame performance improvements can be conferred via other types of prompting. Figure 5 shows an \nablation study with three variations of chain of thought described below. \nEquation only. One reason for why chain-of-thought prompting might help is that it produces the \nmathematical equation to be evaluated, and so we test a variation where the model is prompted \nto output only a mathematical equation before giving the answer.  Figure 5 shows that equation \nonly prompting does not help much for GSM8K, which implies that the semantics of the questions","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":5,"lines":{"from":77,"to":87}}}}],["0fa77011-d21d-49aa-abae-20a05d13e84f",{"pageContent":"only prompting does not help much for GSM8K, which implies that the semantics of the questions \nin GSM8K are too challenging to directly translate into an equation without the natural language \nreasoning steps in chain of thought. For datasets of one-step or two-step problems, however, we find \nthat equation only prompting does improve performance, since the equation can be easily derived \nfrom the question (see Appendix Table 6). \n5","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":5,"lines":{"from":87,"to":92}}}}],["f8b5480c-966d-49c9-a021-125cfca89aae",{"pageContent":"LaMDA \nPaLM \n0 \n20 \n40 \n60 \nGSM8K solve rate (%) \nStandard prompting \nEquation only \nVariable compute only \nReasoning after answer \nChain-of-thought prompting \nFigure 5:    Ablation study for dif- \nferent variations of prompting us- \ning LaMDA 137B and PaLM 540B. \nResults for other datasets are given \nin Appendix Table 6 and Table 7. \nVariable  compute  only. Another  intuition  is  that  chain  of \nthought  allows  the  model  to  spend  more  computation  (i.e., \nintermediate tokens) on harder problems. To isolate the effect \nof variable computation from chain-of-thought reasoning, we \ntest a configuration where the model is prompted to output a \nonly sequence of dots ( ... ) equal to the number of characters in \nthe equation needed to solve the problem. This variant performs \nabout the same as the baseline, which suggests that variable \ncomputation by itself is not the reason for the success of chain- \nof-thought prompting, and that there appears to be utility from","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":6,"lines":{"from":1,"to":27}}}}],["80b5fb94-e9d6-406c-9326-937d9a0b6a26",{"pageContent":"of-thought prompting, and that there appears to be utility from \nexpressing intermediate steps via natural language. \nChain of thought after answer. Another potential benefit of \nchain-of-thought prompting could simply be that such prompts \nallow the model to better access relevant knowledge acquired \nduring pretraining. Therefore, we test an alternative configura- \ntion where the chain of thought prompt is only given after the \nanswer, isolating whether the model actually depends on the \nproduced chain of thought to give the final answer. This variant \nperforms about the same as the baseline, which suggests that \nthe sequential reasoning embodied in the chain of thought is \nuseful for reasons beyond just activating knowledge. \n3.4    Robustness of Chain of Thought \nGSM8K \n0 \n5 \n10 \n15 \n20 \nSolve rate (%) \nStandard prompting \nChain-of-thought prompting \n· different annotator (B) \n· different annotator (C) \n· intentionally concise style \n· exemplars from GSM8K ( α )","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":6,"lines":{"from":27,"to":52}}}}],["d1f81ffc-36ad-44da-9514-9ae5a44b1004",{"pageContent":"· different annotator (C) \n· intentionally concise style \n· exemplars from GSM8K ( α ) \n· exemplars from GSM8K ( β ) \n· exemplars from GSM8K ( γ ) \nMAWPS \n0 \n20 \n40 \n60 \nFigure 6:  Chain-of-thought prompting \nhas variance for different prompt exam- \nples (as expected) but outperforms stan- \ndard prompting for various annotators as \nwell as for different exemplars. \nSensitivity to exemplars is a key consideration of prompt- \ning approaches—for instance, varying the permutation of \nfew-shot exemplars can cause the accuracy of GPT-3 on \nSST-2 to range from near chance (54.3%) to near state of \nthe art (93.4%) (Zhao et al., 2021).  In this final subsec- \ntion, we evaluate robustness to chains of thought written \nby different annotators.  In addition to the results above, \nwhich used chains of thought written by an Annotator \nA, two other co-authors of this paper (Annotators B and \nC) independently wrote chains of thought for the same \nfew-shot exemplars (shown in Appendix H). Annotator A","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":6,"lines":{"from":50,"to":75}}}}],["b0ed145b-69eb-43c0-9a0d-540b45847260",{"pageContent":"few-shot exemplars (shown in Appendix H). Annotator A \nalso wrote another chain of thought that was more concise \nthan the original, following the style of solutions given in \nCobbe et al. (2021). \n1 \nFigure 6 shows these results for LaMDA 137B on GSM8K \nand MAWPS (ablation results for other datasets are given \nin Appendix Table 6 / Table 7). Although there is variance \namong different chain of thought annotations, as would be \nexpected when using exemplar-based prompting (Le Scao \nand Rush, 2021; Reynolds and McDonell, 2021; Zhao \net al., 2021), all sets of chain of thought prompts outper- \nform the standard baseline by a large margin. This result \nimplies that successful use of chain of thought does not \ndepend on a particular linguistic style. \nTo confirm that successful chain-of-thought prompting \nworks for other sets of exemplars, we also run experiments \nwith three sets of eight exemplars randomly sampled from the GSM8K training set, an independent \n1","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":6,"lines":{"from":75,"to":93}}}}],["86add572-986e-4ce5-b404-2316009f8383",{"pageContent":"with three sets of eight exemplars randomly sampled from the GSM8K training set, an independent \n1 \nFor instance, whereas original chain of thought uses several short sentences ( “’There were originally 9 \ncomputers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is \n29.” ), the concise chain of thought would read “5 * 4 = 20 new computers were added. So there are 9 + 20 = 29 \nnew computers in the server room now” . \n6","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":6,"lines":{"from":92,"to":98}}}}],["93bd4fc8-8ed9-4a11-aef0-52cfdfb0af5f",{"pageContent":"source (examples in this dataset already included reasoning steps like a chain of thought). \n2 \nFig- \nure 6 shows that these prompts performed comparably with our manually written exemplars, also \nsubstantially outperforming standard prompting. \nIn addition to robustness to annotators, independently-written chains of thought, different exemplars, \nand various language models, we also find that chain-of-thought prompting for arithmetic reasoning \nis robust to different exemplar orders and varying numbers of exemplars (see Appendix A.2). \n4    Commonsense Reasoning \nAlthough chain of thought is particularly suitable for math word problems, the language-based nature \nof chain of thought actually makes it applicable to a broad class of commonsense reasoning problems, \nwhich involve reasoning about physical and human interactions under the presumption of general \nbackground knowledge. Commonsense reasoning is key for interacting with the world and is still","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":7,"lines":{"from":1,"to":13}}}}],["4d947d4d-0abb-4f1f-b98f-a080820afec2",{"pageContent":"background knowledge. Commonsense reasoning is key for interacting with the world and is still \nbeyond the reach of current natural language understanding systems (Talmor et al., 2021). \nBenchmarks. We consider five datasets covering a diverse range of commonsense reasoning types. \nThe popular CSQA (Talmor et al., 2019) asks commonsense questions about the world involving \ncomplex semantics that often require prior knowledge. StrategyQA (Geva et al., 2021) requires \nmodels to infer a multi-hop strategy to answer questions. We choose two specialized evaluation sets \nfrom the BIG-bench effort (BIG-bench collaboration, 2021): Date Understanding, which involves \ninferring a date from a given context, and Sports Understanding, which involves determining whether \na sentence relating to sports is plausible or implausible.  Finally, the SayCan dataset (Ahn et al., \n2022) involves mapping a natural language instruction to a sequence of robot actions from a discrete","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":7,"lines":{"from":13,"to":22}}}}],["09a8f71f-0ac3-4cf5-a0f3-ba3f4afc0262",{"pageContent":"set. Figure 3 shows examples with chain of thought annotations for all datasets. \nPrompts. \nWe follow the same experimental setup as the prior section. For CSQA and StrategyQA, \nwe randomly selected examples from the training set and manually composed chains of thought for \nthem to use as few-shot exemplars. The two BIG-bench tasks do not have training sets, so we selected \nthe first ten examples as exemplars in the evaluation set as few-shot exemplars and report numbers on \nthe rest of the evaluation set. For SayCan, we use six examples from the training set used in Ahn et al. \n(2022) and also manually composed chains of thought. \nResults. Figure 7 highlights these results for PaLM (full results for LaMDA, GPT-3, and different \nmodel scales are shown in Table 4). For all tasks, scaling up model size improved the performance \nof standard prompting; chain-of-thought prompting led to further gains, with improvements appear-","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":7,"lines":{"from":23,"to":33}}}}],["2dd73982-a6ad-4f67-8ed9-b17c6e547c35",{"pageContent":"of standard prompting; chain-of-thought prompting led to further gains, with improvements appear- \ning to be largest for PaLM 540B. With chain-of-thought prompting, PaLM 540B achieved strong \nperformance relative to baselines, outperforming the prior state of the art on StrategyQA (75.6% vs \n69.4%) and outperforming an unaided sports enthusiast on sports understanding (95.4% vs 84%). \nThese results demonstrate that chain-of-thought prompting can also improve performance on tasks \nrequiring a range of commonsense reasoning abilities (though note that gain was minimal on CSQA). \n8 62 540 \n20 \n40 \n60 \n80 \n100 \nSolve rate (%) \nCSQA \n8 62 540 \n50 \n60 \n70 \n80 \n90 \nStrategyQA \nStandard prompting \nChain of thought \nPrior supervised best \nHuman \n8 62 540 \n0 \n20 \n40 \n60 \n80 \nModel scale (# parameters in billions) \nDate \n8 62 540 \n40 \n60 \n80 \n100 \nSports \n8 62 540 \n20 \n40 \n60 \n80 \n100 \nSayCan \nFigure 7: Chain-of-thought prompting also improves the commonsense reasoning abilities of","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":7,"lines":{"from":33,"to":79}}}}],["b8166990-0da5-4bdd-b036-bd6ac4d48f7e",{"pageContent":"SayCan \nFigure 7: Chain-of-thought prompting also improves the commonsense reasoning abilities of \nlanguage models.   The language model shown here is PaLM. Prior best numbers are from the \nleaderboards of CSQA (Talmor et al., 2019) and StrategyQA (Geva et al., 2021) (single-model only, \nas of May 5, 2022). Additional results using various sizes of LaMDA, GPT-3, and PaLM are shown \nin Table 4. \n2 \nWe sample examples ≤ 60 tokens to fit into our input context window, and also limit the examples to ≤ 2 \nsteps to solve for a fair comparison with the eight exemplars that we composed. \n7","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":7,"lines":{"from":78,"to":87}}}}],["fe998a5d-fffe-4695-80ca-c453bc4fe1ef",{"pageContent":"5    Symbolic Reasoning \n0 \n25 \n50 \n75 \n100 \nSolve rate (%) \nLetter Concat: 2 \n(in domain) \nLetter Concat: 4 \n(OOD) \nStandard prompting \nChain-of-thought prompting \n8 62 540 \n40 \n60 \n80 \n100 \nSolve rate (%) \nCoin Flip: 2 \n(in domain) \n8 62 540 \nModel scale (# parameters in billions) \nCoin Flip: 4 \n(OOD) \nFigure  8: Using  chain-of-thought \nprompting facilitates generalization to \nlonger sequences in two symbolic rea- \nsoning tasks. \nOur final experimental evaluation considers symbolic rea- \nsoning, which is simple for humans but potentially chal- \nlenging  for  language  models.   We  show  that  chain-of- \nthought prompting not only enables language models to \nperform symbolic reasoning tasks that are challenging in \nthe standard prompting setting, but also facilitates length \ngeneralization to inference-time inputs longer than those \nseen in the few-shot exemplars. \nTasks. We use the following two toy tasks. \n• Last letter concatenation. This task asks the model","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":8,"lines":{"from":1,"to":39}}}}],["2eab8b28-fb42-4393-8e20-949d3fdd99a2",{"pageContent":"Tasks. We use the following two toy tasks. \n• Last letter concatenation. This task asks the model \nto concatenate the last letters of words in a name (e.g., \n“Amy Brown” → “yn” ). It is a more challenging version \nof first letter concatenation, which language models can \nalready perform without chain of thought. \n3 \nWe generate \nfull names by randomly concatenating names from the \ntop one-thousand first and last names from name census \ndata ( https://namecensus.com/ ). \n• Coin flip. This task asks the model to answer whether a \ncoin is still heads up after people either flip or don’t flip \nthe coin (e.g., “A coin is heads up. Phoebe flips the coin. \nOsvaldo does not flip the coin. Is the coin still heads up?” \n→ “no” ). \nAs the construction of these symbolic reasoning tasks is \nwell-defined, for each task we consider an in-domain test \nset for which examples had the same number of steps as","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":8,"lines":{"from":38,"to":56}}}}],["5c5e8e1c-0936-4ac2-bb21-8e689f85e107",{"pageContent":"set for which examples had the same number of steps as \nthe training/few-shot exemplars, as well as an out-of-domain (OOD) test set, for which evaluation \nexamples had more steps than those in the exemplars. For last letter concatenation, the model only \nsees exemplars of names with two words, and then performs last letter concatenation on names with 3 \nand 4 words. \n4 \nWe do the same for the number of potential flips in the coin flip task. Our experimental \nsetup uses the same methods and models as in the prior two sections. We again manually compose \nchains of thought for the few-shot exemplars for each task, which are given in Figure 3. \nResults. The results of these in-domain and OOD evaluations are shown in Figure 8 for PaLM, \nwith results for LaMDA shown in Appendix Table 5. With PaLM 540B, chain-of-thought prompting \nleads to almost 100% solve rates (note that standard prompting already solves coin flip with PaLM","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":8,"lines":{"from":56,"to":67}}}}],["79d9e314-88cd-4fcf-bff0-2cec9e328cf9",{"pageContent":"leads to almost 100% solve rates (note that standard prompting already solves coin flip with PaLM \n540, though not for LaMDA 137B). Note that these in-domain evaluations are “toy tasks” in the \nsense that perfect solution structures are already provided by the chains of thought in the few-shot \nexemplars; all the model has to do is repeat the same steps with the new symbols in the test-time \nexample. And yet, small models still fail—the ability to perform abstract manipulations on unseen \nsymbols for these three tasks only arises at the scale of 100B model parameters. \nAs for the OOD evaluations, standard prompting fails for both tasks. With chain-of-thought prompting, \nlanguage models achieve upward scaling curves (though performance is lower than in the in-domain \nsetting). Hence, chain-of-thought prompting facilitates length generalization beyond seen chains of \nthought for language models of sufficient scale. \n6    Discussion","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":8,"lines":{"from":67,"to":77}}}}],["a35418a6-2539-40ca-a176-bf17dfb5023c",{"pageContent":"thought for language models of sufficient scale. \n6    Discussion \nWe have explored chain-of-thought prompting as a simple mechanism for eliciting multi-step rea- \nsoning behavior in large language models. We first saw that chain-of-thought prompting improves \nperformance by a large margin on arithmetic reasoning, yielding improvements that are much stronger \nthan ablations and robust to different annotators, exemplars, and language models (Section 3). Next, \n3 \nWe tested 10 common names using GPT-3 davinci and it got all but one correct. \n4 \nFor names of length longer than 2 words, we concatenate multiple first and last names together. \n8","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":8,"lines":{"from":76,"to":86}}}}],["ecc436c1-5a38-4376-afae-d3d75f2dbb2e",{"pageContent":"experiments on commonsense reasoning underscored how the linguistic nature of chain-of-thought \nreasoning makes it generally applicable (Section 4). Finally, we showed that for symbolic reasoning, \nchain-of-thought prompting facilitates OOD generalization to longer sequence lengths (Section 5). In \nall experiments, chain-of-thought reasoning is elicited simply by prompting an off-the-shelf language \nmodel. No language models were finetuned in the process of writing this paper. \nThe emergence of chain-of-thought reasoning as a result of model scale has been a prevailing theme \n(Wei et al., 2022b). For many reasoning tasks where standard prompting has a flat scaling curve, chain- \nof-thought prompting leads to dramatically increasing scaling curves. Chain-of-thought prompting \nappears to expand the set of tasks that large language models can perform successfully—in other \nwords, our work underscores that standard prompting only provides a lower bound on the capabilities","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":9,"lines":{"from":1,"to":10}}}}],["948f0229-29cc-486c-a7b0-7f8ed580a9d9",{"pageContent":"of large language models. This observation likely raises more questions than it answers—for instance, \nhow much more can we expect reasoning ability to improve with a further increase in model scale? \nWhat other prompting methods might expand the range of tasks that language models can solve? \nAs for limitations, we first qualify that although chain of thought emulates the thought processes of \nhuman reasoners, this does not answer whether the neural network is actually “reasoning,” which \nwe leave as an open question. Second, although the cost of manually augmenting exemplars with \nchains of thought is minimal in the few-shot setting, such annotation costs could be prohibitive for \nfinetuning (though this could potentially be surmounted with synthetic data generation, or zero-shot \ngeneralization). Third, there is no guarantee of correct reasoning paths, which can lead to both correct \nand incorrect answers; improving factual generations of language models is an open direction for","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":9,"lines":{"from":11,"to":20}}}}],["a71c55e1-64d6-43a2-b385-34379fde9b2b",{"pageContent":"and incorrect answers; improving factual generations of language models is an open direction for \nfuture work (Rashkin et al., 2021; Ye and Durrett, 2022; Wiegreffe et al., 2022, inter alia ). Finally, \nthe emergence of chain-of-thought reasoning only at large model scales makes it costly to serve in \nreal-world applications; further research could explore how to induce reasoning in smaller models. \n7    Related Work \nThis work is inspired by many research areas, which we detail in an extended related work section \n(Appendix C). Here we describe two directions and associated papers that are perhaps most relevant. \nThe first relevant direction is using intermediate steps to solve reasoning problems. Ling et al. (2017) \npioneer the idea of using natural language rationales to solve math word problems through a series \nof intermediate steps. Their work is a remarkable contrast to the literature using formal languages","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":9,"lines":{"from":20,"to":29}}}}],["b8b456a2-5e00-475d-9f25-c774df27d411",{"pageContent":"to reason (Roy et al., 2015; Chiang and Chen, 2019; Amini et al., 2019; Chen et al., 2019). Cobbe \net al. (2021) extend Ling et al. (2017) by creating a larger dataset and using it to finetune a pretrained \nlanguage model rather than training a model from scratch.  In the domain of program synthesis, \nNye et al. (2021) leverage language models to predict the final outputs of Python programs via \nfirst line-to-line predicting the intermediate computational results, and show that their step-by-step \nprediction method performs better than directly predicting the final outputs. \nNaturally, this paper also relates closely to the large body of recent work on prompting. Since the \npopularization of few-shot prompting as given by Brown et al. (2020), several general approaches \nhave improved the prompting ability of models, such as automatically learning prompts (Lester et al., \n2021) or giving models instructions describing a task (Wei et al., 2022a; Sanh et al., 2022; Ouyang","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":9,"lines":{"from":30,"to":39}}}}],["9c278183-ff73-406c-86ee-a483e8ee5172",{"pageContent":"et al., 2022).  Whereas these approaches improve or augment the input part of the prompt (e.g., \ninstructions that are prepended to inputs), our work takes the orthogonal direction of augmenting the \noutputs of language models with a chain of thought. \n8    Conclusions \nWe have explored chain-of-thought prompting as a simple and broadly applicable method for enhanc- \ning reasoning in language models. Through experiments on arithmetic, symbolic, and commonsense \nreasoning, we find that chain-of-thought reasoning is an emergent property of model scale that allows \nsufficiently large language models to perform reasoning tasks that otherwise have flat scaling curves. \nBroadening the range of reasoning tasks that language models can perform will hopefully inspire \nfurther work on language-based approaches to reasoning. \n9","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":9,"lines":{"from":40,"to":50}}}}],["89c6eb4e-3b5b-4f61-9cec-d3acc70f5462",{"pageContent":"Acknowledgements \nWe thank Jacob Devlin, Claire Cui, Andrew Dai, and Ellie Pavlick for providing feedback on the \npaper. We thank Jacob Austin, Yuhuai Wu, Henryk Michalewski, Aitor Lewkowycz, Charles Sutton, \nand Aakanksha Chowdhery for helpful discussions. We thank Sid Maxwell for notifying us about a \nmistake in the manual error analysis in the original manuscript. \nReferences \nMichael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea \nFinn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, et al. 2022. Do as I can, not as I \nsay: Grounding language in robotic affordances. arXiv preprint arXiv:2204.01691 . \nAida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh \nHajishirzi. 2019.  MathQA: Towards interpretable math word problem solving with operation- \nbased formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":10,"lines":{"from":1,"to":12}}}}],["950b37ab-3de2-452e-a4dd-9ff0c5d386fd",{"pageContent":"based formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the \nAssociation for Computational Linguistics: Human Language Technologies, Volume 1 (Long and \nShort Papers) , Minneapolis, Minnesota. Association for Computational Linguistics. \nDaniel Andor, Luheng He, Kenton Lee, and Emily Pitler. 2019. Giving BERT a calculator: Finding \noperations and arguments with reading comprehension. EMNLP . \nJacob Andreas, Dan Klein, and Sergey Levine. 2018. Learning with latent language. NAACL . \nJacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, \nEllen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. 2021. Program synthesis with large language \nmodels. arXiv preprint arXiv:2108.07732 . \nBIG-bench collaboration. 2021.   Beyond the imitation game:  Measuring and extrapolating the \ncapabilities of language models. In preparation . \nKaj Bostrom, Xinyu Zhao, Swarat Chaudhuri, and Greg Durrett. 2021. Flexible generation of natural","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":10,"lines":{"from":12,"to":23}}}}],["4363bc82-5e74-4087-88d9-ce1c7ee08a10",{"pageContent":"Kaj Bostrom, Xinyu Zhao, Swarat Chaudhuri, and Greg Durrett. 2021. Flexible generation of natural \nlanguage deductions. EMNLP . \nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, \nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel \nHerbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, \nJeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, \nBenjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, \nand Dario Amodei. 2020. Language models are few-shot learners. NeurIPS . \nJonathon Cai, Richard Shin, and Dawn Song. 2017.  Making neural programming architectures \ngeneralize via recursion. ICLR . \nOana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, and Phil Blunsom. 2018. e-SNLI: \nNatural language inference with natural language explanations. NeurIPS .","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":10,"lines":{"from":23,"to":34}}}}],["313208dc-ea47-47ee-bedd-45bcf839ccb1",{"pageContent":"Natural language inference with natural language explanations. NeurIPS . \nHoward Chen, Jacqueline He, Karthik Narasimhan, and Danqi Chen. 2022.  Can rationalization \nimprove robustness? NAACL . \nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared \nKaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021.  Evaluating \nlarge language models trained on code. arXiv preprint arXiv:2107.03374 . \nXinyun Chen, Chen Liang, Adams Wei Yu, Denny Zhou, Dawn Song, and Quoc V. Le. 2019. Neural \nsymbolic reader:  Scalable integration of distributed and symbolic representations for reading \ncomprehension. ICLR . \nTing-Rui Chiang and Yun-Nung Chen. 2019. Semantically-aligned equation generation for solving \nand reasoning math word problems. In Proceedings of the 2019 Conference of the North Ameri- \ncan Chapter of the Association for Computational Linguistics: Human Language Technologies,","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":10,"lines":{"from":34,"to":45}}}}],["d639d85a-3f3a-457d-8195-1e44f7eb05ef",{"pageContent":"can Chapter of the Association for Computational Linguistics: Human Language Technologies, \nVolume 1 (Long and Short Papers) , pages 2656–2668, Minneapolis, Minnesota. Association for \nComputational Linguistics. \n10","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":10,"lines":{"from":45,"to":48}}}}],["a6712d82-fe5d-41f6-aff8-c1d8d116dd09",{"pageContent":"Peter Clark,  Oyvind Tafjord,  and Kyle Richardson. 2020.   Transformers as soft reasoners over \nlanguage. IJCAI . \nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher \nHesse, and John Schulman. 2021. Training verifiers to solve math word problems. arXiv preprint \narXiv:2110.14168 . \nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of \ndeep bidirectional transformers for language understanding. NAACL . \nHonghua Dong, Jiayuan Mao, Tian Lin, Chong Wang, Lihong Li, and Denny Zhou. 2019. Neural \nlogic machines. ICLR . \nDheeru Dua, Sameer Singh, and Matt Gardner. 2020. Benefits of intermediate annotations in reading \ncomprehension. ACL . \nMor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. 2021. Did \naristotle use a laptop? A question answering benchmark with implicit reasoning strategies. TACL .","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":11,"lines":{"from":1,"to":13}}}}],["f7cfe6a0-91eb-41b0-a35a-9222d75f2ed8",{"pageContent":"aristotle use a laptop? A question answering benchmark with implicit reasoning strategies. TACL . \nYuling Gu, Bhavana Dalvi Mishra, and Peter Clark. 2022.  DREAM: Uncovering mental models \nbehind language models. NAACL . \nBraden Hancock, Paroma Varma, Stephanie Wang, Martin Bringmann, Percy Liang, and Christopher \nRé. 2018. Training classifiers with natural language explanations. ACL . \nPeter Hase and Mohit Bansal. 2022. When can models learn from explanations? a formal framework \nfor understanding the roles of explanation data. ACL . \nDan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, \nand Jacob Steinhardt. 2021. Measuring mathematical problem solving with the math dataset. arXiv \npreprint arXiv:2103.03874 . \nMohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. 2014. Learning \nto solve arithmetic word problems with verb categorization. EMNLP .","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":11,"lines":{"from":13,"to":24}}}}],["fc17675d-5641-4d98-accd-309151aa6ccf",{"pageContent":"to solve arithmetic word problems with verb categorization. EMNLP . \nZhanming Jie, Jierui Li, and Wei Lu. 2022.  Learning to reason deductively: Math word problem \nsolving as complex relation extraction. arXiv preprint arXiv:2203.10316 . \nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, \nScott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language \nmodels. arXiv preprint arXiv:2001.08361 . \nRik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. 2016. \nMAWPS: A math word problem repository. NAACL . \nAndrew K. Lampinen, Ishita Dasgupta, Stephanie C.Y. Chan, Kory Matthewson, Michael Henry \nTessler, Antonia Creswell, James L. McClelland, Jane X. Wang, and Felix Hill. 2022. Can language \nmodels learn from explanations in context? arXiv preprint arXiv:2204.02329 . \nYihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang,","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":11,"lines":{"from":24,"to":35}}}}],["1c425e92-128c-4791-99e2-cdbfc6d1f76e",{"pageContent":"Yihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang, \nand Ee-Peng Lim. 2021. MWPToolkit: An open-source framework for deep learning-based math \nword problem solvers. arXiv preprint arXiv:2109.00799 . \nTeven Le Scao and Alexander Rush. 2021. How many data points is a prompt worth? NAACL . \nBrian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter-efficient \nprompt tuning. EMNLP . \nIddo Lev, Bill MacCartney, Christopher Manning, and Roger Levy. 2004.  Solving logic puzzles: \nFrom robust processing to precise semantics. Proceedings of the 2nd Workshop on Text Meaning \nand Interpretation . \nXiang Lisa Li and Percy Liang. 2021. Prefix-tuning: Optimizing continuous prompts for generation. \nACL . \n11","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":11,"lines":{"from":35,"to":46}}}}],["6ea30ba8-6d5d-4ab8-b131-f89424b9db7f",{"pageContent":"Zhengzhong Liang,  Steven Bethard,  and Mihai Surdeanu. 2021.   Explainable multi-hop verbal \nreasoning through internal monologue. NAACL . \nWang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017. Program induction by rationale \ngeneration: Learning to solve and explain algebraic word problems. ACL . \nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021. \nPre-train, prompt, and predict: A systematic survey of prompting methods in natural language \nprocessing. arXiv preprint arXiv:2107.13586 . \nBodhisattwa Prasad Majumder, Oana-Maria Camburu, Thomas Lukasiewicz, and Julian McAuley. \n2021.   Rationale-inspired natural language explanations with commonsense. arXiv preprint \narXiv:2106.13876 . \nAna Marasovi \n ́ \nc, Iz Beltagy, Doug Downey, and Matthew E Peters. 2022. Few-shot self-rationalization \nwith natural language prompts. NAACL Findings . \nJoshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020.  On faithfulness and","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":12,"lines":{"from":1,"to":15}}}}],["736511fe-84eb-4837-8543-0f5802136977",{"pageContent":"Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020.  On faithfulness and \nfactuality in abstractive summarization. In ACL . \nShen Yun Miao, Chao Chun Liang, and Keh Yih Su. 2020.  A diverse corpus for evaluating and \ndeveloping English math word problem solvers. ACL . \nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke \nZettlemoyer. 2022. Rethinking the role of demonstrations: What makes in-context learning work? \narXiv preprint arXiv:2202.12837 . \nSharan Narang, Colin Raffel, Katherine Lee, Adam Roberts, Noah Fiedel, and Karishma Malkan. \n2020. WT5?!    Training  text-to-text  models  to  explain  their  predictions. arXiv  preprint \narXiv:2004.14546 . \nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David \nBieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. 2021. Show your work:","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":12,"lines":{"from":15,"to":26}}}}],["a640536b-3aae-4494-ab2f-d17a74b16789",{"pageContent":"Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. 2021. Show your work: \nScratchpads for intermediate computation with language models. arXiv preprint arXiv:2112.00114 . \nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong \nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to \nfollow instructions with human feedback. arXiv preprint arXiv:2203.02155 . \nArkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021.  Are NLP models really able to solve \nsimple math word problems? NAACL . \nMatthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and \nLuke Zettlemoyer. 2018. Deep contextualized word representations. NAACL . \nXinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, and \nWeizhu Chen. 2022. Reasoning like program executors. arXiv preprint arXiv:2201.11473 .","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":12,"lines":{"from":26,"to":36}}}}],["eac08881-a722-4421-be89-46ae40f1f943",{"pageContent":"Weizhu Chen. 2022. Reasoning like program executors. arXiv preprint arXiv:2201.11473 . \nPiotr Pi ̨ekos, Mateusz Malinowski, and Henryk Michalewski. 2021.   Measuring and improving \nBERT’s mathematical abilities by predicting the order of reasoning. ACL . \nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John \nAslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. 2021. Scaling language models: \nMethods, analysis & insights from training Gopher. arXiv preprint arXiv:2112.11446 . \nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi \nZhou, Wei Li, and Peter J Liu. 2020.  Exploring the limits of transfer learning with a unified \ntext-to-text transformer. Journal of Machine Learning Research , 21:1–67. \nDheeraj Rajagopal, Vidhisha Balachandran, Eduard H. Hovy, and Yulia Tsvetkov. 2021. SelfExplain: \nA self-explaining architecture for neural text classifiers. EMNLP .","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":12,"lines":{"from":36,"to":46}}}}],["0085e8f9-f3d3-443c-8d57-0a295b1de235",{"pageContent":"A self-explaining architecture for neural text classifiers. EMNLP . \nNazneen Fatema Rajani,  Bryan McCann,  Caiming Xiong,  and Richard Socher. 2019.   Explain \nyourself! Leveraging language models for commonsense reasoning. ACL . \n12","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":12,"lines":{"from":46,"to":49}}}}],["ff0d9701-24da-43c9-9af4-4112d062aa90",{"pageContent":"Qiu Ran,  Yankai Lin,  Peng Li,  Jie Zhou,  and Zhiyuan Liu. 2019.   NumNet:  Machine reading \ncomprehension with numerical reasoning. EMNLP . \nHannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Michael Collins, Dipanjan Das, Slav Petrov, \nGaurav Singh Tomar, Iulia Turc, and David Reitter. 2021. Measuring attribution in natural language \ngeneration models. arXiv preprint arXiv:2112.12870 . \nGabriel Recchia. 2021. Teaching autoregressive language models complex tasks by demonstration. \narXiv preprint arXiv:2109.02102 . \nEmily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen, Chris Callison-Burch, and Jason Wei. 2022. \nA recipe for arbitrary text style transfer with large language models. ACL . \nLaria Reynolds and Kyle McDonell. 2021. Prompt programming for large language models: Beyond \nthe few-shot paradigm. Extended Abstracts of the 2021 CHI Conference on Human Factors in \nComputing Systems . \nSubhro Roy and Dan Roth. 2015. Solving general arithmetic word problems. EMNLP .","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":13,"lines":{"from":1,"to":13}}}}],["75e4e32c-a072-49a7-b96e-e76e0c11c98a",{"pageContent":"Subhro Roy and Dan Roth. 2015. Solving general arithmetic word problems. EMNLP . \nSubhro Roy, Tim Vieira, and Dan Roth. 2015.  Reasoning about Quantities in Natural Language. \nTACL . \nMohammed Saeed, Naser Ahmadi, Preslav Nakov, and Paolo Papotti. 2021. RuleBERT: Teaching \nsoft rules to pre-trained language models. EMNLP . \nVictor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, \nAntoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2022.  Multitask prompted \ntraining enables zero-shot task generalization. ICLR . \nJianhao Shen,  Yichun Yin,  Lin Li,  Lifeng Shang,  Xin Jiang,  Ming Zhang,  and Qun Liu. 2021. \nGenerate & rank: A multi-task framework for math word problems. In Findings of the Association \nfor Computational Linguistics: EMNLP 2021 . \nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. CommonsenseQA: A \nquestion answering challenge targeting commonsense knowledge. NAACL .","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":13,"lines":{"from":13,"to":25}}}}],["0be19fbc-a744-4034-906a-985ba504d598",{"pageContent":"question answering challenge targeting commonsense knowledge. NAACL . \nAlon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, and Jonathan Berant. 2020.  Leap-of- \nthought: Teaching pre-trained models to systematically reason over implicit knowledge. NeurIPS . \nAlon Talmor, Ori Yoran, Ronan Le Bras, Chandra Bhagavatula, Yoav Goldberg, Yejin Choi, and \nJonathan Berant. 2021.  CommonsenseQA 2.0:  Exposing the limits of ai through gamification. \nNeurIPS Track on Datasets and Benchmarks . \nYi Tay, Mostafa Dehghani, Vinh Q Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven \nZheng, Neil Houlsby, and Donald Metzler. 2022. Unifying language learning paradigms. arXiv \npreprint arXiv:2205.05131 . \nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze \nCheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022. LaMDA: Language models for \ndialog applications. arXiv preprint arXiv:2201.08239 .","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":13,"lines":{"from":25,"to":36}}}}],["889ebb26-2c24-4e0d-b0e6-662b809aa638",{"pageContent":"dialog applications. arXiv preprint arXiv:2201.08239 . \nXuezhi  Wang,  Jason  Wei,  Dale  Schuurmans,  Quoc  Le,  Ed  Chi,  and  Denny  Zhou.  2022a. \nSelf-consistency  improves  chain  of  thought  reasoning  in  language  models. arXiv  preprint \narXiv:2203.11171 . \nYizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana \nArunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. 2022b. \nBenchmarking generalization via in-context instructions on 1,600+ language tasks. arXiv preprint \narXiv:2204.07705 . \nJason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, \nAndrew M. Dai, and Quoc V. Le. 2022a. Finetuned language models are zero-shot learners. ICLR . \n13","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":13,"lines":{"from":36,"to":46}}}}],["50ba420c-dc4f-4167-b555-2634811f7cdf",{"pageContent":"Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, \nMaarten Bosma, Denny Zhou, Donald Metzler, et al. 2022b. Emergent abilities of large language \nmodels. Transactions on Machine Learning Research . \nSarah Wiegreffe, Jack Hessel, Swabha Swayamdipta, Mark Riedl, and Yejin Choi. 2022. Reframing \nhuman-AI collaboration for generating free-text explanations. NAACL . \nSarah Wiegreffe and Ana Marasovi \n ́ \nc. 2021. Teach me to explain: A review of datasets for explainable \nNLP. NeurIPS . \nSarah Wiegreffe, Ana Marasovi \n ́ \nc, and Noah A. Smith. 2021. Measuring association between labels \nand free-text rationales. EMNLP . \nTongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and \nCarrie J Cai. 2022a.  PromptChainer:  Chaining large language model prompts through visual \nprogramming. CHI Extended Abstracts . \nTongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022b. AI chains: Transparent and controllable","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":14,"lines":{"from":1,"to":17}}}}],["bd87a5a7-a9f9-4cf7-af8b-c2dd234f53de",{"pageContent":"Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022b. AI chains: Transparent and controllable \nhuman-AI interaction by chaining large language model prompts. CHI . \nYujun Yan, Kevin Swersky, Danai Koutra, Parthasarathy Ranganathan, and Milad Hashemi. 2020. \nNeural execution engines: Learning to execute subroutines. NeurIPS . \nHuihan Yao, Ying Chen, Qinyuan Ye, Xisen Jin, and Xiang Ren. 2021. Refining language models \nwith compositional explanations. NeurIPS . \nXi Ye and Greg Durrett. 2022.  The unreliability of explanations in few-shot in-context learning. \narXiv preprint arXiv:2205.03401 . \nYordan Yordanov, Vid Kocijan, Thomas Lukasiewicz, and Oana-Maria Camburu. 2021. Few-shot \nout-of-domain transfer learning of natural language explanations. arXiv preprint arXiv:2112.06204 . \nOmar Zaidan, Jason Eisner, and Christine Piatko. 2007.  Using “annotator rationales” to improve \nmachine learning for text categorization. NAACL .","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":14,"lines":{"from":17,"to":28}}}}],["9b59e8b8-80bd-49dc-aa13-54d05e78f93d",{"pageContent":"machine learning for text categorization. NAACL . \nWojciech Zaremba and Ilya Sutskever. 2014. Learning to execute. arXiv preprint arXiv:1410.4615 . \nEric Zelikman, Yuhuai Wu, and Noah D. Goodman. 2022.  STaR: Bootstrapping reasoning with \nreasoning. arXiv preprint arXiv:2203.14465 . \nTony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021.  Calibrate before use: \nImproving few-shot performance of language models. ICML . \nWangchunshu Zhou, Jinyi Hu, Hanlin Zhang, Xiaodan Liang, Maosong Sun, Chenyan Xiong, and \nJian Tang. 2020. Towards interpretable natural language understanding with explanations as latent \nvariables. NeurIPS . \n14","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":14,"lines":{"from":28,"to":37}}}}],["19fa1b8e-56ce-4aa1-81cf-89bf60182828",{"pageContent":"Checklist \n1.  For all authors... \n(a) Do the main claims made in the abstract and introduction accurately reflect the paper’s \ncontributions and scope? [Yes] \n(b) \nDid you describe the limitations of your work? [Yes] See Section 6 and Appendix A.2. \n(c) Did you discuss any potential negative societal impacts of your work? [Yes] We don’t \nexpect negative societal impacts as a direct result of the contributions in our paper. One \nconsideration, however, is that generated chain of thought is not always factual, which \nis noted as a limitation in Appendix D.1 (and note that we do not suggest using such \nchains of thought in a factual manner or in any real-world scenario). \n(d) Have you read the ethics review guidelines and ensured that your paper conforms to \nthem? [Yes] \n2.  If you are including theoretical results... \n(a)  Did you state the full set of assumptions of all theoretical results? [N/A] \n(b)  Did you include complete proofs of all theoretical results? [N/A]","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":15,"lines":{"from":1,"to":16}}}}],["b7194b04-a934-4d99-9690-fd537f7d6bcc",{"pageContent":"(b)  Did you include complete proofs of all theoretical results? [N/A] \n3.  If you ran experiments... \n(a) Did you include the code, data, and instructions needed to reproduce the main experi- \nmental results (either in the supplemental material or as a URL)? [Yes] We included \ninputs, outputs, and targets for LaMDA and GPT-3 in the supplementary material. \nAlthough we use proprietary models, we GPT-3 results are fully reproducible. Repro- \nducibility is further discussed in Appendix E.1. \n(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they \nwere chosen)? [Yes] Data splits were specified, N/A for hyperparams. \n(c) Did you report error bars (e.g., with respect to the random seed after running exper- \niments multiple times)?  [Yes] Standard deviation for multiple seeds using LaMDA \n137B, where each seed is a different random order of exemplars, is given in Table 6 \nand Table 7.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":15,"lines":{"from":16,"to":28}}}}],["0101b84a-59aa-42d7-96da-462ef2fb5869",{"pageContent":"137B, where each seed is a different random order of exemplars, is given in Table 6 \nand Table 7. \n(d) Did you include the total amount of compute and the type of resources used (e.g., type \nof GPUs, internal cluster, or cloud provider)? [Yes] Type of resources are described in \nAppendix E.2, though we did not estimate the total amount of compute. \n4.  If you are using existing assets (e.g., code, data, models) or curating/releasing new assets... \n(a) If your work uses existing assets, did you cite the creators? [Yes] We used two models \nthat we anonymized based on the recommendation of the NeurIPS chairs. These models \nwill be cited in the camera-ready version of the paper. \n(b)  Did you mention the license of the assets? [Yes] See Appendix E.3. \n(c) Did you include any new assets either in the supplemental material or as a URL? [Yes] \nThe coinflip and last letter concatenation datasets are the only new assets, and they are \ngiven in the Supplementary Materials.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":15,"lines":{"from":27,"to":39}}}}],["78a23e55-e209-4707-8187-680322e16db2",{"pageContent":"given in the Supplementary Materials. \n(d) Did you discuss whether and how consent was obtained from people whose data you’re \nusing/curating? [N/A] No human data collected. \n(e) Did you discuss whether the data you are using/curating contains personally identifiable \ninformation or offensive content? [N/A] No human data collected. \n5.  If you used crowdsourcing or conducted research with human subjects... \n(a) Did you include the full text of instructions given to participants and screenshots, if \napplicable? [N/A] \n(b) \nDid you describe any potential participant risks, with links to Institutional Review \nBoard (IRB) approvals, if applicable? [N/A] \n(c) Did you include the estimated hourly wage paid to participants and the total amount \nspent on participant compensation? [N/A] \n15","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":15,"lines":{"from":39,"to":52}}}}],["41b20cb5-d57e-4583-8d3f-93ffc664bddd",{"pageContent":"A    Frequently Asked Questions \nA.1    Why does increasing model scale improve chain-of-thought prompting? \nThe finding that successful chain-of-thought reasoning predictably emerges only at certain model \nscales is intriguing. Scaling up language models has been shown to confer benefits such as improved \nperformance and sample efficiency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent \nin the sense that its success cannot be predicted only by extrapolating the performance of small scale \nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters. \nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and \nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved \nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":16,"lines":{"from":1,"to":10}}}}],["e6913cd4-6cec-4f73-a322-d4e6561da293",{"pageContent":"manually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding \n(20 errors), one step missing (18 errors), and other errors (7 errors). The “other category” included \nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one \nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were \nconceived based on what improvements were needed to make the chain of thought correct. \nAs shown in Figure 9, scaling PaLM to 540B parameters fixed a substantial portion of errors in all \nthree categories. Examples of semantic understanding and one-step missing errors that were fixed by \nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that \nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function \nof model scale (though note that model scale is often conflated with other factors, such as amount of","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":16,"lines":{"from":10,"to":19}}}}],["dc994b3c-3387-4410-b772-1aba93912073",{"pageContent":"training compute). \nSemantic understanding \n \n(62B made 20 errors of this type,  \n540B  fi xes 6 of them) \nOne step missing \n \n(62B made 18 errors of this type,  \n540B  fi xes 12 of them) \nOther \n \n(62B made 7 errors of this type,  \n540B  fi xes 4 of them) \nTypes of errors made by  \na 62B language model: \nErrors  fi xed by  \nscaling from  \n62B to 540B \nFigure 9:   Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized \nthat semantic understanding, one step missing, and other. The other category includes hallucinations, \nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B fixed a substantial portion of \nerrors in all categories. \nThere are also three notable points regarding why small language models fail. The first observation \nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated \nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":16,"lines":{"from":20,"to":44}}}}],["259f4c54-659e-4620-8f41-0fed38eb0ea5",{"pageContent":"in Section 5, for even symbolic reasoning tasks that only require generalization to new examples \nusing the same chain of thought logical structure that was given in the few-shot exemplars, small \nlanguage models still failed.  The second observation is that small language models seem to have \ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple \narithmetic operations (without semantic understanding) requires sufficient model scale. Finally, we \nnoticed qualitatively that small language models often did not generate a final answer that could be \nparsed, due to either repetitions or logic that never arrived at a final answer. \nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated \nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol \nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":16,"lines":{"from":44,"to":53}}}}],["bf1b5295-2712-4194-975f-5d149ecf91b9",{"pageContent":"investigate what properties of pretraining data, model architecture, and optimization objective causally \nenable such reasoning capabilities. \n16","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":16,"lines":{"from":54,"to":56}}}}],["d56339af-d49d-42da-92a3-151051b368c5",{"pageContent":"Tracy used a piece of wire 4  \nfeet long to support tomato  \nplants in the garden. The  \nwire was cut into pieces 6  \ninches long. How many  \npieces did she obtain? \nShe cut the wire into 6 inch pieces.  \nThis means she got 4 * 6 = 24  \npieces. The answer is 24.  \n(Incorrect: semantic  \nunderstanding error) \n62B Model Output \nQuestion \n540B Model Output \nThe wire was 4 feet long. This  \nmeans it was 4 * 12 = 48 inches  \nlong. It was cut into pieces 6 inches  \nlong. This means she obtained 48 /  \n6 = 8 pieces. The answer is 8.  \n(Correct) \nTom's ship can travel at 10  \nmiles per hour. He is sailing  \nfrom 1 to 4 PM. He then  \ntravels back at a rate of 6  \nmph. How long does it take  \nhim to get back? \nHe travels from 1 to 4 PM. That  \nmeans he travels for 3 hours. He  \ntravels back at 6 mph. That means  \nhe travels for 3 * 6 = 18 miles. The  \nanswer is 18.  (Incorrect: semantic  \nunderstanding error) \nHe travels at 10 mph from 1 to 4  \nPM. This means he travels 3 hours.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":17,"lines":{"from":1,"to":34}}}}],["ff5f3a77-e073-467b-b307-ec87c7c7be20",{"pageContent":"understanding error) \nHe travels at 10 mph from 1 to 4  \nPM. This means he travels 3 hours.  \n3 hours at 10 mph means he travels  \n3 * 10 = 30 miles. He then travels  \nback at 6 mph. This means he  \ntravels 6 miles per hour. He has to  \ntravel 30 miles, so it takes him 30 / 6  \n= 5 hours. The answer is 5.  \n(Correct) \nStephen placed an online  \norder for groceries. His final  \nbill came to $40.00.  \nBecause this was through a  \ndelivery vendor, they tacked  \non a 25% fee to his final  \ntotal and charged him $3.00  \nin delivery fees. Stephen  \nalso added a $4.00 tip. After  \nthe extra fees, what was the  \nfinal price of Stephen's  \ngroceries? \nThe final price of Stephen's  \ngroceries was $40.00. The delivery  \nvendor added 25% to the final total,  \nso the final total was 125% of  \n$40.00. This means the final total  \nwas 125% * $40.00 = $50.00. The  \ndelivery vendor also charged $3.00  \nin delivery fees. So the final price of  \nStephen's groceries was $50.00 +","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":17,"lines":{"from":32,"to":62}}}}],["a0669ea8-9344-448d-b796-fece044cb641",{"pageContent":"in delivery fees. So the final price of  \nStephen's groceries was $50.00 +  \n$3.00 = $53.00. The answer is  \n$53.00.  (Incorrect: one step  \nmissing error) \nStephen's bill was $40.00. The  \ndelivery vendor added 25% to the  \nbill. This means the bill was  \nincreased by 25% of $40.00. This is  \n0.25 * $40.00 = $10.00. The delivery  \nfee was $3.00. The tip was $4.00.  \nSo the total bill was $40.00 + $10.00  \n+ $3.00 + 540b model $4.00 =  \n$57.00. The answer is 57.  (Correct) \nThere are four schools  \ncompeting at a basketball  \ntournament. Each school  \nhas sent a girls’ basketball  \nteam and a boys’ basketball  \nteam and each team has 5  \nplayers each. Each school  \nhas also sent a coach for  \neach team. In total, how  \nmany people have all of the  \nschools sent? \nThere are 4 schools. Each school  \nhas sent a girls’ basketball team and  \na boys’ basketball team. Each team  \nhas 5 players each. That means  \nthere are 4 * 2 * 5 = 40 players.  \nEach team has a coach. That","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":17,"lines":{"from":61,"to":91}}}}],["c447ac5c-53a9-45f5-97d5-548bbdd9e230",{"pageContent":"has 5 players each. That means  \nthere are 4 * 2 * 5 = 40 players.  \nEach team has a coach. That  \nmeans there are 40 + 4 = 44  \ncoaches. The answer is 44.  \n(Incorrect: one step missing  \nerror) \nEach school has sent 2 teams, each  \nwith 5 players. This means each  \nschool has sent 2 * 5 = 10 players.  \nEach school has also sent 2  \ncoaches. This means each school  \nhas sent 10 + 2 = 12 people. There  \nare 4 schools, so in total all of the  \nschools have sent 4 * 12 = 48  \npeople. The answer is 48.  (Correct) \n62B Model Output \n62B Model Output \n62B Model Output \n540B Model Output \n540B Model Output \n540B Model Output \nQuestion \nQuestion \nQuestion \nFigure 10:   Examples of semantic understanding and one-step missing errors that were fixed by \nscaling PaLM from 62B to 540B. \nA.2    What is the role of prompt engineering? \nOne of the key considerations of prompting is sensitivity to the exact prompt. There is no shortage","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":17,"lines":{"from":89,"to":117}}}}],["33ee9602-fcf8-434b-b121-6b2fed0cf066",{"pageContent":"of work showing that prompts affect language models in unexpected ways (Min et al., 2022). The \ngeneral way that we created chain of thought annotations was by taking eight exemplars from the \ntraining set and decomposing the reasoning process into multiple steps leading to the final answer. \nExamples of chain of thought annotations are provided in Figure 3, with full prompts given in \nAppendix G. To analyze how sensitive chain of thought is to prompt engineering, we performed \nrobustness experiments with respect to various factors. \n• Different annotators. \nWe first analyze robustness to three different annotators (Section 3.4 and \nFigure 6). Although there is notable variance in performance (which we will discuss later), chain \nof thought performed better than the baseline by a large margin for all three annotators on eight \ndatasets in arithmetic, commonsense, and symbolic reasoning (Table 6 and Table 7). Similar to the","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":17,"lines":{"from":118,"to":128}}}}],["1e68b8b3-39d6-4ad5-bec8-f0284e78b0bf",{"pageContent":"datasets in arithmetic, commonsense, and symbolic reasoning (Table 6 and Table 7). Similar to the \nannotation process in Cobbe et al. (2021), annotators were not given specific instructions about \n17","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":17,"lines":{"from":128,"to":130}}}}],["abe627fd-49f8-4440-bebd-244926a57b93",{"pageContent":"how to write the chain of thought annotations other than to simply write the step-by-step reasoning \nprocess that led to the final answer. Thus, the annotations were written in each annotator’s own \nlinguistic “chain of thought” writing style. \n• Annotators without machine learning background. The GSM8K dataset (Cobbe et al., 2021) \nconveniently provides a training set with reasoning chains written by crowd compute workers, \nwhich enables us to investigate whether chain of thought still works with reasoning chains from an \nindependent source without a background in machine learning. So we randomly sampled three sets \nof eight exemplars with chains of thought from GSM8K. These chain of thought annotations also \noutperformed the baseline by a large margin for all four arithmetic datasets (Table 6), indicating \nthat chain of thought is not dependent on a particular set of annotators. \n• Different exemplars. The different GSM8K exemplars experiment above (Table 6) also shows","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":18,"lines":{"from":1,"to":11}}}}],["416e842d-1702-43be-a02f-84fa90b50e5b",{"pageContent":"• Different exemplars. The different GSM8K exemplars experiment above (Table 6) also shows \nthat chain-of-thought prompting works for different sets of exemplars. Notably, we test every set of \nexemplars on all four arithmetic datasets (instead of picking exemplars from the training set for \neach dataset), which suggests that the exemplars do not necessarily have to come from the same \ndataset distribution as the test examples. \n• Different order of exemplars. Prior work has shown that in some cases (e.g., classification) even \nthe order of prompts matter—varying the permutation of few-shot exemplars can cause the accuracy \nof GPT-3 on SST-2 to range from near chance (54.3%) to near SOTA (93.4%) (Zhao et al., 2021). \nWe show the standard deviation of performance from different exemplars in Table 6 and Table 7. \nStandard deviations with respect to prompt order are relatively minimal in almost all cases. The","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":18,"lines":{"from":11,"to":20}}}}],["47f199a8-acfe-49a3-9d37-5551b89be343",{"pageContent":"Standard deviations with respect to prompt order are relatively minimal in almost all cases. The \none exception is the coin flip task, for which exemplar orders have high standard deviation, likely \nfor the reason cited in Zhao et al. (2021)—for classification, many exemplars of the same category \nin a row biases the model outputs). \n• Different number of exemplars. \nWe also found that gains from chain-of-thought prompting \ngenerally still held when there was a varying number of few-shot exemplars. This is shown for five \ndatasets in Figure 11 (we did not have the compute to run this for all datasets). We also found in \npreliminary experiments that further increasing the number of exemplars in standard prompting \ndid not lead to significant gains (e.g., increasing from 8 to 16 exemplars did not improve the \nperformance of standard prompting enough to catch up with chain-of-thought prompting).","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":18,"lines":{"from":20,"to":30}}}}],["6abdf02a-40f0-4670-8eea-415c1b97ad18",{"pageContent":"performance of standard prompting enough to catch up with chain-of-thought prompting). \n• Different language models. Another interesting question is whether certain prompts that work \nbetter for one model work better for other large language models.  We find that with the same \nprompts, chain-of-thought prompting improves performance across all three models (LaMDA, \nGPT-3, and PaLM) for all datasets except CSQA and StrategyQA for GPT-3 (Table 1, Table 4, \nTable 5).  The fact that gains from chain of thought did not transfer perfectly among models is \na limitation; further work could investigate why how different pre-training datasets and model \narchitectures affect the performance gain from chain-of-thought prompting. \nPrompt engineering still matters, though. Although the results are relatively robust to the prompt \nfor arithmetic reasoning, we want to be clear that prompt engineering still does matter, and can","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":18,"lines":{"from":30,"to":39}}}}],["139ce0b4-ea64-45bb-8503-eb8b5e539879",{"pageContent":"for arithmetic reasoning, we want to be clear that prompt engineering still does matter, and can \nimprove  performance  significantly  in  many  cases.   Though  most  chain  of  thought  annotations \noutperform standard prompting, there is large variation in many cases.  For instance, for the coin \nflip task, the performance varied from 99.6% for Annotator A to 71.4% for Annotator C, though \nboth were above standard prompting = 50.0% (see Table 7).  There are even tasks where prompt \nengineering is a requirement for good performance. In preliminary experiments, we tried using chain \nof thought to enable language models to reverse the order of a list of 5 items. While two co-authors \nwere not able to write chain of thought prompts that solved the task despite their best attempts, a third \nco-author was able to write a chain of thought that perfectly solved the task. \nHow to generate chain of thought annotations in a robust fashion could be an interesting direction","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":18,"lines":{"from":39,"to":48}}}}],["c389ad2e-fb6a-4206-b44c-aba0ca058813",{"pageContent":"How to generate chain of thought annotations in a robust fashion could be an interesting direction \nfor future work. For instance, an idea here could be to use a large language model to automatically \ngenerate chains of thought via prompting (and potentially optimize this over a validation set). \nA.3    Will chain-of-thought prompting improve performance for my task of interest? \nWhile chain-of-thought prompting is in principle applicable for any text-to-text task, it is more \nhelpful for some tasks than others. Based on the experiments in this paper, our intuition is that chain \nof thought helps the most when three conditions are met: (1) the task is challenging and requires \n18","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":18,"lines":{"from":48,"to":55}}}}],["92244ba5-5a5b-4508-a7d2-d67f2ca2d064",{"pageContent":"multi-step reasoning, (2) a large language model is used, and (3) the scaling curve is relatively flat. \nConversely, the benefits are smaller when one or more of these conditions are not met. \nThese intuitions are perhaps supported by the arithmetic reasoning results. The performance gain \nfrom chain-of-thought prompting is largest for PaLM 540B on GSM8K (challenging multi-step \nproblems, flat scaling curve), which meets these conditions. The performance gain is small for the \nsubsets of MAWPS that only require one or two steps (SingleOP, SingleEq, and AddSub), for which \nPaLM 540B already achieves performance of 90% or higher (and it is also generally true that there is \nless headroom for improvement when performance is already strong). \nAlthough in this paper we focused on multi-step reasoning tasks (arithmetic, commonsense, and \nsymbolic), chain-of-thought prompting can potentially be applied to any task for which humans use a","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":19,"lines":{"from":1,"to":10}}}}],["792ae62b-62be-49d7-b4f1-e579a1e65d32",{"pageContent":"“chain of thought” to solve (at least in principle). We leave the empirical evaluation of chain-of-thought \nprompting on such diverse tasks (e.g., machine translation, etc.) to future work. \nA.4    Why is prompting with the equation only not enough for some arithmetic reasoning \ndatasets? \nPrompting with the equation only as an intermediate step does help on many datasets, especially when \nthe datasets only require a few reasoning steps (SVAMP, ASDiv, MAWPS). For GSM8K, however, \nusing the equation only did not improve performance substantially. Based on qualitative analysis, we \nbelieve that these questions are too semantically challenging for the model to directly translate them \ninto a math equation. Consider this example from LaMDA 137B: \nQ UESTION : Mike plays ping pong for 40 minutes.  In the first 20 minutes, he scores 4 \npoints. In the second 20 minutes, he scores 25% more points. How many total points did he \nscore?","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":19,"lines":{"from":11,"to":22}}}}],["431213de-4885-4120-b137-9dc8574f67a9",{"pageContent":"points. In the second 20 minutes, he scores 25% more points. How many total points did he \nscore? \nE QUATION ONLY ( WRONG ANSWER ): (4 + 20 * 0.25) = 6. The answer is 6. \nC HAIN  OF  THOUGHT ( CORRECT ): Mike played ping pong for 40 minutes.  In the first \n20 minutes, he scored 4 points. In the second 20 minutes, he scored 25% more points. So \nhe scored 25% more in the second 20 minutes. 4 x 1.25 = 5. So he scored 5 points in the \nsecond 20 minutes. So he scored 9 points in total. The answer is 9. \nIt is hard for the model to directly translate all of the semantics into a single equation, but chain of \nthought allows it to better reason about each part of the question via intermediate steps in natural \nlanguage. \n19","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":19,"lines":{"from":21,"to":31}}}}],["1416b2b2-7141-428e-9e31-51dc6f62ed10",{"pageContent":"B    All Experimental Results \nThis section contains tables for experimental results for varying models and model sizes, on all \nbenchmarks, for standard prompting vs. chain-of-thought prompting. \nFor the arithmetic reasoning benchmarks, some chains of thought (along with the equations produced) \nwere correct, except the model performed an arithmetic operation incorrectly. A similar observation \nwas made in Cobbe et al. (2021).  Hence, we can further add a Python program as an external \ncalculator (using the Python eval function) to all the equations in the generated chain of thought. \nWhen there are multiple equations in a chain of thought, we propagate the external calculator results \nfrom one equation to the following equations via string matching. As shown in Table 1, we see that \nadding a calculator significantly boosts performance of chain-of-thought prompting on most tasks. \nTable 1:   Chain of thought prompting outperforms standard prompting for various large language","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":20,"lines":{"from":1,"to":11}}}}],["dfc14de6-7a7b-460e-a7ce-4815a4537900",{"pageContent":"Table 1:   Chain of thought prompting outperforms standard prompting for various large language \nmodels on five arithmetic reasoning benchmarks. All metrics are accuracy (%). Ext. calc.: post-hoc \nexternal calculator for arithmetic computations only. Prior best numbers are from the following. a : \nCobbe et al. (2021). b & e : Pi et al. (2022), c : Lan et al. (2021), d : Pi ̨ekos et al. (2021). \nPrompting GSM8K SVAMP ASDiv AQuA MAWPS \nPrior best N/A (finetuning)   55 \na \n57.4 \nb \n75.3 \nc \n37.9 \nd \n88.4 \ne \nUL2 20B Standard 4.1 10.1 16.0 20.5 16.6 \nChain of thought   4.4 (+0.3) 12.5 (+2.4) 16.9 (+0.9) 23.6 (+3.1) 19.1 (+2.5) \n+ ext. calc 6.9 28.3 34.3 23.6 42.7 \nLaMDA 137B Standard 6.5 29.5 40.1 25.5 43.2 \nChain of thought   14.3 (+7.8) 37.5 (+8.0) 46.6 (+6.5) 20.6 (-4.9) 57.9 (+14.7) \n+ ext. calc 17.8 42.1 53.4 20.6 69.3 \nGPT-3 175B Standard 15.6 65.7 70.3 24.8 72.7 \n(text-davinci-002) Chain of thought   46.9 (+31.3) 68.9 (+3.2) 71.3 (+1.0) 35.8 (+11.0) 87.1 (+14.4)","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":20,"lines":{"from":11,"to":33}}}}],["91764852-9ce8-4993-8f08-6e2e42381787",{"pageContent":"+ ext. calc 49.6 70.3 71.1 35.8 87.5 \nCodex Standard 19.7 69.9 74.0 29.5 78.7 \n(code-davinci-002) Chain of thought   63.1 (+43.4) 76.4 (+6.5) 80.4 (+6.4) 45.3 (+15.8) 92.6 (+13.9) \n+ ext. calc 65.4 77.0 80.0 45.3 93.3 \nPaLM 540B Standard 17.9 69.4 72.1 25.2 79.2 \nChain of thought   56.9 (+39.0) 79.0 (+9.6) 73.9 (+1.8) 35.8 (+10.6) 93.3 (+14.2) \n+ ext. calc 58.6 79.8 72.6 35.8 93.5 \n20","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":20,"lines":{"from":34,"to":41}}}}],["ca43e7af-5ea9-4d04-8e62-eb1f7bdcec38",{"pageContent":"Table 2: Standard prompting versus chain of thought prompting on five arithmetic reasoning bench- \nmarks.  Note that chain of thought prompting is an emergent ability of model scale—it does not \npositively impact performance until used with a model of sufficient scale. \nGSM8K SVAMP ASDiv AQuA MAWPS \nModel standard   CoT   standard   CoT   standard   CoT   standard   CoT   standard   CoT \nUL2 20B 4.1 4.4 10.1 12.5 16.0 16.9 20.5 23.6 16.6 19.1 \nLaMDA  420M 2.6 0.4 2.5 1.6 3.2 0.8 23.5 8.3 3.2 0.9 \n2B 3.6 1.9 3.3 2.4 4.1 3.8 22.9  17.7 3.9 3.1 \n8B 3.2 1.6 4.3 3.4 5.9 5.0 22.8  18.6 5.3 4.8 \n68B 5.7 8.2 13.6 18.8 21.8 23.1 22.3  20.2 21.6 30.6 \n137B 6.5 14.3 29.5 37.5 40.1 46.6 25.5  20.6 43.2 57.9 \nGPT 350M 2.2 0.5 1.4 0.8 2.1 0.8 18.1 8.7 2.4 1.1 \n1.3B 2.4 0.5 1.5 1.7 2.6 1.4 12.6 4.3 3.1 1.7 \n6.7B 4.0 2.4 6.1 3.1 8.6 3.6 15.4  13.4 8.8 3.5 \n175B 15.6 46.9 65.7 68.9 70.3 71.3 24.8 35.8 72.7 87.1 \nCodex - 19.7 63.1 69.9 76.4 74.0 80.4 29.5 45.3 78.7 92.6","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":21,"lines":{"from":1,"to":16}}}}],["e29c4b14-4b36-491e-b0c3-14c1685cb123",{"pageContent":"Codex - 19.7 63.1 69.9 76.4 74.0 80.4 29.5 45.3 78.7 92.6 \nPaLM 8B 4.9 4.1 15.1 16.8 23.7 25.2 19.3 21.7 26.2 30.5 \n62B 9.6 29.9 48.2  46.7 58.7 61.9 25.6  22.4 61.8 80.3 \n540B 17.9 56.9 69.4 79.0 72.1 73.9 25.2 35.8 79.2 93.3 \nTable 3:   Standard prompting versus chain of thought prompting on the four subsets of the MAWPS \nbenchmark. The point of stratifying the MAWPS benchmark is to show that performance gains are \nminimal on easy one-step or two-step problems where large language models already achieve high \nperformance (e.g., SingleOp, SingleEq, and AddSub). \nSingleOp SingleEq AddSub MultiArith \nModel standard   CoT   standard   CoT   standard   CoT   standard   CoT \nUL2 20B 24.9 27.2 18.0 20.2 18.5  18.2 5.0 10.7 \nLaMDA  420M 2.8 1.0 2.4 0.4 1.9 0.7 5.8 1.5 \n2B 4.6 4.1 2.4 3.3 2.7 3.2 5.8 1.8 \n8B 8.0 7.0 4.5 4.4 3.4 5.2 5.2 2.4 \n68B 36.5 40.8 23.9 26.0 17.3 23.2 8.7 32.4 \n137B 73.2 76.2 48.8 58.7 43.0 51.9 7.6 44.9 \nGPT 350M 3.2 1.8 2.0 0.2 2.0 1.5 2.3 0.8","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":21,"lines":{"from":16,"to":32}}}}],["df5f19fe-2405-4f84-8187-2b77e6a7ef23",{"pageContent":"137B 73.2 76.2 48.8 58.7 43.0 51.9 7.6 44.9 \nGPT 350M 3.2 1.8 2.0 0.2 2.0 1.5 2.3 0.8 \n1.3B 5.3 3.0 2.4 1.6 2.3 1.5 2.2 0.5 \n6.7B 13.5 3.9 8.7 4.9 8.6 2.5 4.5 2.8 \n175B 90.9  88.8 82.7 86.6 83.3  81.3 33.8 91.7 \nCodex - 93.1  91.8 86.8 93.1 90.9  89.1 44.0 96.2 \nPaLM 8B 41.8 46.6 29.5  28.2 29.4 31.4 4.2 15.8 \n62B 87.9  85.6 77.2 83.5 74.7 78.2 7.3 73.7 \n540B 94.1  94.1 86.5 92.3 93.9  91.9 42.2 94.7 \n21","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":21,"lines":{"from":31,"to":40}}}}],["864f2082-b616-40de-b0c0-0d813fd13bce",{"pageContent":"Table 4:  Standard prompting versus chain of thought prompting on five commonsense reasoning \nbenchmarks. Chain of thought prompting is an emergent ability of model scale—it does not positively \nimpact performance until used with a model of sufficient scale. \nCSQA StrategyQA Date Sports SayCan \nModel standard   CoT   standard   CoT   standard   CoT   standard   CoT   standard   CoT \nUL2 20B 34.2 51.4 59.0  53.3 13.5 14.0 57.9 65.3 20.0 41.7 \nLaMDA  420M 20.1  19.2 46.4  24.9 1.9 1.6 50.0  49.7 7.5 7.5 \n2B 20.2  19.6 52.6  45.2 8.0 6.8 49.3  57.5 8.3 8.3 \n8B 19.0  20.3 54.1  46.8 9.5 5.4 50.0  52.1 28.3  33.3 \n68B 37.0 44.1 59.6 62.2 15.5 18.6 55.2 77.5 35.0 42.5 \n137B 53.6 57.9 62.4 65.4 21.5 26.8 59.5 85.8 43.3 46.6 \nGPT 350M 14.7  15.2 20.6 0.9 4.3 0.9 33.8  41.6 12.5 0.8 \n1.3B 12.0  19.2 45.8  35.7 4.0 1.4 0.0  26.9 20.8 9.2 \n6.7B 19.0 24.0 53.6  50.0 8.9 4.9 0.0 4.4 17.5 35.0 \n175B 79.5  73.5 65.9  65.4 43.8 52.1 69.6 82.4 81.7 87.5","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":22,"lines":{"from":1,"to":15}}}}],["1af5f11a-d12b-414d-9942-b85c6cadbd62",{"pageContent":"175B 79.5  73.5 65.9  65.4 43.8 52.1 69.6 82.4 81.7 87.5 \nCodex - 82.3  77.9 67.1 73.2 49.0 64.8 71.7 98.5 85.8 88.3 \nPaLM 8B 19.8 24.9 55.6  53.5 12.9  13.1 55.1 75.2 34.2 40.0 \n62B 65.4 68.1 58.4 63.4 29.8 44.7 72.1 93.6 65.8 70.0 \n540B 78.1 79.9 68.6 77.8 49.0 65.3 80.5 95.4 80.8 91.7 \nTable 5:   Standard prompting versus chain of thought prompting enables length generalization to \nlonger inference examples on two symbolic manipulation tasks. \nLast Letter Concatenation Coin Flip (state tracking) \n2 OOD: 3 OOD: 4 2 OOD: 3 OOD: 4 \nModel standard  CoT standard  CoT standard  CoT standard CoT standard  CoT standard  CoT \nUL2 20B 0.6 18.8 0.0   0.2 0.0   0.0 70.4   67.1 51.6 52.2 48.7 50.4 \nLaMDA 420M 0.3 1.6 0.0   0.0 0.0   0.0 52.9   49.6 50.0 50.5 49.5 49.1 \n2B 2.3 6.0 0.0   0.0 0.0   0.0 54.9 55.3 47.4 48.7 49.8 50.2 \n8B 1.5 11.5 0.0   0.0 0.0   0.0 52.9 55.5 48.2 49.6 51.2 50.6 \n68B 4.4 52.0 0.0 0.8 0.0 2.5 56.2 83.2 50.4 69.1 50.9 59.6","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":22,"lines":{"from":15,"to":29}}}}],["6e99f604-9011-47ac-8ccc-7761ab70f714",{"pageContent":"68B 4.4 52.0 0.0 0.8 0.0 2.5 56.2 83.2 50.4 69.1 50.9 59.6 \n137B 5.8 77.5 0.0 34.4 0.0 13.5 49.0 99.6 50.7 91.0 49.1 74.5 \nPaLM 8B 2.6 18.8 0.0   0.0 0.0 0.2 60.0 74.4 47.3 57.1 50.9 51.8 \n62B 6.8 85.0 0.0 59.6 0.0 13.4 91.4 96.8 43.9 91.0 38.3 72.4 \n540B 7.6 99.4 0.2 94.8 0.0 63.0 98.1 100.0 49.3 98.6 54.8 90.2 \n22","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":22,"lines":{"from":29,"to":34}}}}],["0489f845-6dee-4fd4-a766-5dfed3415147",{"pageContent":"Table 6:  Ablation and robustness results for arithmetic reasoning datasets. Chain of thought generally \noutperforms ablations by a large amount. “Equation only” performs in between standard prompting \nand chain of thought prompting, as it allows for intermediate reasoning steps via equations but does \nnot leverage natural language. Chain of thought prompting has variance (as expected) when used \nwith prompts written by different annotators or when using other exemplars, but still outperforms \nstandard prompting by a large margin. Standard deviation shown is for different order of few-shot \nprompting exemplars, with five different random seeds. Results here are shown for LaMDA 137B, as \nadditional queries for GPT-3 and PaLM are both limited and expensive. \nGSM8K SVAMP ASDiv MAWPS \nStandard prompting 6.5 ± 0.4 29.5 ± 0.6 40.1 ± 0.6 43.2 ± 0.9 \nChain of thought prompting 14.3 ± 0.4 36.7 ± 0.4 46.6 ± 0.7 57.9 ± 1.5 \nAblations \n· equation only 5.4 ± 0.2 35.1 ± 0.4 45.9 ± 0.6 50.1 ± 1.0","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":23,"lines":{"from":1,"to":13}}}}],["c23a9908-50ca-47ce-9daa-8d4e037de1d9",{"pageContent":"Ablations \n· equation only 5.4 ± 0.2 35.1 ± 0.4 45.9 ± 0.6 50.1 ± 1.0 \n· variable compute only 6.4 ± 0.3 28.0 ± 0.6 39.4 ± 0.4 41.3 ± 1.1 \n· reasoning after answer 6.1 ± 0.4 30.7 ± 0.9 38.6 ± 0.6 43.6 ± 1.0 \nRobustness \n· different annotator (B) 15.5 ± 0.6 35.2 ± 0.4 46.5 ± 0.4 58.2 ± 1.0 \n· different annotator (C) 17.6 ± 1.0 37.5 ± 2.0 48.7 ± 0.7 60.1 ± 2.0 \n· intentionally concise style 11.1 ± 0.3 38.7 ± 0.8 48.0 ± 0.3 59.6 ± 0.7 \n· exemplars from GSM8K ( α ) 12.6 ± 0.6 32.8 ± 1.1 44.1 ± 0.9 53.9 ± 1.1 \n· exemplars from GSM8K ( β ) 12.7 ± 0.5 34.8 ± 1.1 46.9 ± 0.6 60.9 ± 0.8 \n· exemplars from GSM8K ( γ ) 12.6 ± 0.7 35.6 ± 0.5 44.4 ± 2.6 54.2 ± 4.7 \nTable 7:  Ablation and robustness results for four datasets in commonsense and symbolic reasoning. \nChain of thought generally outperforms ablations by a large amount. Chain of thought prompting has \nvariance (as expected) when used with prompts written by different annotators or when using other","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":23,"lines":{"from":12,"to":25}}}}],["5fc0f6ec-59c9-483e-912f-e0ade31df874",{"pageContent":"variance (as expected) when used with prompts written by different annotators or when using other \nexemplars, but still outperforms standard prompting by a large margin. Standard deviation shown \nis for different order of few-shot prompting exemplars, with five different random seeds.  Results \nhere are shown for LaMDA 137B, as additional queries for GPT-3 and PaLM are both limited and \nexpensive. The exception is that we run SayCan using PaLM here, as the SayCan evaluation set is \nonly 120 examples and therefore less expensive to run multiple times. \nCommonsense Symbolic \nDate Sports SayCan Concat Coin \nStandard prompting 21.5 ± 0.6 59.5 ± 3.0 80.8 ± 1.8 5.8 ± 0.6 49.0 ± 2.1 \nChain of thought prompting 26.8 ± 2.1 85.8 ± 1.8 91.7 ± 1.4 77.5 ± 3.8 99.6 ± 0.3 \nAblations \n· variable compute only 21.3 ± 0.7 61.6 ± 2.2 74.2 ± 2.3 7.2 ± 1.6 50.7 ± 0.7 \n· reasoning after answer 20.9 ± 1.0 63.0 ± 2.0 83.3 ± 0.6 0.0 ± 0.0 50.2 ± 0.5 \nRobustness","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":23,"lines":{"from":25,"to":38}}}}],["24b2c15d-ef24-4533-a66c-276c8db1f237",{"pageContent":"· reasoning after answer 20.9 ± 1.0 63.0 ± 2.0 83.3 ± 0.6 0.0 ± 0.0 50.2 ± 0.5 \nRobustness \n· different annotator (B) 27.4 ± 1.7 75.4 ± 2.7 88.3 ± 1.4 76.0 ± 1.9 77.5 ± 7.9 \n· different annotator (C) 25.5 ± 2.5 81.1 ± 3.6 85.0 ± 1.8 68.1 ± 2.2 71.4 ± 11.1 \n23","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":23,"lines":{"from":37,"to":41}}}}],["e0a23f28-91e4-4b3d-baf8-c62059332725",{"pageContent":"C    Extended Related Work \nChain-of-thought prompting is a general approach that is inspired by several prior directions: prompt- \ning, natural language explanations, program synthesis/execution, numeric and logical reasoning, and \nintermediate language steps. \nC.1    Prompting \nThe recent success of large-scale language models has led to growing interest in improving their \ncapability to perform tasks via prompting (Brown et al. (2020), and see Liu et al. (2021) for a \nsurvey). This paper falls in the category of general prompting approaches, whereby input prompts are \noptimized to allow a single large language model to better perform a variety of tasks (Li and Liang, \n2021; Lester et al., 2021; Reif et al., 2022, inter alia ). \nOne recent line of work aims to improve the ability of language models to perform a task by providing \ninstructions that describe the task (Raffel et al., 2020; Wei et al., 2022a; Ouyang et al., 2022; Sanh","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":24,"lines":{"from":1,"to":12}}}}],["f9a2bd38-f2ee-4c2b-920e-c1729d70044f",{"pageContent":"et al., 2022; Wang et al., 2022b). This line of work is related because it also augments input–output \npairs with meta-data. But whereas an instruction augments the input to a task (instructions are typically \nprepended to the inputs), chain-of-thought prompting augments the outputs of language models. \nAnother related direction is sequentially combining the outputs of language models; human–computer \ninteraction (HCI) work (Wu et al., 2022a,b) has shown that combining sequential generations of \nlanguage models improves task outcomes in a 20-person user study. \nC.2    Natural language explanations \nAnother closely related direction uses natural language explanations (NLEs), often with the goal of \nimproving model interpretability (Zhou et al., 2020; Wiegreffe and Marasovi \n ́ \nc, 2021, inter alia ). That \nline of work typically focuses on natural language inference (Camburu et al., 2018; Yordanov et al.,","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":24,"lines":{"from":13,"to":24}}}}],["b9b4a0bc-f8b7-48d4-8831-644008597099",{"pageContent":"2021; Bostrom et al., 2021), and produces explanations either simultaneously to or after the final \nprediction (Narang et al., 2020; Majumder et al., 2021; Wiegreffe et al., 2021, 2022). By contrast, \nthe chain of thought processing considered in this paper occurs before the final answer. And while \nNLE aims mostly to improve neural network interpretability (Rajagopal et al., 2021), the goal of \nchain-of-thought prompting is to allow models to decompose multi-hop reasoning tasks into multiple \nsteps—interpretability is just a side effect. Marasovi \n ́ \nc et al. (2022) show that prompt-based finetuning \nwith NLE improves NLI and classification performance, though they largely focus on evaluating \nexplanation plausibility. In comparison, our work focuses on a range of arithmetic, commonsense, \nand symbolic tasks that require multi-hop reasoning. \nC.3    Program synthesis and execution \nUsing intermediate reasoning steps has a long history in program synthesis and execution (Zaremba","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":24,"lines":{"from":25,"to":37}}}}],["f0a1602a-7d86-4860-8351-7a9a917d7eab",{"pageContent":"Using intermediate reasoning steps has a long history in program synthesis and execution (Zaremba \nand Sutskever, 2014, inter alia ).  Recent work along in this direction has included a number of \narchitectural innovations (Cai et al., 2017; Dong et al., 2019; Yan et al., 2020), as well as the use of \nlarge language models (Chen et al., 2021; Austin et al., 2021). The program execution work closest to \nours is perhaps Nye et al. (2021), which show that large language models can perform up to 10-digit \naddition, evaluate polynomials, and execute python programs. Whereas generating a program and \nthen executing it can be viewed as a type of reasoning, our work generalizes such domain-specific \nprimitives to natural language, which is open-domain and relevant to any text-to-text NLP task in \nprinciple. \nC.4    Numeric and logical reasoning \nNumeric and logical reasoning has been a long-studied task in machine learning and natural language","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":24,"lines":{"from":37,"to":47}}}}],["ed9623f7-011c-4bd6-abe9-40546ed4f412",{"pageContent":"processing (Lev et al., 2004, inter alia ).  Recent work has also aimed to inject numeric reasoning \nabilities in language models in various ways, such as augmenting BERT with a predefined set of \nexecutable operations (Andor et al., 2019), including a graph neural network (Ran et al., 2019), and \nusing specialized training procedures (Pi ̨ekos et al., 2021).  Another line of work aims to enable \nlanguage models to perform logical or formal reasoning, often by verablizing the rules in natural \nlanguage formal rules using language (Clark et al., 2020; Saeed et al., 2021; Liang et al., 2021). \n24","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":24,"lines":{"from":48,"to":54}}}}],["4c35abd7-ec41-4dc3-93d8-ed082baa8fb3",{"pageContent":"Perhaps the most-related work here is Recchia (2021), which shows that finetuning enables longhand \nmodule operations, which has previously been difficult for performers. Whereas work in this direction \nis often task-specific and uses finetuning, we show that chain-of-thought prompting works for a broad \nrange of tasks without any finetuning. \nC.5    Intermediate language steps \nExtensive prior work has shown the benefits of endowing neural networks with the ability to produce \nintermediate steps via training or finetuning confers various benefits in a range of scenarios.  As \nexamples, it has been shown that natural language intermediate steps can improve performance \n(Zaidan et al., 2007; Yao et al., 2021; Hase and Bansal, 2022; Gu et al., 2022), improve robustness \n(Chen et al., 2022), speed up training (Hancock et al., 2018), mitigate bias (Dua et al., 2020), and \neven help in image and reinforcement learning settings (Andreas et al., 2018). To endow models with","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":25,"lines":{"from":1,"to":11}}}}],["e07f6825-83fb-47cb-b0e6-92be1d157896",{"pageContent":"the ability to produce intermediate steps, prior work typically finetunes models on either manually \nannotated training datasets (Camburu et al., 2018; Rajani et al., 2019, inter alia ) or generates synthetic \ndatasets (Talmor et al., 2020; Zelikman et al., 2022).  Compared with these training or finetuning \nmethods, our work shows that various natural language reasoning abilities can be elicited in off-the- \nshelf language models of sufficient scale simply via prompting. This prompting setup is important \nbecause it allows for intermediate step reasoning without a large number of labeled annotations, and \nbecause a single model can perform a range of reasoning tasks without any gradient updates. \nD    Appendix: Additional Analysis \nD.1    Correct Chain of Thought Analysis \nAs mentioned in the main text, we analyze 50 chains of thought from LaMDA 137B that led to \ncorrect answers in the GSM8K dataset. Of these 50, only one arrived at the correct answer through","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":25,"lines":{"from":12,"to":22}}}}],["18254b8f-1849-45ce-8a67-b9ee42cef750",{"pageContent":"correct answers in the GSM8K dataset. Of these 50, only one arrived at the correct answer through \nincorrect reasoning (shown in Table 9:  “correct by chance”).  The other 49 had correct logic and \nmath, with examples shown in Table 8. Five had minor imperfections while maintaining coherent and \nunderstandable logic: \n•  One had underspecified statements (shown in Table 9: “correct but underspecified statements”). \n• \nOne made an unrelated but correct statement (shown in Table 9: “correct but unrelated statement”). \n• Two had the correct logic but omitted specific steps in the equation, though it was still understand- \nable (shown in Table 9: “correct but imperfect equation”). \n• One had the correct math but inverted the semantics (shown in Table 9:  “correct but inverted \nsemantics”) \nTable 8:  Example of correct chains of thought produced by the model for the GSM8K dataset. \nQ UESTION : James decides to run 3 sprints 3 times a week. He runs 60 meters each sprint. How many total","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":25,"lines":{"from":22,"to":34}}}}],["94239737-3e55-4de5-86bf-013bb3cf64f6",{"pageContent":"meters does he run a week? \nM ODEL A NSWER (CORRECT): James decides to run 3 sprints 3 times a week.  He runs 60 meters each \nsprint. So he runs 60 meters x 3 sprints x 3 times a week. That is 60 meters x 9. The answer is 540. X \nQ UESTION : Brandon’s iPhone is four times as old as Ben’s iPhone. Ben’s iPhone is two times older than Suzy’s \niPhone. If Suzy’s iPhone is 1 year old, how old is Brandon’s iPhone? \nM ODEL A NSWER (CORRECT): Brandon’s iPhone is 4 times as old as Ben’s iPhone.  Ben’s iPhone is 2 \ntimes older than Suzy’s iPhone. So Brandon’s iPhone is 4 x 2 = 8 times older than Suzy’s iPhone. Suzy’s iPhone \nis 1 year old. So Brandon’s iPhone is 8 x 1 = 8 years old. The answer is 8. X \nQ UESTION : Jean has 30 lollipops.  Jean eats 2 of the lollipops.  With the remaining lollipops, Jean wants to \npackage 2 lollipops in one bag. How many bags can Jean fill? \nM ODEL A NSWER (CORRECT): Jean started with 30 lollipops. She ate 2 of them. So she has 28 lollipops","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":25,"lines":{"from":35,"to":45}}}}],["2f55842b-0db7-46e3-bfd8-d1871823b1c5",{"pageContent":"left. She wants to package 2 lollipops in one bag. So she can package 28 / 2 = 14 bags. The answer is 14. X \nAlthough we find that chain-of-thought reasoning is mostly correct for math questions where the final \nanswer was correct, this is likely because it is hard to arrive at the correct final answer by coincidence \nfor free response questions. For multiple choice or binary classification problems, it was much more \n25","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":25,"lines":{"from":46,"to":50}}}}],["49b4b499-a492-4240-908b-dfa8fef51b64",{"pageContent":"likely that models could arrive at the correct answer via an incorrect reasoning path (e.g., all the \ncommmonsense reasoning datasets we evaluate). This is a limitation, and future work should perform \nan analysis of the factuality of such chains of thought. \nTable 9:  Of 50 examples that the model got correct, there were 7 salient cases where the chain of \nthought the model generated was imperfect. We found the other 43 to be equivalent to what a human \nwould potentially generate as a ground truth. \nQ UESTION : There are 36 penguins sunbathing in the snow. One-third of them jump in and swim in the ocean. \nAnother one-third go inside the cave to eat their dinner. How many penguins are still left sunbathing? \nM ODEL A NSWER ( CORRECT BY CHANCE ): There are 36 penguins. One-third of them jump in and swim in \nthe ocean. So that is 12 penguins. Another one-third go inside the cave to eat their dinner. So that is 12 penguins. \nThe answer is 12.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":26,"lines":{"from":1,"to":11}}}}],["54cb2486-e1cc-41a4-a15d-4441fa9e3910",{"pageContent":"The answer is 12. \nQ UESTION : John has 2 houses with 3 bedrooms each.  Each bedroom has 2 windows each.  There are an \nadditional 4 windows in each house not connected to bedrooms. How many total windows are there between the \nhouses? \nM ODEL A NSWER ( CORRECT BUT UNDERSPECIFIED STATEMENTS ): There are 2 houses with 3 bedrooms \neach. Each bedroom has 2 windows each. So there are 2 x 3 = 6 windows in each house. There are an additional \n4 windows in each house not connected to bedrooms. So there are 4 + 4 = 8 windows in each house. So there are \n6 x 2 = 12 windows in each house. So there are 12 + 8 = 20 windows in both houses. The answer is 20. \nQ UESTION : If Ann is 9 years old and her brother is twice her age, how old will her brother be in 3 years? \nM ODEL A NSWER ( CORRECT BUT UNRELATED STATEMENT ): Ann is 9 years old. Her brother is twice her \nage. So her brother is 18 years old. In 3 years, she will be 12. So her brother will be 18 + 3 = 21 years old. The \nanswer is 21.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":26,"lines":{"from":11,"to":22}}}}],["b7f91d8a-f24f-41f0-b450-0ae41a942f9f",{"pageContent":"answer is 21. \nQ UESTION : A local gas station is selling gas for $3.00 a gallon. An app company is offering $.20 cashback per \ngallon if you fill up at this station. If someone buys 10 gallons of gas, how much with their gas be, after the \ncashback rewards? \nM ODEL A NSWER ( CORRECT  BUT  IMPERFECT  EQUATION ): \nThe gas is originally 3 dollars per gallon. If \nyou buy 10 gallons, that is 3 x 10 = 30 dollars. If you get 20 cents off per gallon, that is 20 x 10 = 2 dollars. So \nthe total is 30 - 2 = 28 dollars. The answer is 28 dollars. \nQ UESTION : Nissa hires 60 seasonal workers to play elves in her department store’s Santa village. A third of \nthe elves quit after children vomit on them, then 10 of the remaining elves quit after kids kick their shins. How \nmany elves are left? \nM ODEL A NSWER ( CORRECT  BUT  IMPERFECT  EQUATION ): \nNissa hires 60 seasonal workers.  A third of","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":26,"lines":{"from":22,"to":34}}}}],["cd11dd50-e82e-427b-9823-72c3dfe4774c",{"pageContent":"Nissa hires 60 seasonal workers.  A third of \nthem quit. So 60 - 1/3 = 40 elves are left. Then 10 elves quit. So 40 - 10 = 30 elves are left. The answer is 30 \nelves. \nQ UESTION : Grandma Jones baked 5 apple pies for the fireman’s luncheon. She cut each pie into 8 pieces and \nset the five pies out on the buffet table for the guests to serve themselves. At the end of the evening, after the \nguests had taken and eaten their pieces of pie, there were 14 pieces of pie remaining. How many pieces were \ntaken by the guests? \nM ODEL A NSWER ( CORRECT BUT INVERTED SEMANTICS ): 5 pies were baked and cut into 8 pieces each. \nThe 5 pies were then served to the guests. 8 x 5 = 40 pieces of pie. The guests ate 14 pieces of pie. 40 - 14 = 26 \npieces of pie were left. The answer is 26. X \n26","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":26,"lines":{"from":34,"to":44}}}}],["beb5ca0d-94d5-4175-b29e-3be384f03a6d",{"pageContent":"D.2    Incorrect Chain of Thought Analysis \nWe also manually analyze 50 randomly sampled outputs of the model that were incorrect on GSM8K \nfor LaMDA 137B. There are many ways that a chain of thought can be incorrect, making the design \nof error categorization non-trivial. We decided to categorize errors into what changes are needed to \nmake the chain of thought correct, with the goal of elucidating how the model can be improved in the \nfuture. \nWe found that many chains of thought can be made correct with one of the following three classes of \nmodification. \n• Calculator error only. We found that 8% of the chains of thought were completely correct except \nfor a calculator error—in other words, applying an external calculator to equations, as done in \nCobbe et al. (2021), would make the chain of thought correct. An example of this type of error is \nshown in Table 10: “calculator error only”. Indeed, the solve rate of chain-of-thought prompting","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":27,"lines":{"from":1,"to":12}}}}],["68147395-10a5-41ee-b094-fcb89767c6a5",{"pageContent":"shown in Table 10: “calculator error only”. Indeed, the solve rate of chain-of-thought prompting \non for LaMDA 137B GSM8K went up from 14.3% to 17.3% when we added a Python program \nas an external calculator, as shown in Table 2.  Also, 34% of the examples contained calculator \nerrors in addition to other types of errors. However, we perform the rest of the error categorization \nindependently of calculator errors. \n• Symbol mapping error. We next found that 16% percent of the chains of thought were correct \nexcept for what we call symbol mapping errors. We define a symbol mapping error as when the \nchain of thought is correct except for the number symbols, and it could be made totally correct by \nmodifying only the equations and not the words. As one might argue that they could simply place \nthe correct final equation in any chain of thought, we constrain this category to chains of thought","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":27,"lines":{"from":12,"to":21}}}}],["42216210-c07b-4941-b65d-46490028d8e2",{"pageContent":"where the chain of thought can be modified to be a completely correct reasoning process (not just \nfinal answer). An example of this error category is shown in Table 10: “symbol mapping error”. \n• One step missing error. Our next category of error is chains of thought which were correct except \nthat they were missing a single step. In other words, these chains of thoughts could be rewritten to \nbe correct by adding in an additional reasoning step that was missed by the model. An example of \nthis error category is shown in Table 10: “one step missing error”. We found that 22% percent of \nthe errors fell into this category. \nTable 10:  Example of incorrect chains of thought, categorized as described in Appendix D.2. \nQ UESTION : Dan plants 3 rose bushes. Each rose bush has 25 roses. Each rose has 8 thorns. How many thorns \nare there total? \nM ODEL A NSWER ( INCORRECT ; CALCULATOR ERROR ONLY ): Dan plants 3 rose bushes. Each rose bush","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":27,"lines":{"from":22,"to":32}}}}],["a0b0af3b-b8dd-44cf-91cf-0e0a78fed060",{"pageContent":"M ODEL A NSWER ( INCORRECT ; CALCULATOR ERROR ONLY ): Dan plants 3 rose bushes. Each rose bush \nhas 25 roses. Each rose has 8 thorns. So 3 x 25 x 8 = 300. The answer is 300. 7 \nE XPLANATION  FOR E RROR C ATEGORY : The produced chain of thought could be made correct just by \nrunning the equation through an external calculator, instead of asking the model to do the computation. \nQ UESTION : Jill gets paid $20 per hour to teach and $30 to be a cheerleading coach. If she works 50 weeks a \nyear, 35 hours a week as a teacher and 15 hours a week as a coach, what’s her annual salary? \nM ODEL A NSWER ( INCORRECT ; SYMBOL  MAPPING  ERROR ): \nJill gets paid 20 dollars per hour to teach \nand 30 dollars per hour to be a cheerleading coach. If she works 50 weeks a year, 35 hours a week as a teacher \nand 15 hours a week as a coach, then she works 50 x 35 = 1750 hours as a teacher and 15 x 30 = 450 hours as a","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":27,"lines":{"from":32,"to":41}}}}],["e726dcb7-49ad-41c3-b4f2-d66ab0d05cc7",{"pageContent":"coach. So she works 1750 + 450 = 2200 hours. She gets paid 20 dollars per hour for 1750 hours and 30 dollars \nper hour for 450 hours. So her annual salary is 20 x 1750 + 30 x 450 = $36,500. The answer is $36,500. 7 \nE XPLANATION FOR E RROR C ATEGORY : The model incorrectly mapped “15 x 30” instead of “15 x 50”, and \nthe chain of thought would be made correct by fixing just that one change (with an external calculator). \nQ UESTION : Kelian has two recipes for preparing dishes, one having 20 instructions and the second one having \ntwice as many instructions as the first one. How many instructions does Kelian have to read to prepare the two \ndishes? \nM ODEL A NSWER ( INCORRECT ; ONE STEP MISSING ERROR ): Kelian has two recipes. One has 20 instruc- \ntions. The other has twice as many instructions as the first one. So the second one has 40 instructions. So Kelian \nhas to read 40 instructions to prepare the two dishes. The answer is 40. 7","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":27,"lines":{"from":42,"to":51}}}}],["d2c2e63f-25eb-44ee-b8da-2156eeb50fdb",{"pageContent":"has to read 40 instructions to prepare the two dishes. The answer is 40. 7 \nE XPLANATION FOR E RROR C ATEGORY : The model answer could be made correct just adding one additional \nstep (in this case, adding 20 and 40). \n27","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":27,"lines":{"from":51,"to":54}}}}],["4008810d-5dfd-4e5b-b34e-0c64c8d01694",{"pageContent":"We found that the remaining chains of thought (27 of 50; 54%) would require substantial edits to make \ninto a correct chain of thought. Almost all cases here involved some error in semantic understanding \n(see Table 11: “semantic understanding error”), and 8 of the 27 also had incoherent chain of thoughts, \nmeaning that some statements in the generated chain of thought did not follow from prior ones or \nviolated basic world knowledge (see Table 11: “incoherent chain of thought error”). \nTable 11:   Example of incorrect chains of thought, categorized as described in Appendix D.2. These \nchains of thought had multiple mistakes that could not be fixed with minor edits. \nQ UESTION : Gretchen has 110 coins. There are 30 more gold coins than silver coins. How many gold coins \ndoes Gretchen have? \nM ODEL A NSWER ( INCORRECT ; SEMANTIC  UNDERSTANDING  ERROR ): Gretchen has 110 coins.  There","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":28,"lines":{"from":1,"to":10}}}}],["f9e1f5e5-00d4-4d9b-a94a-ea295f3617fc",{"pageContent":"M ODEL A NSWER ( INCORRECT ; SEMANTIC  UNDERSTANDING  ERROR ): Gretchen has 110 coins.  There \nare 30 more gold coins than silver coins. So there are 110 - 30 = 80 silver coins. So there are 80 silver coins and \n110 - 80 = 30 gold coins. The answer is 30. 7 \nE XPLANATION FOR E RROR C ATEGORY : \nThe model does not understand that 110 coins are in total and that \nit must solve an equation to get the number of gold and silver coins. \nQ UESTION : In a dance class of 20 students, 20% enrolled in contemporary dance, 25% of the remaining \nenrolled in jazz dance, and the rest enrolled in hip-hop dance. What percentage of the entire students enrolled in \nhip-hop dance? \nM ODEL A NSWER ( INCORRECT ; INCOHERENT  CHAIN  OF  THOUGHT  ERROR ): \n20% of the students en- \nrolled in contemporary dance. 25% of the remaining students enrolled in jazz dance. The rest enrolled in hip-hop \ndance.  So the percentage of the entire students enrolled in hip-hop dance is the percentage of the students","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":28,"lines":{"from":10,"to":22}}}}],["b85a8d66-eafd-43f9-81e1-32789323aaa2",{"pageContent":"enrolled in hip-hop dance, minus the percentage of the students enrolled in contemporary dance, minus the \npercentage of the students enrolled in jazz dance. So the percentage of the entire students enrolled in hip-hop \ndance is (25 + 20) - (25 + 20) = 100%. The answer is 100%. 7 \nE XPLANATION  FOR E RROR C ATEGORY : This chain of thought is incoherent in that the percent of entire \nstudents enrolled in hip-hope dance cannot be the percent of student enrolled in hip-hop dance minus another \nterm. \nOverall, there are no guarantees that the reasoning processes generated by large language models \nare coherent or factually correct, as underscored by the recent work evaluating the factuality of \nlanguage model generations and explanations (Maynez et al., 2020; Rashkin et al., 2021; Ye and \nDurrett, 2022; Marasovi \n ́ \nc et al., 2022; Wiegreffe et al., 2022). Incorrect reasoning processes can lead","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":28,"lines":{"from":23,"to":34}}}}],["495a3f0a-3bce-4145-8330-5286f6a641b2",{"pageContent":"́ \nc et al., 2022; Wiegreffe et al., 2022). Incorrect reasoning processes can lead \nto both incorrect final answers as well as accidentally correct final answers (with accidentally correct \nfinal answers being more likely for tasks such as binary classification as opposed to free response). \nImproving the factuality of language model generations with respect to context and world knowledge \nis an important direction open problems in language model research and could also be expected to \npotentially improve multi-step reasoning abilities of language models.  One potential method for \nimproving the quality of decoding could involve generating multiple reasoning paths and scoring \neach of them with a verifier, though this requires training the verifier (Cobbe et al., 2021; Shen et al., \n2021; Thoppilan et al., 2022). \nD.3    Additional Robustness Analysis \nAs the experiments in the main paper use a fixed number of few-shot exemplars (8; as constrained by","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":28,"lines":{"from":33,"to":44}}}}],["432bfd63-85eb-49cf-ade2-2c0d4cf4fa28",{"pageContent":"the input length of 1024 tokens), we verify that the chain-of-thought prompting is robust to various \nnumbers of few-shot exemplars. We run experiments for LaMDA 137B, comparing chain-of-thought \nprompting with standard prompting for the five datasets where standard prompting had a mostly flat \nscaling curve (the largest model did not achieve high performance).  As shown in Figure 11, the \nimprovement of chain-of-thought prompting over standard prompting remains robust to varying the \nnumber of few-shot exemplars in the prompt. \n28","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":28,"lines":{"from":45,"to":51}}}}],["cfc0c0c1-df0c-4d2f-b5e4-3dc0ea51e4d2",{"pageContent":"1 2 4 6 8 \n0 \n5 \n10 \n15 \nSolve rate (%) \nGSM8K \n1 2 4 6 8 \n0 \n20 \n40 \n60 \nMultiArith \n(MAWPS) \n1 2 4 6 8 \n0 \n25 \n50 \n75 \n100 \nNumber of few-shot exemplars \nSports \nUnderstanding \nStandard prompting \nChain of thought prompting \n1 2 4 6 8 \n0 \n25 \n50 \n75 \n100 \nCoin Flip \n1 2 3 4 \n0 \n25 \n50 \n75 \n100 \nLast Letter \nConcatenation \nFigure 11:   The improvement of chain of thought prompting over standard prompting appears robust \nto varying the number of few-shot exemplars in the prompt. \nTable 12:   Summary of math word problem benchmarks we use in this paper with examples. N : \nnumber of evaluation examples. \nDataset N Example problem \nGSM8K 1,319 Josh decides to try flipping a house. He buys a house for $80,000 and then puts \nin $50,000 in repairs.  This increased the value of the house by 150%.  How \nmuch profit did he make? \nSVAMP 1,000 Each pack of dvds costs 76 dollars. If there is a discount of 25 dollars on each \npack. How much do you have to pay to buy each pack?","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":29,"lines":{"from":1,"to":50}}}}],["16695463-ac13-43a5-aea7-3e25bbdc705c",{"pageContent":"pack. How much do you have to pay to buy each pack? \nASDiv 2,096 Ellen has six more balls than Marin. Marin has nine balls. How many balls does \nEllen have? \nAQuA 254 A car is being driven, in a straight line and at a uniform speed, towards the base \nof a vertical tower.  The top of the tower is observed from the car and, in the \nprocess, it takes 10 minutes for the angle of elevation to change from 45 \n◦ \nto 60 \n◦ \n. \nAfter how much more time will this car reach the base of the tower? Answer \nChoices: (a) 5 \n√ \n3 + 1 (b) 6 \n√ \n3 + \n√ \n2 (c) 7 \n√ \n3 - 1 (d) 8 \n√ \n3 - 2 (e) None of these \nMAWPS: SingleOp 562 If there are 7 bottle caps in a box and Linda puts 7 more bottle caps inside, how \nmany bottle caps are in the box? \nMAWPS: SingleEq 508 Benny bought a soft drink for 2 dollars and 5 candy bars. He spent a total of 27 \ndollars. How much did each candy bar cost? \nMAWPS: AddSub 395 There were 6 roses in the vase. Mary cut some roses from her flower garden.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":29,"lines":{"from":50,"to":76}}}}],["0d03c275-751a-4166-9594-822b9c9732e0",{"pageContent":"MAWPS: AddSub 395 There were 6 roses in the vase. Mary cut some roses from her flower garden. \nThere are now 16 roses in the vase. How many roses did she cut? \nMAWPS: MultiArith 600 The school cafeteria ordered 42 red apples and 7 green apples for students \nlunches. But, if only 9 students wanted fruit, how many extra did the cafeteria \nend up with? \n29","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":29,"lines":{"from":76,"to":81}}}}],["4b1c8a96-6023-477d-a120-e2f313a94f2f",{"pageContent":"E    Additional Details \nVersion Control \nV5 → V6 . Fixed minor typo in Figure 3. \nV4 → V5 . Added Codex and UL2 results. Small changes to writing and style of paper. \nV3 → V4 . Fixed typo in Figure 3 and added a couple citations. \nV2 → V3 . Added GPT-3 results. Added SVAMP and AQuA eval datasets for math. Added SayCan \neval for commonsense. Added Extended Related Work section (Appendix C). Added ablations for \nCommonsense and Symbolic Reasoning (Table 7). Added FAQ section (Appendix A). Added raw \nresults in Appendix B. \nV1 → V2 . Added PaLM results (V1 only had LaMDA). \nE.1    Reproducibility Statement \nAs our results make use of two sets of large language models that is not publicly available, we take \nthe following actions to facilitate reproducibility. First, we provide the exact input prompts for all \ntasks in Table 20–Table 27 in Appendix G (and emphasize that we do not perform any finetuning and","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":30,"lines":{"from":1,"to":14}}}}],["689dcc64-ee65-4813-b869-b945e90553b3",{"pageContent":"tasks in Table 20–Table 27 in Appendix G (and emphasize that we do not perform any finetuning and \nonly apply prompting to off-the-shelf language models). Second, we conduct experiments using the \npublicly available GPT-3 API for four model scales text-ada-001, text-babbage-001, text-curie-001, \ntext-davinci-002). Finally, we make exact inputs, targets, and predictions for LaMDA 137B for each \ntask available as a zip file in the supplementary material. \nE.2    Computational Resources \nFor all three language models we evaluated, we did prompting-based inference only. No finetuning \nwas done for this paper. For inference on LaMDA 137B we use TPU v3 (8x8 configuration, 64 chips \n/ 128 cores), and for inference on PaLM 540B we use TPU v4 (4x4x12 configuration, 192 chips / 384 \ncores). GPT-3 experiments were done using the public API. \n5 \nE.3    Dataset Details and Licenses \nWe list the details and licenses for all arithmetic and commonsense datasets used in this paper. The","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":30,"lines":{"from":14,"to":26}}}}],["1a638dc1-474c-4250-a866-ecb4ff70d93f",{"pageContent":"symbolic reasoning datasets were created synthetically, as described in Section 4. \nArithmetic reasoning \n• \nMath  Word  Problem  Repository  (Koncel-Kedziorski  et  al.,  2016):  AddSub  (Hosseini \net al., 2014): https://www.cs.washington.edu/nlp/arithmetic ; MultiArith (Roy \nand Roth, 2015), license: CC BY 4.0. \n•  ASDiv (Miao et al., 2020): https://github.com/chaochun/nlu-asdiv-dataset . \n• \nAQuA (Ling et al., 2017): https://github.com/deepmind/AQuA , license: https:// \ngithub.com/deepmind/AQuA/blob/master/LICENSE . \n• GSM8K  (Cobbe  et  al.,  2021): https://github.com/openai/grade-school-math , \nMIT   license: https://github.com/openai/grade-school-math/blob/master/ \nLICENSE . \n• SVAMP (Patel et al., 2021): https://github.com/arkilpatel/SVAMP , MIT license: \nhttps://github.com/arkilpatel/SVAMP/blob/main/LICENSE . \nCommonsense reasoning \n• CSQA (Talmor et al., 2019): https://www.tau-nlp.org/commonsenseqa , https:// \ngithub.com/jonathanherzig/commonsenseqa . \n5","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":30,"lines":{"from":27,"to":45}}}}],["71bd5777-e2a4-4fe1-a9e9-284309d34158",{"pageContent":"github.com/jonathanherzig/commonsenseqa . \n5 \nhttps://beta.openai.com/docs/api-reference/making-requests \n30","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":30,"lines":{"from":44,"to":47}}}}],["dbbda8f7-37a5-4d5b-9ee6-42d86b6c25ec",{"pageContent":"• StrategyQA  (Geva  et  al.,  2021):   we  use  the  open-domain  setting  (question-only  set) \nfrom  BIG-bench  collaboration  (2021): https://github.com/google/BIG-bench/ \ntree/main/bigbench/benchmark_tasks/strategyqa .  The original dataset is from \nhttps://github.com/eladsegal/strategyqa , MIT license: https://github.com/ \neladsegal/strategyqa/blob/main/LICENSE . \n• Date understanding and sports understanding from BIG-Bench (BIG-bench collaboration, \n2021):  Apache License v.2: https://github.com/google/BIG-bench/blob/main/ \nLICENSE . \n• SayCan (Ahn et al., 2022): SayCan dataset can be accessed at https://say-can.github. \nio/ under CC BY 4.0 license. \n31","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":31,"lines":{"from":1,"to":11}}}}],["1eb587ec-9ae1-46b4-8167-6d1e8643fbed",{"pageContent":"F    Appendix: Input/Output Examples \nTable 13:  Examples of correct and incorrect chains of thought produced by LaMDA 137B on the \nletter concatenation task. \nQ UESTION : Take the last letters of the words in “Waldo Schmidt” and concatenate them. \nM ODEL A NSWER (CORRECT): The last letter of “Waldo” is “o”.   The last letter of “Schmidt” is “t”. \nConcatenating them is “ot”. So the answer is ot. X \nQ UESTION : Take the last letters of the words in “Daniel Friedman” and concatenate them. \nM ODEL A NSWER (INCORRECT): The last letter of “Daniel” is “l”. The last letter of “Friedman” is “m”. \nConcatenating them is “lm”. So the answer is lm. 7 \nTable 14:  Examples of correct and incorrect chains of thought produced by LaMDA 137B on the \ncoinflip task. \nQ UESTION : A coin is heads up. Andree flips the coin. Audrie does not flip the coin. Is the coin still heads up? \nM ODEL A NSWER (CORRECT): The coin was flipped by Andree. So the coin was flipped 1 time, which is","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":32,"lines":{"from":1,"to":13}}}}],["16918ee6-5c93-4abf-9f20-00c4ab550e5f",{"pageContent":"M ODEL A NSWER (CORRECT): The coin was flipped by Andree. So the coin was flipped 1 time, which is \nan odd number. The coin started heads up, so after an odd number of flips, it will be tails up. So the answer is no. \nX \nQ UESTION : A coin is heads up. Kristian does not flip the coin. Dallas does not flip the coin. Is the coin still \nheads up? \nM ODEL A NSWER (INCORRECT): \nThe coin was flipped by Kristian. So the coin was flipped 1 time, which \nis an odd number. The coin started heads up, so after an odd number of flips, it will be tails up. So the answer is \nno. 7 \nTable 15:   Examples of correct and incorrect chains of thought produced by LaMDA 137B on CSQA. \nQ UESTION : When a person is beginning work, what are they building? \nAnswer Choices: (a) time (b) accomplishing (c) working (d) momentum (e) tiredness \nM ODEL A NSWER (CORRECT): The answer must be something that is built.  Of the above choices, only \nmomentum is built. So the answer is (d). X","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":32,"lines":{"from":13,"to":26}}}}],["1f3aed63-0edf-4953-9622-c8882551bb47",{"pageContent":"momentum is built. So the answer is (d). X \nQ UESTION : Where are you likely to find a hamburger? \nAnswer Choices: (a) fast food restaurant (b) pizza (c) ground up dead cows (d) mouth (e) cow carcus \nM ODEL A NSWER (CORRECT): The answer must be a place where hamburgers are found.  Of the above \nchoices, only fast food restaurants serve hamburgers. So the answer is (a). X \nQ UESTION : Aside from water and nourishment what does your dog need? \nAnswer Choices: (a) bone (b) charm (c) petted (d) lots of attention (e) walked \nM ODEL A NSWER (INCORRECT): \nThe answer must be something that a dog needs. Of the above choices, \nonly bone is something that a dog needs. So the answer is (a). 7 (Ground truth is (d).) \nQ UESTION : What are you waiting alongside with when you’re in a reception area? \nAnswer Choices: (a) motel (b) chair (c) hospital (d) people (e) hotels \nM ODEL A NSWER (INCORRECT): \nThe answer must be something that is waiting with you in a reception","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":32,"lines":{"from":26,"to":39}}}}],["aeaa313d-32e6-41b1-a58f-5f5308a3bb6b",{"pageContent":"M ODEL A NSWER (INCORRECT): \nThe answer must be something that is waiting with you in a reception \narea. Of the above choices, only people are waiting with you in a reception area. So the answer is (e). 7 (Ground \ntruth is (d).) \n32","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":32,"lines":{"from":38,"to":42}}}}],["bc8a2c4a-c399-40ca-8355-03c15a4df224",{"pageContent":"Table 16:    Examples of correct and incorrect chains of thought produced by LaMDA 137B on \nStrategyQA. \nQ UESTION : Will The Exorcist stimulate limbic system? \nM ODEL A NSWER (CORRECT): \nThe Exorcist is a horror movie. Horror movies are scary. The limbic system \nis involved in fear. Thus, The Exorcist will stimulate the limbic system. So the answer is yes. X \nQ UESTION : Was Jackson Pollock trained by Leonardo da Vinci? \nM ODEL A NSWER (CORRECT): Leonardo da Vinci lived in the 15th century. Jackson Pollock lived in the \n20th century. Thus, Jackson Pollock could not have been trained by Leonardo da Vinci. So the answer is no. X \nQ UESTION : Can Harry Potter book a flight on Asiana Airlines? \nM ODEL A NSWER (INCORRECT): Harry Potter is a fictional character. Thus, Harry Potter can do anything. \nSo the answer is yes. 7 (Ground truth is “no”.) \nQ UESTION : Would a sophist use an épée? \nM ODEL A NSWER (INCORRECT): A sophist is a person who is skilled in the art of persuasion. An épée is","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":33,"lines":{"from":1,"to":14}}}}],["098a15e0-8e84-4bda-a265-a7a6ced5a8f3",{"pageContent":"a type of sword. Thus, a sophist could use an épée. So the answer is yes. 7 (Ground truth is “no”.) \nTable 17:  Examples of correct and incorrect chains of thought produced by LaMDA 137B on Date \nUnderstanding. \nQ UESTION : May 6, 1992 is like yesterday to Jane, but that is actually ten years ago. What is the date a month \nago in MM/DD/YYYY? \nM ODEL A NSWER (CORRECT): May 6, 1992 is ten years ago, so today is May 6, 2002. So a month ago will \nbe April 6, 2002. So the answer is 04/06/2002. X \nQ UESTION : This is the last day of 1899. What is the date 24 hours later in MM/DD/YYYY? \nM ODEL A NSWER (CORRECT): Today is 12/31/1899. 24 hours later will be 01/01/1900. So the answer is \n01/01/1900. X \nQ UESTION : Jane scheduled 3 apointments with 5 poeple for tomorrow (Tue, 7/9/1972). What is the date one \nweek ago from today in MM/DD/YYYY? \nM ODEL A NSWER (INCORRECT): Tomorrow is 7/9/1972. One week ago from today is 7/2/1972. So the \nanswer is 7/2/1972. 7 (Ground truth is 07/01/1972.)","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":33,"lines":{"from":15,"to":28}}}}],["8494954e-889d-4e7a-9dc2-c24b9173738f",{"pageContent":"answer is 7/2/1972. 7 (Ground truth is 07/01/1972.) \nQ UESTION : Today is the palindrome day of 2020, because the MMDDYYYY format of the date is the same \nbackwards as forwards. What is the date tomorrow in MM/DD/YYYY? \nM ODEL A NSWER (INCORRECT): Today is 02/29/2020. Tomorrow will be 03/01/2020. So the answer is \n03/01/2020. 7 (Ground truth is “02/03/2020”.) \nTable 18:   Examples of correct and incorrect chains of thought produced by LaMDA 137B on Sports \nUnderstanding. \nQ UESTION : Is the following sentence plausible? “Joao Moutinho was out at third.” \nM ODEL A NSWER (CORRECT): Joao Moutinho is a soccer player. Being out at third is part of baseball, not \nsoccer. So the answer is no. X \nQ UESTION : Is the following sentence plausible?  “Malcolm Brogdon eurostepped to the basket in the NBA \nChampionship.” \nM ODEL A NSWER (CORRECT): Malcolm Brogdon is a basketball player. Eurostepping to the basket is part \nof basketball. So the answer is yes. X","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":33,"lines":{"from":28,"to":41}}}}],["a7c24704-f52e-42cf-ab36-dde214729a3b",{"pageContent":"of basketball. So the answer is yes. X \nQ UESTION : Is the following sentence plausible? “Derrick White backhanded a shot.” \nM ODEL A NSWER (INCORRECT): Derrick White is a basketball player.  Backhanding a shot is part of \nbasketball. So the answer is yes. 7 (Ground truth is “no”, backhanding a shot is part of hockey.) \nQ UESTION : Is the following sentence plausible? “Nazem Kadri was out at home.” \nM ODEL A NSWER (INCORRECT): Nazem Kadri is a hockey player. Being out at home is part of hockey. \nSo the answer is yes. 7 (Ground truth is “no”, being out at home is part of baseball.) \n33","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":33,"lines":{"from":41,"to":48}}}}],["531da685-4c31-4483-80f6-d6ed4204afe6",{"pageContent":"Table 19:   Examples of correct and incorrect chains of thought produced by PaLM 540B on SayCan \nrobot planning tasks. \nQ UESTION : I spilled my coke on the table, could you throw it away and then bring me something to help clean? \nM ODEL A NSWER (CORRECT): Explanation: The user has spilled their coke on the table. I will throw away \nthe coke and then bring the user a sponge. Plan: find(coke), pick(coke), find(trash), put(coke), find(sponge), \npick(sponge), find(table), put(sponge). X \nQ UESTION : Could you compost that apple for me? \nM ODEL A NSWER (CORRECT): Explanation: The user would like me to compost the apple. I will move the \napple to the compost. Plan: find(apple), pick(apple), find(trash), put(apple). X \nQ UESTION : Can you bring me a drink that is not coke? \nM ODEL A NSWER (INCORRECT): Explanation: The user asked me to bring a drink that is not coke, I will \nbring a sprite. Plan: find(sprite), pick(sprite), find(user), put(sprite). 7 (Feasible answers including finding lime","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":34,"lines":{"from":1,"to":12}}}}],["29f1a772-cfca-4df4-aad9-c065d13c7bbd",{"pageContent":"soda, pepsi, grapefruit soda or water, because there is no sprite in the scene as defined in Table 28.) \nQ UESTION : Can you bring me something salty? \nM ODEL A NSWER (INCORRECT): Explanation: The user would like something salty.  There are several \noptions in the objects list, so I will bring the user a lime soda. Plan: find(lime soda), pick(lime soda), find(user), \nput(lime soda). 7 (Feasible answers including finding chips. The model misidentify lime soda as salty.) \n34","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":34,"lines":{"from":13,"to":18}}}}],["432b1704-5f1e-4de8-ab9d-489223cf653b",{"pageContent":"G    Appendix: Full Prompts \nTable 20:   Few-shot exemplars for full chain of thought prompt for math word problems. This set of \nexemplars was used for all math word problem datasets except AQuA. \nP ROMPT FOR M ATH W ORD P ROBLEMS \nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there \nwill be 21 trees. How many trees did the grove workers plant today? \nA: There are 15 trees orig i nally. Then there were 21 trees af ter some more were planted. So there must have \nbeen 21 - 15 = 6. The answer is 6. \nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot? \nA: \nThere are orig i nally 3 cars. 2 more cars ar rive. 3 + 2 = 5. The answer is 5. \nQ: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total? \nA: Orig i nally, Leah had 32 choco lates. Her sis ter had 42. So in to tal they had 32 + 42 = 74. Af ter eat ing 35, they","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":35,"lines":{"from":1,"to":13}}}}],["cb4fa791-40db-44af-b601-2c50a147d6ac",{"pageContent":"had 74 - 35 = 39. The answer is 39. \nQ: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did \nJason give to Denny? \nA: \nJa son started with 20 lol lipops. Then he had 12 af ter giv ing some to Denny. So he gave Denny 20 - 12 = 8. \nThe answer is 8. \nQ: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he \nhave now? \nA: Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9. \nThe answer is 9. \nQ: There were nine computers in the server room. Five more computers were installed each day, from monday \nto thursday. How many computers are now in the server room? \nA: There were orig i nally 9 com put ers. For each of 4 days, 5 more com put ers were added. So 5 * 4 = 20 \ncom put ers were added. 9 + 20 is 29. The answer is 29. \nQ: \nMichael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":35,"lines":{"from":14,"to":29}}}}],["f41ab95d-d12a-40f1-a150-5c431bc2b0a0",{"pageContent":"balls did he have at the end of wednesday? \nA: Michael started with 58 golf balls. Af ter los ing 23 on tues day, he had 58 - 23 = 35. Af ter los ing 2 more, he \nhad 35 - 2 = 33 golf balls. The answer is 33. \nQ: Olivia has $23. She bought five bagels for $3 each. How much money does she have left? \nA: Olivia had 23 dol lars. 5 bagels for 3 dol lars each will be 5 x 3 = 15 dol lars. So she has 23 - 15 dol lars left. 23 \n- 15 is 8. The answer is 8. \n35","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":35,"lines":{"from":30,"to":36}}}}],["01649888-9ad4-43ac-a282-e708de15ef7b",{"pageContent":"Table 21:  Few-shot exemplars for full chain of thought prompt for AQuA. \nP ROMPT FOR AQ U A ALGEBRAIC WORD PROBLEMS \nQ: John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers \nis? \nAnswer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64 \nA: If 10 is added to each num ber, then the mean of the num bers also in creases by 10. So the new mean would be \n50. The answer is (a). \nQ: If a / b = 3/4 and 8a + 5b = 22,then find the value of a. \nAnswer Choices: (a) 1/2 (b) 3/2 (c) 5/2 (d) 4/2 (e) 7/2 \nA: \nIf a / b = 3/4, then b = 4a / 3. So 8a + 5(4a / 3) = 22. This sim pli fies to 8a + 20a / 3 = 22, which means 44a / 3 \n= 22. So a is equal to 3/2. The answer is (b). \nQ: A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then find the distance? \nAnswer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km \nA: The dis tance that the per son trav eled would have been 20 km/hr * 2.5 hrs = 50 km. The answer is (e).","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":36,"lines":{"from":1,"to":15}}}}],["c3b6ddf5-bb8f-410d-92d8-a1cc80e4b3d6",{"pageContent":"Q: How many keystrokes are needed to type the numbers from 1 to 500? \nAnswer Choices: (a) 1156 (b) 1392 (c) 1480 (d) 1562 (e) 1788 \nA: There are 9 one - digit num bers from 1 to 9. There are 90 two - digit num bers from 10 to 99. There are 401 \nthree - digit num bers from 100 to 500. 9 + 90(2) + 401(3) = 1392. The answer is (b). \nTable 22:  Few-shot exemplars for full chain of thought prompt for the last letter concatenation task. \nP ROMPT FOR L AST L ETTER C ONCATENATION \nQ: Take the last letters of the words in \"Elon Musk\" and concatenate them. \nA: The last let ter of \"Elon\" is \"n\". The last let ter of \"Musk\" is \"k\". Con cate nat ing them is \"nk\". The answer is nk. \nQ: Take the last letters of the words in \"Larry Page\" and concatenate them. \nA: The last let ter of \"Larry\" is \"y\". The last let ter of \"Page\" is \"e\". Con cate nat ing them is \"ye\". The answer is ye. \nQ: Take the last letters of the words in \"Sergey Brin\" and concatenate them. \nA:","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":36,"lines":{"from":16,"to":27}}}}],["e0f21b0c-5674-4092-9885-5ee454b2dfc2",{"pageContent":"Q: Take the last letters of the words in \"Sergey Brin\" and concatenate them. \nA: \nThe last let ter of \"Sergey\" is \"y\". The last let ter of \"Brin\" is \"n\". Con cate nat ing them is \"yn\". The answer is \nyn. \nQ: Take the last letters of the words in \"Bill Gates\" and concatenate them. \nA: The last let ter of \"Bill\" is \"l\". The last let ter of \"Gates\" is \"s\". Con cate nat ing them is \"ls\". The answer is ls. \n36","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":36,"lines":{"from":26,"to":32}}}}],["e33b4213-26ac-4247-9853-7113cc6c29df",{"pageContent":"Table 23:  Few-shot exemplars for full chain of thought prompt for the coinflip task. \nP ROMPT FOR C OIN F LIP \nQ: Q: A coin is heads up. Ka flips the coin. Sherrie flips the coin. Is the coin still heads up? \nA: \nThe coin was flipped by Ka and Sher rie. So the coin was flipped 2 times, which is an even num ber. The coin \nstarted heads up, so af ter an even num ber of flips, it will still be heads up. So the answer is yes. \nQ: A coin is heads up. Jamey flips the coin. Teressa flips the coin. Is the coin still heads up? \nA: The coin was flipped by Jamey and Ter essa. So the coin was flipped 2 times, which is an even num ber. The \ncoin started heads up, so af ter an even num ber of flips, it will still be heads up. So the answer is yes. \nQ: A coin is heads up. Maybelle flips the coin. Shalonda does not flip the coin. Is the coin still heads up? \nA: The coin was flipped by May belle. So the coin was flipped 1 time, which is an odd num ber. The coin started","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":37,"lines":{"from":1,"to":11}}}}],["0558e601-ee1c-4661-9903-0c5ac9dffc0d",{"pageContent":"heads up, so af ter an odd num ber of flips, it will be tails up. So the answer is no. \nQ: A coin is heads up. Millicent does not flip the coin. Conception flips the coin. Is the coin still heads up? \nA: The coin was flipped by Con cep tion. So the coin was flipped 1 time, which is an odd num ber. The coin \nstarted heads up, so af ter an odd num ber of flips, it will be tails up. So the answer is no. \nQ: A coin is heads up. Sal flips the coin. Raymond does not flip the coin. Is the coin still heads up? \nA: \nThe coin was flipped by Sal. So the coin was flipped 1 time, which is an odd num ber. The coin started heads \nup, so af ter an odd num ber of flips, it will be tails up. So the answer is no. \nQ: A coin is heads up. Conception flips the coin. Kristian does not flip the coin. Is the coin still heads up? \nA: The coin was flipped by Con cep tion. So the coin was flipped 1 time, which is an odd num ber. The coin","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":37,"lines":{"from":12,"to":21}}}}],["60eafbcc-ae4d-4749-a1c3-4facf855affc",{"pageContent":"started heads up, so af ter an odd num ber of flips, it will be tails up. So the answer is no. \nQ: A coin is heads up. Inga does not flip the coin. Elanor does not flip the coin. Is the coin still heads up? \nA: The coin was flipped by no one. So the coin was flipped 0 times. The coin started heads up, and it was not \nflipped, so it is still heads up. So the answer is yes. \nQ: A coin is heads up. Ryan flips the coin. Shaunda flips the coin. Is the coin still heads up? \nA: The coin was flipped by Ryan and Shaunda. So the coin was flipped 2 times, which is an even num ber. The \ncoin started heads up, so af ter an even num ber of flips, it will still be heads up. So the answer is yes. \n37","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":37,"lines":{"from":22,"to":29}}}}],["a2d33598-3aa0-4230-a2c8-7dbc11182cb5",{"pageContent":"Table 24:    Few-shot exemplars for full chain of thought prompt for CSQA. There are newlines \nbetween the answer choices that are omitted in the table for space reasons. \nP ROMPT FOR CSQA \nQ: What  do  people  use  to  absorb  extra  ink  from  a  fountain  pen?   Answer  Choices:  (a)  shirt  pocket  (b) \ncalligrapher’s hand (c) inkwell (d) desk drawer (e) blotter \nA: The an swer must be an item that can ab sorb ink. Of the above choices, only blot ters are used to ab sorb ink. \nSo the answer is (e). \nQ: What home entertainment equipment requires cable? \nAnswer Choices: (a) radio shack (b) substation (c) television (d) cabinet \nA: The an swer must re quire ca ble. Of the above choices, only tele vi sion re quires ca ble. So the answer is (c). \nQ: \nThe fox walked from the city into the forest, what was it looking for? Answer Choices: (a) pretty flowers (b) \nhen house (c) natural habitat (d) storybook","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":38,"lines":{"from":1,"to":13}}}}],["dff395f0-6051-497a-a35c-b87b7f02ee42",{"pageContent":"hen house (c) natural habitat (d) storybook \nA: The an swer must be some thing in the for est. Of the above choices, only nat u ral habi tat is in the for est. So the \nanswer is (b). \nQ: Sammy wanted to go to where the people were. Where might he go? Answer Choices: (a) populated areas \n(b) race track (c) desert (d) apartment (e) roadblock \nA: \nThe an swer must be a place with a lot of peo ple. Of the above choices, only pop u lated ar eas have a lot of \npeo ple. So the answer is (a). \nQ: Where do you put your grapes just before checking out? Answer Choices: (a) mouth (b) grocery cart (c)super \nmarket (d) fruit basket (e) fruit market \nA: The an swer should be the place where gro cery items are placed be fore check ing out. Of the above choices, \ngro cery cart makes the most sense for hold ing gro cery items. So the answer is (b). \nQ: Google Maps and other highway and street GPS services have replaced what? Answer Choices: (a) united \nstates (b) mexico (c) countryside (d) atlas","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":38,"lines":{"from":13,"to":26}}}}],["4cd05642-1229-4010-beab-6ee3b8ae866c",{"pageContent":"states (b) mexico (c) countryside (d) atlas \nA: The an swer must be some thing that used to do what Google Maps and GPS ser vices do, which is to give \ndi rec tions. Of the above choices, only at lases are used to give di rec tions. So the answer is (d). \nQ: Before getting a divorce, what did the wife feel who was doing all the work? Answer Choices: (a) harder (b) \nanguish (c) bitterness (d) tears (e) sadness \nA: The an swer should be the feel ing of some one get ting di vorced who was do ing all the work. Of the above \nchoices, the clos est feel ing is bit ter ness. So the answer is (c). \n38","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":38,"lines":{"from":26,"to":33}}}}],["edb3f527-b3c8-443b-8a01-b962efbec6dc",{"pageContent":"Table 25:  Few-shot exemplars for full chain of thought prompt for StrategyQA. \nP ROMPT FOR S TRATEGY QA \nQ: Do hamsters provide food for any animals? \nA: Ham sters are prey an i mals. Prey are food for preda tors. Thus, ham sters pro vide food for some an i mals. So \nthe answer is yes. \nQ: Could Brooke Shields succeed at University of Pennsylvania? \nA: Brooke Shields went to Prince ton Uni ver sity. Prince ton Uni ver sity is about as aca dem i cally rig or ous as the \nUni ver sity of Penn syl va nia. Thus, Brooke Shields could also suc ceed at the Uni ver sity of Penn syl va nia. So the \nanswer is yes. \nQ: Yes or no: Hydrogen’s atomic number squared exceeds number of Spice Girls? \nA: Hy dro gen has an atomic num ber of 1. 1 squared is 1. There are 5 Spice Girls. Thus, Hy dro gen’s atomic \nnum ber squared is less than 5. So the answer is no. \nQ: Yes or no: Is it common to see frost during some college commencements?","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":39,"lines":{"from":1,"to":13}}}}],["fc8e73c0-b950-4ee4-9d28-d94c3f2146db",{"pageContent":"Q: Yes or no: Is it common to see frost during some college commencements? \nA: Col lege com mence ment cer e monies can hap pen in De cem ber, May, and June. De cem ber is in the win ter, so \nthere can be frost. Thus, there could be frost at some com mence ments. So the answer is yes. \nQ: Yes or no: Could a llama birth twice during War in Vietnam (1945-46)? \nA: \nThe War in Viet nam was 6 months. The ges ta tion pe riod for a llama is 11 months, which is more than 6 \nmonths. Thus, a llama could not give birth twice dur ing the War in Viet nam. So the answer is no. \nQ: Yes or no: Would a pear sink in water? \nA: The den sity of a pear is about 0 . 6 g/cm \n3 \n, which is less than wa ter. Ob jects less dense than wa ter float. Thus, \na pear would float. So the answer is no. \nTable 26:  Few-shot exemplars for full chain of thought prompt for Date Understanding. \nP ROMPT FOR D ATE U NDERSTANDING \nQ: 2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY?","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":39,"lines":{"from":13,"to":27}}}}],["1e5912ef-5113-4b6d-b592-48155ea9fff5",{"pageContent":"Q: 2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY? \nA: If 2015 is com ing in 36 hours, then it is com ing in 2 days. 2 days be fore 01/01/2015 is 12/30/2014, so to day \nis 12/30/2014. So one week from to day will be 01/05/2015. So the answer is 01/05/2015. \nQ: The first day of 2019 is a Tuesday, and today is the first Monday of 2019.  What is the date today in \nMM/DD/YYYY? \nA: If the first day of 2019 was Tues day, then 01/01/2019 was a Tues day. To day is the first mon day, would be six \ndays later. So to day is 01/07/2019. So the answer is 01/07/2019. \nQ: \nThe concert was scheduled to be on 06/01/1943, but was delayed by one day to today. What is the date 10 \ndays ago in MM/DD/YYYY? \nA: One day af ter 06/01/1943 is 06/02/1943, so to day is 06/02/1943. 10 days be fore to day is 05/23/1943. So the \nanswer is 05/23/1943. \nQ: It is 4/19/1969 today. What is the date 24 hours later in MM/DD/YYYY?","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":39,"lines":{"from":27,"to":39}}}}],["de2ce809-4529-4282-8d44-ec5d3bb46b58",{"pageContent":"answer is 05/23/1943. \nQ: It is 4/19/1969 today. What is the date 24 hours later in MM/DD/YYYY? \nA: To day is 04/19/1969. 24 hours later is one day af ter to day, which would be 04/20/1969. So the answer is \n04/20/1969. \nQ: Jane thought today is 3/11/2002, but today is in fact Mar 12, which is 1 day later. What is the date 24 hours \nlater in MM/DD/YYYY? \nA: To day is 03/12/2002. So the date 24 hours later will be 03/13/2002. So the answer is 03/13/2002. \nQ: Jane was born on the last day of Feburary in 2001.  Today is her 16-year-old birthday.  What is the date \nyesterday in MM/DD/YYYY? \nA: The last day of Febru ary is the 28th, so Jane was born on 02/28/2001. To day is her 16 - year old birth day, so \nto day is 02/28/2017. So yes ter day was 02/27/2017. So the answer is 02/27/2017. \n39","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":39,"lines":{"from":38,"to":49}}}}],["f2948f36-b1b9-4805-954d-c9dbf194347c",{"pageContent":"Table 27:  Few-shot exemplars for full chain of thought prompt for Sports Understanding. \nP ROMPT FOR S PORTS U NDERSTANDING \nQ: Is the following sentence plausible? “Kyle Palmieri was called for slashing.” \nA: \nKyle Palmieri is a hockey player. Be ing called for slash ing is part of hockey. So the answer is yes. \nQ: Is the following sentence plausible? “Joao Moutinho caught the screen pass in the NFC championship.” \nA: Joao Moutinho is a soc cer player. The NFC cham pi onship is part of Amer i can foot ball, not soc cer. So the \nanswer is no. \nQ: Is the following sentence plausible? “Carson Wentz set the pick and roll.” \nA: Car son Wentz is an Amer i can foot ball player. Pick and roll is part of bas ket ball, not foot ball. So the answer \nis no. \nQ: Is the following sentence plausible? “Jonas Valanciunas beat the buzzer.” \nA: Jonas Valan ci u nas is a bas ket ball player. Beat ing the buzzer is part of bas ket ball. So the answer is yes.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":40,"lines":{"from":1,"to":13}}}}],["0d407f55-9375-479e-a8e6-27caaf5b19bb",{"pageContent":"Q: Is the following sentence plausible? “Jamel Murray was perfect from the line.” \nA: \nJa mal Mur ray is a bas ket ball player. Be ing per fect from the line is part of bas ket ball. So the answer is yes. \nQ: Is the following sentence plausible? “Sam Darnold passed the puck.” \nA: \nSam Darnold is a Amer i can foot ball player. Pass ing the puck is part of hockey, not Amer i can foot ball. So the \nanswer is no. \nQ: Is the following sentence plausible? “Draymond Green threw a touchdown.” \nA: Dray mond Green is an bas ket ball player. Throw ing a touch down is part of foot ball, not bas ket ball. So the \nanswer is no. \nQ: Is the following sentence plausible? “Malcolm Brogdon banked the shot in.” \nA: Mal colm Brog don is a bas ket ball player. Bank ing the shot in is part of bas ket ball. So the answer is yes. \n40","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":40,"lines":{"from":14,"to":26}}}}],["3223d207-a446-4fa4-bd10-c44df7bcd8c1",{"pageContent":"Table 28:  Few-shot exemplars for full chain of thought prompt for SayCan robot planning tasks. \nP ROMPT FOR S AY C AN R OBOT P LANNING \nLocations = [counter, table, user, trash, bowl]. \nObjects = [7up, apple, kettle chips, tea, multigrain chips, coke, lime soda, jalapeno chips, rice chips, orange, \ngrapefruit soda, pepsi, redbull, energy bar, sponge, water]. \nThe robot can pick up items with pick(object) and put down items with put(object) as well as find objects or \nlocations with find(). The robot can only understand the explicit locations and objects listed. \nHuman : I’m hungry, can you bring me some chips. \nExplanation : The user is hun gry and has asked for chips. There are sev eral types of chips avail able, I will bring \nthe user the ket tle chips. \nPlan : 1. find(kettle chips), 2. pick(kettle chips), 3. find(user), 4. put(kettle chips), 5. done(). \nHuman : How would you move the grapefruit drink from the table to the counter?","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":41,"lines":{"from":1,"to":12}}}}],["8304525d-4a2a-46d3-b58d-a20d80cd1eeb",{"pageContent":"Human : How would you move the grapefruit drink from the table to the counter? \nExplanation : The user has asked me to move the grape fruit drink to the counter. \nPlan : 1. find(grapefruit soda), 2. pick(grapefruit soda), 3. find(counter), 4. put(grapefruit soda), 5. done(). \nHuman : How would you bring me some snacks? \nExplanation : The user has asked for snacks, I will choose two items and bring them. I will bring jalapeno chips \nand an ap ple. \nPlan : 1. find(jalapeno chips), 2. pick(jalapeno chips), 3. find(user), 4. put(jalapeno chips), 5. find(apple), 6. \npick(apple), 7. find(user), 8. put(apple), 9. done(). \nHuman : How would you bring me something to eat that isn’t a fruit? \nExplanation : The user has asked for a food that isn’t a fruit, I will bring an en ergy bar to them. \nPlan : 1. find(energy bar), 2. pick(energy bar), 3. find(user), 4. put(energy bar), 5. done(). \nHuman : How would you put the rice chips in the bowl and then move the tea to the table? \nExplanation :","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":41,"lines":{"from":12,"to":24}}}}],["7b8ccdaf-4eb5-4b36-b4aa-a05325e3f9a9",{"pageContent":"Explanation : \nThe user has asked me to do two tasks, I will do one and then the other. \nPlan :  1.  find(rice chips), 2.  pick(rice chips), 3.  find(bowl), 4.  put(rice chips), 5.  find(tea), 6.  pick(tea), 7. \nfind(table), 8. put(tea), 9. done(). \nHuman : How would you throw away a redbull? \nExplanation : The user has asked me to throw away the red bull, I will move it to the trash. \nPlan : 1. find(redbull), 2. pick(redbull), 3. find(trash), 4. put(redbull), 5. done(). \nHuman : Bring me a drink. \nExplanation : The user has asked for a drink and there are many op tions. I will bring them a wa ter. \nPlan : 1. find(water), 2. pick(water), 3. find(user), 4. put(water), 5. done(). \n41","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":41,"lines":{"from":24,"to":34}}}}],["7d1612d5-ad29-45b3-b0b1-7731f73b6410",{"pageContent":"H    Appendix: Alternate Annotators for MWP \nTable 29:   Few-shot exemplars for full chain of thought prompt for math word problems.  These \nexemplars are the same as in Table 20, except that the chains of thought were written by a different \nannotator (“Annotator B” instead of “Annotator A”). Annotators were co-authors and familiar with \nthe goal of chain of thought prompting. \nP ROMPT FOR M ATH W ORD P ROBLEMS \nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there \nwill be 21 trees. How many trees did the grove workers plant today? \nA: \nThere are 21 trees now and there are 15 trees in the be gin ning, so the work ers plant 21 - 15 = 6 trees. The \nanswer is 6. \nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot? \nA: There are 3 cars in the be gin ning, 2 more ar rive, so now there should be 3 + 2 = 5 cars. The answer is 5.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":42,"lines":{"from":1,"to":13}}}}],["d7378e9e-340e-48ca-96aa-27e30b8d926c",{"pageContent":"Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total? \nA: Leah had 32 choco lates and her sis ter had 42, in to tal they have 32 + 42 = 74 choco lates. Af ter they ate 35, \nnow there are 74 - 35 = 39 choco lates. The answer is 39. \nQ: \nJason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did \nJason give to Denny? \nA: Ja son started with 20 lol lipops, but now he only has 12, so he gave Denny 20 - 12 = 8 lol lipops. The answer \nis 8. \nQ: \nShawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he \nhave now? \nA: Shawn got 2 toys each from his mom and dad, so he got 2 * 2 = 4 more, now he will have 5 + 4 = 9 toys. The \nanswer is 9. \nQ: There were nine computers in the server room. Five more computers were installed each day, from monday \nto thursday. How many computers are now in the server room?","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":42,"lines":{"from":14,"to":28}}}}],["8732565c-7c70-41c2-a7c9-831fcd88f8f2",{"pageContent":"to thursday. How many computers are now in the server room? \nA: 5 com put ers were in stalled from mon day to thurs day, so in to tal 5 * 4 = 20 com put ers are in stalled. 9 \ncom put ers are there in the be gin ning, so now there are 20 + 9 = 29 com put ers. The answer is 29. \nQ: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf \nballs did he have at the end of wednesday? \nA: Michael started with 58 golf balls and lost 23, so he has 58 - 23 = 35. Af ter he lost 2 more, he has 35 - 2 = 33 \nballs now. The answer is 33. \nQ: Olivia has $23. She bought five bagels for $3 each. How much money does she have left? \nA: 5 bagels for $3 each should cost 5 * 3 = 15 dol lars. Olivia had $23 in the be gin ning, so now she has 23 - 15 = \n8 dol lars left. The answer is 8. \n42","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":42,"lines":{"from":28,"to":38}}}}],["aaf7dce1-5b7d-485c-be93-c7c464964aa7",{"pageContent":"Table 30:   Few-shot exemplars for full chain of thought prompt for math word problems.  These \nexemplars are the same as in Table 20, except that the chains of thought were written by a different \nannotator (“Annotator C” instead of “Annotator A”). \nP ROMPT FOR M ATH W ORD P ROBLEMS \nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there \nwill be 21 trees. How many trees did the grove workers plant today? \nA: We start with 15 trees. Later we have 21 trees. The dif fer ence must be the num ber of trees they planted. So, \nthey must have planted 21 - 15 = 6 trees. The answer is 6. \nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot? \nA: There are 3 cars in the park ing lot al ready. 2 more ar rive. Now there are 3 + 2 = 5 cars. The answer is 5. \nQ: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":43,"lines":{"from":1,"to":11}}}}],["9fdd0133-5403-4605-9afe-8ebcbfea3269",{"pageContent":"A: Leah had 32 choco lates and Leah’s sis ter had 42. That means there were orig i nally 32 + 42 = 74 choco lates. \n35 have been eaten. So in to tal they still have 74 - 35 = 39 choco lates. The answer is 39. \nQ: \nJason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did \nJason give to Denny? \nA: \nJa son had 20 lol lipops. Since he only has 12 now, he must have given the rest to Denny. The num ber of \nlol lipops he has given to Denny must have been 20 - 12 = 8 lol lipops. The answer is 8. \nQ: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he \nhave now? \nA: \nHe has 5 toys. He got 2 from mom, so af ter that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so in \nto tal he has 7 + 2 = 9 toys. The answer is 9. \nQ: There were nine computers in the server room. Five more computers were installed each day, from monday \nto thursday. How many computers are now in the server room?","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":43,"lines":{"from":12,"to":26}}}}],["94ad819f-9219-473b-b140-d245b205f949",{"pageContent":"to thursday. How many computers are now in the server room? \nA: There are 4 days from mon day to thurs day. 5 com put ers were added each day. That means in to tal 4 * 5 = 20 \ncom put ers were added. There were 9 com put ers in the be gin ning, so now there are 9 + 20 = 29 com put ers. The \nanswer is 29. \nQ: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf \nballs did he have at the end of wednesday? \nA: \nMichael ini tially had 58 balls. He lost 23 on Tues day, so af ter that he has 58 - 23 = 35 balls. On Wednes day \nhe lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33. \nQ: Olivia has $23. She bought five bagels for $3 each. How much money does she have left? \nA: She bought 5 bagels for $3 each. This means she spent 5 * $3 = $15 on the bagels. She had $23 in be gin ning, \nso now she has $23 - $15 = $8. The answer is 8. \n43","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2201.11903.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.21","CreationDate":"D:20230112010630Z","ModDate":"D:20230112010630Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":43},"loc":{"pageNumber":43,"lines":{"from":26,"to":38}}}}],["1d5603ec-2ea1-48a3-8301-49592fd5a3a6",{"pageContent":"Tree of Thoughts: Deliberate Problem Solving \nwith Large Language Models \nShunyu Yao \nPrinceton University \nDian Yu \nGoogle DeepMind \nJeffrey Zhao \nGoogle DeepMind \nIzhak Shafran \nGoogle DeepMind \nThomas L. Griffiths \nPrinceton University \nYuan Cao \nGoogle DeepMind \nKarthik Narasimhan \nPrinceton University \nAbstract \nLanguage models are increasingly being deployed for general problem solving \nacross a wide range of tasks, but are still confined to token-level, left-to-right \ndecision-making processes during inference.  This means they can fall short in \ntasks that require exploration, strategic lookahead, or where initial decisions play \na pivotal role. To surmount these challenges, we introduce a new framework for \nlanguage model inference, “Tree of Thoughts” (ToT), which generalizes over the \npopular “Chain of Thought” approach to prompting language models, and enables \nexploration over coherent units of text (“thoughts”) that serve as intermediate steps","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":1,"lines":{"from":1,"to":25}}}}],["a62a7771-06bf-4d35-8a4f-1c884c2aff4a",{"pageContent":"exploration over coherent units of text (“thoughts”) that serve as intermediate steps \ntoward problem solving. ToT allows LMs to perform deliberate decision making \nby considering multiple different reasoning paths and self-evaluating choices to \ndecide the next course of action, as well as looking ahead or backtracking when \nnecessary to make global choices. Our experiments show that ToT significantly \nenhances language models’ problem-solving abilities on three novel tasks requiring \nnon-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. \nFor instance, in Game of 24, while GPT-4 with chain-of-thought prompting only \nsolved 4% of tasks, our method achieved a success rate of 74%. Code repo with all \nprompts: https://github.com/princeton-nlp/tree-of-thought-llm . \n1    Introduction \nOriginally designed to generate text, scaled-up versions of language models (LMs) such as GPT [ 25 ,","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":1,"lines":{"from":25,"to":36}}}}],["330b73af-fbd0-45a9-bc76-217668a69da9",{"pageContent":"26 , 1 , 23 ] and PaLM [ 5 ] have been shown to be increasingly capable of performing an ever wider \nrange of tasks requiring mathematical, symbolic, commonsense, and knowledge reasoning.  It is \nperhaps surprising that underlying all this progress is still the original autoregressive mechanism for \ngenerating text, which makes token-level decisions one by one and in a left-to-right fashion. Is such \na simple mechanism sufficient for a LM to be built toward a general problem solver? If not, what \nproblems would challenge the current paradigm, and what should be alternative mechanisms? \nThe literature on human cognition provides some clues to answer these questions. Research on “dual \nprocess” models suggests that people have two modes in which they engage with decisions – a fast, \nautomatic, unconscious mode (“System 1”) and a slow, deliberate, conscious mode (“System 2”) \n[ 30 , 31 , 16 , 15 ].  These two modes have previously been connected to a variety of mathematical","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":1,"lines":{"from":37,"to":46}}}}],["d6e14383-2242-464f-840f-d900cb5679de",{"pageContent":"models used in machine learning. For example, research on reinforcement learning in humans and \nother animals has explored the circumstances under which they engage in associative “model free” \nlearning or more deliberative “model based” planning [ 7 ]. The simple associative token-level choices \nof LMs are also reminiscent of “System 1”, and thus might benefit from augmentation by a more \ndeliberate “System 2” planning process that (1) maintains and explores diverse alternatives for current \n37th Conference on Neural Information Processing Systems (NeurIPS 2023). \narXiv:2305.10601v2  [cs.CL]  3 Dec 2023","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":1,"lines":{"from":47,"to":53}}}}],["3636350b-7b65-4de9-a375-51793fc46786",{"pageContent":"GĮŔũƜ \njũƜŔũƜ \nGĮŔũƜ \njũƜŔũƜ \nʱÊʲˤGj ʱæʲˤ\u001dĵÉ \nGĮŔũƜ \nˤjũƜŔũƜ \nʱçʲˤ\u001dĵÉˁ\u001d \nʟʟ ʟʟ \naÊĠĵŗƓŤƆˤsĵŤò \nGĮŔũƜ \nˤjũƜŔũƜ \nʱíʲˤÉĵÉˤʱĵũŗŝʲ \nʟʟ \nʟʟ \nʟʟ \nˤˤʝˤƛĎĵũĈĎƜ \n)L[\u0003FRORU\u0003\u000bE\\\u0003<XTLDQ\f \n0DUN\u0003GLIIHUHQFH\u0003E\\\u0003FRORU \nGĮŔũƜ \njũƜŔũƜ \nGĮŔũƜ \njũƜŔũƜ \nGĮŔũƜ \nˤjũƜŔũƜ \nʱçʲˤòĦƙˤ\u001dĵĮŝƓŝŤòĮçƆˤ \nƀƓƜĎˤ\u001dĵÉˤʱ\u001dĵÉˁ\u001dʲ \naÊĠĵŗƓŤƆˤsĵŤò \nGĮŔũƜ \nˤjũƜŔũƜ \nʱíʲˤÉŗòòˤĵƙˤĎĵũĈĎŤŝˤʱÉĵÉʲ \nʟʟ \nʟʟ \nʟʟ ʟʟ ʟʟ \nˤˤƛĎĵũĈĎƜ \nʱçʲˤ\u001dĎÊđĮˤĵƙˤĎĵũĈĎƜˤ \nŗĵĭŔƜđĮĈˤʱ\u001dĵÉʲ \nʱÊʲˤGĮŔũƜˁjũƜŔũƜˤ \nŗĵĭŔƜđĮĈˤʱGjʲ \nFigure 1: Schematic illustrating various approaches to problem solving with LLMs. Each rectangle \nbox represents a thought , which is a coherent language sequence that serves as an intermediate \nstep toward problem solving. See concrete examples of how thoughts are generated, evaluated, and \nsearched in Figures 2,4,6. \nchoices instead of just picking one, and (2) evaluates its current status and actively looks ahead or \nbacktracks to make more global decisions.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":2,"lines":{"from":1,"to":45}}}}],["85f91455-2b0c-453f-b9cc-710b6300f1bd",{"pageContent":"backtracks to make more global decisions. \nTo design such a planning process, we return to the origins of artificial intelligence (and cognitive \nscience), drawing inspiration from the planning processes explored by Newell, Shaw, and Simon \nstarting in the 1950s [ 21 , 22 ]. Newell and colleagues characterized problem solving [ 21 ] as search \nthrough a combinatorial problem space, represented as a tree. We thus propose the Tree of Thoughts \n(ToT) framework for general problem solving with language models. As Figure 1 illustrates, while \nexisting methods (detailed below) sample continuous language sequences for problem solving, ToT \nactively maintains a tree of thoughts, where each thought is a coherent language sequence that serves \nas an intermediate step toward problem solving (Table 1). Such a high-level semantic unit allows the \nLM to self-evaluate the progress different intermediate thoughts make towards solving the problem","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":2,"lines":{"from":45,"to":54}}}}],["f1e95be9-c449-48bf-b604-f83a9a0fcca1",{"pageContent":"LM to self-evaluate the progress different intermediate thoughts make towards solving the problem \nthrough a deliberate reasoning process that is also instantiated in language (Figures 2,4,6).  This \nimplementation of search heuristics via LM self-evaluation and deliberation is novel, as previous \nsearch  heuristics  are  either  programmed  or  learned.   Finally,  we  combine  this  language-based \ncapability to generate and evaluate diverse thoughts with search algorithms, such as breadth-first \nsearch (BFS) or depth-first search (DFS), which allow systematic exploration of the tree of thoughts \nwith lookahead and backtracking. \nEmpirically, we propose three new problems that challenge existing LM inference methods even with \nthe state-of-the-art language model, GPT-4 [ 23 ]:  Game of 24, Creative Writing, and Crosswords \n(Table 1). These tasks require deductive, mathematical, commonsense, lexical reasoning abilities,","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":2,"lines":{"from":54,"to":63}}}}],["356a3f42-4a23-45e8-b2f6-65af0ecf596b",{"pageContent":"(Table 1). These tasks require deductive, mathematical, commonsense, lexical reasoning abilities, \nand a way to incorporate systematic planning or search. We show ToT obtains superior results on \nall three tasks by being general and flexible enough to support different levels of thoughts, different \nways to generate and evaluate thoughts, and different search algorithms that adapt to the nature of \ndifferent problems.  We also analyze how such choices affect model performances via systematic \nablations and discuss future directions to better train and use LMs. \n2    Background \nWe first formalize some existing methods that use large language models for problem-solving, \nwhich our approach is inspired by and later compared with. We use p \nθ \nto denote a pre-trained LM \nwith parameters θ , and lowercase letters x,y,z,s, ··· to denote a language sequence , i.e. x = \n( x [1] , ··· ,x [ n ]) \nwhere each x [ i ] is a token, so that p \nθ \n( x ) = \nQ \nn \ni =1 \np \nθ \n( x [ i ] | x [1 ...i ])","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":2,"lines":{"from":63,"to":84}}}}],["3851fbab-cdbc-4697-a2a1-a825fb5aa97b",{"pageContent":"where each x [ i ] is a token, so that p \nθ \n( x ) = \nQ \nn \ni =1 \np \nθ \n( x [ i ] | x [1 ...i ]) \n. We use uppercase \nletters S, ··· to denote a collection of language sequences. \nInput-output (IO) prompting is the most common way to turn a problem input x into output \ny with LM: y ∼ p \nθ \n( y | prompt \nIO \n( x )) , where prompt \nIO \n( x ) wraps input x with task instructions \nand/or few-shot input-output examples. For simplicity, let us denote p \nprompt \nθ \n( output | input ) = \np \nθ \n( output | prompt ( input )) , so that IO prompting can be formulated as y ∼ p \nIO \nθ \n( y | x ) . \n2","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":2,"lines":{"from":76,"to":105}}}}],["738c8b1c-9bcf-4016-bb37-3161f52452db",{"pageContent":"Chain-of-thought (CoT) prompting [ 38 ] was proposed to address cases where the mapping of \ninput x to output y is non-trivial (e.g. when x is a math question and y is the final numerical answer). \nThe key idea is to introduce a chain of thoughts z \n1 \n, ··· ,z \nn \nto bridge x and y , where each z \ni \nis a \ncoherent language sequence that serves as a meaningful intermediate step toward problem solving \n(e.g. z \ni \ncould be an intermediate equation for math QA). To solve problems with CoT, each thought \nz \ni \n∼ p \nCoT \nθ \n( z \ni \n| x,z \n1 ··· i − 1 \n) is sampled sequentially,  then the output y ∼ p \nCoT \nθ \n( y | x,z \n1 ··· n \n) .   In \npractice, [ z \n1 ··· n \n,y ] ∼ p \nCoT \nθ \n( z \n1 ··· n \n,y | x ) is sampled as a continuous language sequence,  and the \ndecomposition of thoughts (e.g. is each z \ni \na phrase, a sentence, or a paragraph) is left ambiguous. \nSelf-consistency with CoT (CoT-SC) [ 36 ] is an ensemble approach that samples k i.i.d. chains \nof thought: [ z \n( i ) \n1 ··· n","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":3,"lines":{"from":1,"to":43}}}}],["063a5ee2-6351-4d73-b3f0-a94f0cb1f142",{"pageContent":"of thought: [ z \n( i ) \n1 ··· n \n,y \n( i ) \n] ∼ p \nCoT \nθ \n( z \n1 ··· n \n,y | x ) ( i = 1 ··· k ) \n, then returns the most frequent output: \narg max \ny \n# { i | y \n( i ) \n= y } .  CoT-SC improves upon CoT, because there are generally different \nthought processes for the same problem (e.g. different ways to prove the same theorem), and the \noutput decision can be more faithful by exploring a richer set of thoughts.  However, within each \nchain there is no local exploration of different thought steps, and the “most frequent” heuristic only \napplies when the output space is limited (e.g. multi-choice QA). \n3    Tree of Thoughts: Deliberate Problem Solving with LM \nA genuine problem-solving process involves the repeated use of available informa- \ntion to initiate exploration, which discloses, in turn, more information until a way \nto attain the solution is finally discovered.—— Newell et al. [21]","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":3,"lines":{"from":41,"to":65}}}}],["40e4d3fd-b064-46d9-a7e5-29ccfd898d12",{"pageContent":"to attain the solution is finally discovered.—— Newell et al. [21] \nResearch on human problem-solving suggests that people search through a combinatorial problem- \nspace – a tree where the nodes represent partial solutions, and the branches correspond to operators \nthat modify them [ 21 , 22 ]. Which branch to take is determined by heuristics that help to navigate the \nproblem-space and guide the problem-solver towards a solution. This perspective highlights two key \nshortcomings of existing approaches that use LMs to solve general problems: 1) Locally, they do not \nexplore different continuations within a thought process – the branches of the tree. 2) Globally, they \ndo not incorporate any type of planning, lookahead, or backtracking to help evaluate these different \noptions – the kind of heuristic-guided search that seems characteristic of human problem-solving. \nTo address these shortcomings, we introduce Tree of Thoughts (ToT) , a paradigm that allows LMs to","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":3,"lines":{"from":65,"to":74}}}}],["6d7afa8c-a9f1-4ac2-9e38-451949a35f49",{"pageContent":"To address these shortcomings, we introduce Tree of Thoughts (ToT) , a paradigm that allows LMs to \nexplore multiple reasoning paths over thoughts (Figure 1(c)). ToT frames any problem as a search \nover a tree, where each node is a state s = [ x,z \n1 ··· i \n] representing a partial solution with the input and \nthe sequence of thoughts so far. A specific instantiation of ToT involves answering four questions: \n1.  How to decompose the intermediate process into thought steps; 2.  How to generate potential \nthoughts from each state; 3. How to heuristically evaluate states; 4. What search algorithm to use. \n1. Thought decomposition. While CoT samples thoughts coherently without explicit decomposition, \nToT leverages problem properties to design and decompose intermediate thought steps. As Table 1 \nshows, depending on different problems, a thought could be a couple of words (Crosswords), a line of","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":3,"lines":{"from":74,"to":84}}}}],["a79a6e77-94da-496b-be48-60e82603c8f7",{"pageContent":"equation (Game of 24), or a whole paragraph of writing plan (Creative Writing). In general, a thought \nshould be “small” enough so that LMs can generate promising and diverse samples (e.g. generating \na whole book is usually too “big” to be coherent), yet “big” enough so that LMs can evaluate its \nprospect toward problem solving (e.g. generating one token is usually too “small” to evaluate). \n2. Thought generator G ( p \nθ \n,s,k ) . Given a tree state s = [ x,z \n1 ··· i \n] , we consider two strategies to \ngenerate k candidates for the next thought step: \n(a) Sample i.i.d. thoughts  from  a  CoT  prompt  (Creative  Writing,  Figure  4): z \n( j ) \n∼ \np \nCoT \nθ \n( z \ni +1 \n| s ) = p \nCoT \nθ \n( z \ni +1 \n| x,z \n1 ··· i \n) ( j = 1 ··· k ) .  This works better when the thought \nspace is rich (e.g. each thought is a paragraph), and i.i.d. samples lead to diversity; \n(b) Propose thoughts sequentially using a “propose prompt” (Game of 24, Figure 2; Crosswords, \nFigure 6): [ z \n(1) \n, ··· ,z","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":3,"lines":{"from":85,"to":115}}}}],["3ee957fc-96da-4293-aae1-27c43219e9ec",{"pageContent":"Figure 6): [ z \n(1) \n, ··· ,z \n( k ) \n] ∼ p \npropose \nθ \n( z \n(1 ··· k ) \ni +1 \n| s ) .  This works better when the thought \nspace is more constrained (e.g. each thought is just a word or a line), so proposing different \nthoughts in the same context avoids duplication. \n3. State evaluator V ( p \nθ \n,S ) . Given a frontier of different states, the state evaluator evaluates the \nprogress they make towards solving the problem, serving as a heuristic for the search algorithm \nto determine which states to keep exploring and in which order.  While heuristics are a standard \napproach to solving search problems, they are typically either programmed (e.g. DeepBlue [ 3 ]) or \n3","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":3,"lines":{"from":113,"to":132}}}}],["0dc73ab2-0a0c-40e1-a225-5d16d5d2bd85",{"pageContent":"learned (e.g. AlphaGo [ 29 ]). We propose a third alternative, by using the LM to deliberately reason \nabout states.  When applicable, such a deliberate heuristic can be more flexible than programmed \nrules, and more sample-efficient than learned models. Similar to the thought generator, we consider \ntwo strategies to evaluate states either independently or together: \n(a) Value each  state  independently: V ( p \nθ \n,S )( s ) ∼ p \nvalue \nθ \n( v | s ) ∀ s ∈ S ,  where  a  value \nprompt reasons about the state s to generate a scalar value v (e.g. 1-10) or a classifica- \ntion (e.g. sure/likely/impossible) that could be heuristically turned into a value. The basis \nof such evaluative reasoning can vary across problems and thought steps. In this work, we \nexplore evaluation via few lookahead simulations (e.g. quickly confirm that 5, 5, 14 can \nreach 24 via 5 + 5 + 14, or “hot l” can mean “inn” via filling “e” in “ ”) plus commonsense","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":4,"lines":{"from":1,"to":15}}}}],["388c28d3-6917-4d1d-a3ce-768c225ce41b",{"pageContent":"reach 24 via 5 + 5 + 14, or “hot l” can mean “inn” via filling “e” in “ ”) plus commonsense \n(e.g. 1 2 3 are too small to reach 24, or no word can start with “tzxc”). While the former \nmight promote “good” states, the latter could help eliminate “bad” states. Such valuations \ndo not need to be perfect, and only need to be approximately helpful for decision making. \n(b) Vote across states: V ( p \nθ \n,S )( s ) = 1 [ s = s \n∗ \n] , where a “good” state s \n∗ \n∼ p \nvote \nθ \n( s \n∗ \n| S ) is \nvoted out based on deliberately comparing different states in S in a vote prompt.  When \nproblem success is harder to directly value (e.g. passage coherency), it is natural to to instead \ncompare different partial solutions and vote for the most promising one.  This is similar \nin spirit to a “step-wise” self-consistency strategy, i.e. cast “which state to explore” as a \nmulti-choice QA, and use LM samples to vote for it.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":4,"lines":{"from":15,"to":35}}}}],["c3608c33-b465-40d6-88af-e7daf31d3317",{"pageContent":"multi-choice QA, and use LM samples to vote for it. \nFor both strategies, we could prompt the LM multiple times to aggregate the value or vote results to \ntrade time/resource/cost for more faithful/robust heuristics. \nAlgorithm 1 ToT-BFS( x,p \nθ \n,G,k,V,T,b ) \nRequire: Input x , LM p \nθ \n, thought generator G () \n& size limit k , states evaluator V () , step limit T , \nbreadth limit b . \nS \n0 \n←{ x } \nfor t = 1 , ··· ,T do \nS \n′ \nt \n←{ [ s,z ] | s ∈ S \nt − 1 \n,z \nt \n∈ G( p \nθ \n,s,k ) } \nV \nt \n← V ( p \nθ \n,S \n′ \nt \n) \nS \nt \n← arg max \nS ⊂ S \n′ \nt \n, | S | = b \nP \ns ∈ S \nV \nt \n( s ) \nend for \nreturn G ( p \nθ \n, arg max \ns ∈ S \nT \nV \nT \n( s ) , 1) \nAlgorithm 2 ToT-DFS( s,t,p \nθ \n,G,k,V,T,v \nth \n) \nRequire: Current state s , step t , LM p \nθ \n, thought \ngenerator G () and size limit k , states evaluator \nV () , step limit T , threshold v \nth \nif t > T then record output G ( p \nθ \n,s, 1) \nend if \nfor s \n′ \n∈ G ( p \nθ \n,s,k ) do ▷ sorted candidates \nif V ( p \nθ \n, { s \n′ \n} )( s ) > v","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":4,"lines":{"from":35,"to":113}}}}],["db5b9415-71cd-4d23-a513-f5ed2f48a300",{"pageContent":"end if \nfor s \n′ \n∈ G ( p \nθ \n,s,k ) do ▷ sorted candidates \nif V ( p \nθ \n, { s \n′ \n} )( s ) > v \nthres \nthen ▷ pruning \nDFS ( s \n′ \n,t + 1) \nend if \nend for \n4.  Search algorithm. Finally, within the ToT framework, one can plug and play different search \nalgorithms depending on the tree structure. We explore two relatively simple search algorithms and \nleave more advanced ones (e.g. A* [11], MCTS [2]) for future work: \n(a) Breadth-first search (BFS) (Algorithm 1) maintains a set of the b most promising states \nper step.  This is used for Game of 24 and Creative Writing where the tree depth is limit \n( T ≤ 3 ), and initial thought steps can be evaluated and pruned to a small set ( b ≤ 5 ). \n(b) Depth-first search (DFS) (Algorithm 2) explores the most promising state first, until the \nfinal output is reached ( t > T ), or the state evaluator deems it impossible to solve the \nproblem from the current s ( V ( p \nθ \n, { s } )( s ) ≤ v \nth \nfor a value threshold v \nth \n).  In the latter","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":4,"lines":{"from":103,"to":135}}}}],["3d998731-7d63-47b3-85af-695a04e33b5f",{"pageContent":"θ \n, { s } )( s ) ≤ v \nth \nfor a value threshold v \nth \n).  In the latter \ncase, the subtree from s is pruned to trade exploration for exploitation. In both cases, DFS \nbacktracks to the parent state of s to continue exploration. \nConceptually, ToT has several benefits as a method for general problem-solving with LMs: (1) Gener- \nality. IO, CoT, CoT-SC, and self-refinement can be seen as special cases of ToT (i.e. trees of limited \ndepth and breadth; Figure 1). (2) Modularity. The base LM, as well as the thought decomposition, \ngeneration, evaluation, and search procedures can all be varied independently.  (3) Adaptability . \nDifferent problem properties, LM capabilities, and resource constraints can be accommodated. (4) \nConvenience. No extra training is needed, just a pre-trained LM is sufficient. The next section will \nshow how these conceptual benefits translate to strong empirical performance in different problems. \n4    Experiments","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":4,"lines":{"from":130,"to":145}}}}],["4e47ce75-fd55-41d8-8c9f-a11914516621",{"pageContent":"4    Experiments \nWe propose three tasks that are hard even when sampling from the state-of-the-art language model, \nGPT-4 [ 23 ], using standard IO prompting or chain-of-thought (CoT) prompting.  We show how \n4","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":4,"lines":{"from":145,"to":148}}}}],["63584635-e5af-478c-93e9-eeff87693400",{"pageContent":"Game of 24 Creative Writing 5x5 Crosswords \nInput 4 numbers (4 9 10 13) 4 random sentences 10 clues (h1. presented;..) \nOutput An equation to reach 24 \n(13-9)*(10-4)=24 \nA passage of 4 paragraphs \nending in the 4 sentences \n5x5   letters: SHOWN; \nWIRRA; AVAIL; ... \nThoughts 3 intermediate equations \n(13-9=4 (left 4,4,10); 10- \n4=6 (left 4,6); 4*6=24) \nA    short    writing    plan \n(1. Introduce a book that \nconnects...) \nWords to fill in for clues: \n(h1. shown; v5. naled; ...) \n#ToT steps 3 1 5-10 (variable) \nTable 1: Task overview. Input, output, thought examples are in blue. \ndeliberate search in trees of thoughts (ToT) produces better results, and more importantly, interesting \nand promising new ways to use language models to solve problems requiring search or planning. \nUnless otherwise stated, we perform experiments using a Chat Completion mode GPT-4 \n1 \nwith a \nsampling temperature of 0.7. \n4.1    Game of 24","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":5,"lines":{"from":1,"to":25}}}}],["da1ee6d5-1047-4d8d-b3dc-aee788b680bb",{"pageContent":"1 \nwith a \nsampling temperature of 0.7. \n4.1    Game of 24 \nGame of 24 is a mathematical reasoning challenge, where the goal is to use 4 numbers and basic \narithmetic operations (+-*/) to obtain 24. For example, given input “4 9 10 13”, a solution output \ncould be “(10 - 4) * (13 - 9) = 24”. \nʳĵĮòˤòƅÊĭŔĦòʴˤ \nGĮŔũƜʝˤʁˤʆˤɾɽˤɾʀ \nĵŝŝđæĦòˤĮòƅƜˤŝŤòŔŝʝˤ ˤˤ \n3URSRVH\u00033URPSW \nʁˤ̌ˤʆˤ̐ˤɾʀˤʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲ \nɾɽˤˊˤʁˤ̐ˤʃˤʱĦòƙƜʝˤʃˤʆˤɾʀʲ \nʳ ʛʛʛĭĵŗòˤĦđĮòŝʟ ʴ \n7KRXJKW\u0003*HQHUDWLRQ \n/0 \n)sÊĦũÊŤòˤđƙˤĈƓsòĮˤĮũĭæòŗŝˤçÊĮˤ \nŗòÊçĎˤɿʁˤʱŝũŗòʫĦđģòĦƆʫđĭŔĵŝŝđæĦòʲ \nɾɽˤɾʁʝˤɾɽˤ̌ˤɾʁˤ̐ˤɿʁʛˤŝũŗò \nʳĭĵŗòˤòƅÊĭŔĦòŝʴ \nɾɽˤɾʀˤɾʀ \n9DOXH\u00033URPSW \nʱɾʀˤˊˤɾɽʲˤʦˤɾʀˤ̐ˤʀˤʦˤɾʀˤ̐ˤʀʆ \nɾɽˤ̌ˤɾʀˤ̌ˤɾʀˤ̐ˤʀʃ \nĎòŗòˤƓŝˤĮĵˤƀÊƆˤƘĵˤĵæŤÊđĮˤɿʁˤƀƓƜĎˤ \nƛĎòŝòˤĮũĭæòŗŝʛˤđĭŔĵŝŝđæĦò \n7KRXJKW\u0003(YDOXDWLRQ \nʱæʲ \nʱçʲ \n/0 \nGĮŔũƜʝˤʁˤʆˤɾɽˤɾʀ \nʁ̌ʆ̐ɾʀ \nʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲ \nɾɽˁʁ̐ʃ \nʱĦòƙƜʝˤʃˤʆˤɾʀʲ \nʟʟ \nɾʀˁʃ̐ʄ \nʱĦòƙƜʝˤʄˤʆʲ \nɾʀˁʆ̐ʁ \nʱĦòƙƜʝˤʁˤʃʲ \nʟʟ \nʁʦʃ̐ɿʁ \nʱĦòƙƜʝˤɿʁʲ \nʁ̌ʃ̐ɾɽ \nʱĦòƙƜʝˤɾɽʲ \nʟʟ \nʱÊʲ \nʳĵĮòˤòƅÊĭŔĦòʴˤ \nGĮŔũƜʝˤʁˤʆˤɾɽˤɾʀ \nĵŝŝđæĦòˤĮòƅƜˤŝŤòŔŝʝˤ ˤˤ \n\u000bD\f\u00033URSRVH\u00033URPSW","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":5,"lines":{"from":22,"to":72}}}}],["b96e1b93-8ddd-4228-9dc2-374ddbc4b4f0",{"pageContent":"ʟʟ \nʱÊʲ \nʳĵĮòˤòƅÊĭŔĦòʴˤ \nGĮŔũƜʝˤʁˤʆˤɾɽˤɾʀ \nĵŝŝđæĦòˤĮòƅƜˤŝŤòŔŝʝˤ ˤˤ \n\u000bD\f\u00033URSRVH\u00033URPSW \nʁˤ̌ˤʆˤ̐ˤɾʀˤʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲ \nɾɽˤˊˤʁˤ̐ˤʃˤʱĦòƙƜʝˤʃˤʆˤɾʀʲ \nʳ ʛʛʛĭĵŗòˤĦđĮòŝʟ ʴ \n7KRXJKW\u0003*HQHUDWLRQ \n/0 \n)sÊĦũÊŤòˤđƙˤĈƓsòĮˤĮũĭæòŗŝˤçÊĮˤ \nŗòÊçĎˤɿʁˤʱŝũŗòʫĦđģòĦƆʫđĭŔĵŝŝđæĦòʲ \nɾɽˤɾʁʝˤɾɽˤ̌ˤɾʁˤ̐ˤɿʁʛˤŝũŗò \nʳĭĵŗòˤòƅÊĭŔĦòŝʴ \nɾɽˤɾʀˤɾʀ \n\u000bE\f\u00039DOXH\u00033URPSW \nʱɾʀˤˊˤɾɽʲˤʦˤɾʀˤ̐ˤʀˤʦˤɾʀˤ̐ˤʀʆ \nɾɽˤ̌ˤɾʀˤ̌ˤɾʀˤ̐ˤʀʃˤĎòŗòˤƓŝˤĮĵˤƀÊƆˤ \nƘĵˤĵæŤÊđĮˤɿʁˤƀƓƜĎˤƛĎòŝòˤæƓĈˤ \nĮũĭæòŗŝʛˤđĭŔĵŝŝđæĦò \n7KRXJKW\u0003(YDOXDWLRQ \n/0 \nGĮŔũƜ ʝˤʁˤʆˤɾɽˤɾʀ \nʁ̌ʆ̐ɾʀ \nʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲ \nɾɽˁʁ̐ʃ \nʱĦòƙƜʝˤʃˤʆˤɾʀʲ \nʟʟ \nɾʀˁʃ̐ʄ \nʱĦòƙƜʝˤʄˤʆʲ \nɾʀˁʆ̐ʁ \nʱĦòƙƜʝˤʁˤʃʲ \nʟʟ \nʁʦʃ̐ɿʁ \nʱĦòƙƜʝˤɿʁʲ \nʁ̌ʃ̐ɾɽ \nʱĦòƙƜʝˤɾɽʲ \nʟʟ \n)L[\u0003FRORU\u0003\u000bE\\\u0003<XTLDQ\f \n0DUN\u0003GLII\u0003SURPSW\u0003ZLWK\u0003FRORU \nFigure 2: ToT in a game of 24. The LM is prompted for (a) thought generation and (b) valuation. \nTask Setup. We scrape data from 4nums.com, which has 1,362 games that are sorted from easy to \nhard by human solving time, and use a subset of relatively hard games indexed 901-1,000 for testing.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":5,"lines":{"from":67,"to":110}}}}],["8eac6495-4940-403f-9630-3d60716c0b31",{"pageContent":"For each task, we consider the output as success if it is a valid equation that equals 24 and uses the \ninput numbers each exactly once. We report the success rate across 100 games as the metric. \nBaselines. We use a standard input-output (IO) prompt with 5 in-context examples. For chain-of- \nthought (CoT) prompting, we augment each input-output pair with 3 intermediate equations, each \noperating on two remaining numbers. For example, given input “4 9 10 13”, the thoughts could be \n“13 - 9 = 4 (left: 4 4 10); 10 - 4 = 6 (left: 4 6); 4 * 6 = 24 (left: 24)”. For each game, we sample IO \nand CoT prompting for 100 times for average performance. We also consider a CoT self-consistency \nbaseline, which takes the majority output from 100 CoT samples, and an iterative-refine approach on \ntop of an IO sample for at most 10 iterations. At each iteration, the LM is conditioned on all previous \nhistory to “reflect on your mistakes and generate a refined answer” if the output is incorrect. Note","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":5,"lines":{"from":111,"to":120}}}}],["7b27dcbd-b4c1-43b4-bcf7-e65f2a426d32",{"pageContent":"that it uses groundtruth feedback signals about equation correctness. \nToT Setup. To frame Game of 24 into ToT, it is natural to decompose the thoughts into 3 steps, \neach an intermediate equation. As shown in Figure 2(a), at each tree node, we exact the remaining \nnumbers and prompt the LM to propose some possible next steps. The same “propose prompt” is \nused for all 3 thought steps, though it only has one example with 4 input numbers. We perform a \nbreadth-first search (BFS) in ToT, where at each step we keep the best b = 5 candidates. To perform \ndeliberate BFS in ToT, as shown in Figure 2(b), we prompt LM to evaluate each thought candidate as \n“sure/maybe/impossible” with regard to reaching 24. The aim is to promote correct partial solutions \nthat can be verdicted within few lookahead trials, and eliminate impossible partial solutions based on \n“too big/small” commonsense, and keep the rest “maybe”. We sample values 3 times for each thought. \n1","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":5,"lines":{"from":121,"to":131}}}}],["b97341fd-ce48-41d7-b44f-2f9bdb72aa39",{"pageContent":"1 \nExperiments were done between May 5-16, 2023. \n5","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":5,"lines":{"from":131,"to":133}}}}],["7075ab72-b28b-4e6d-9b13-a998234cce1e",{"pageContent":"Method Success \nIO prompt 7.3% \nCoT prompt 4.0% \nCoT-SC (k=100) 9.0% \nToT (ours) (b=1) 45% \nToT (ours) (b=5) 74% \nIO + Refine (k=10) 27% \nIO (best of 100) 33% \nCoT (best of 100) 49% \nTable 2: Game of 24 Results. \n0 25 50 75 100 \n0.2 \n0.4 \n0.6 \n(a) Success rate with nodes visited \nIO (best of k) \nCoT (best of k) \nToT (b=1...5) \n1 2 3 4 Correct \n0.0 \n0.2 \n0.4 \n0.6 \n(b) Samples failed at each step \nCoT \nToT (b=5) \nFigure 3: Game of 24 (a) scale analysis & (b) error analysis. \nResults. As shown in Table 2, IO, CoT, and CoT-SC prompting methods perform badly on the task, \nachieving only 7.3%, 4.0%, and 9.0% success rates. In contrast, ToT with a breadth of b = 1 already \nachieves a success rate of 45% , while b = 5 achieves 74% .  We also consider an oracle setup for \nIO/CoT, by calculating the success rate using best of k samples (1 ≤ k ≤ 100) . To compare IO/CoT \n(best of k) with ToT, we consider calculating the tree nodes visited per task in ToT across b = 1 ··· 5 ,","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":6,"lines":{"from":1,"to":32}}}}],["10a00462-77bf-44f8-9977-6494f649a359",{"pageContent":"and map the 5 success rates in Figure 3(a), treating IO/CoT (best of k ) as visiting k nodes in a bandit. \nNot surprisingly, CoT scales better than IO, and best of 100 CoT samples achieve a success rate of \n49% , but still much worse than exploring more nodes in ToT ( b > 1 ). \nError analysis. Figure 3(b) breaks down at which step CoT and ToT samples fail the task, i.e. the \nthought (in CoT) or all b thoughts (in ToT) are invalid or impossible to reach 24. Notably, around \n60% of CoT samples already failed the task after generating the first step, or equivalently, the first \nthree words (e.g. “ 4 + 9 ”). This highlights the issues with direct left-to-right decoding. \n4.2    Creative writing \nNext, we invent a creative writing task where the input is 4 random sentences and the output should \nbe a coherent passage with 4 paragraphs that end in the 4 input sentences respectively. Such a task is \nopen-ended and exploratory, and challenges creative thinking as well as high-level planning.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":6,"lines":{"from":33,"to":43}}}}],["d0b4959d-f636-48f6-a95a-6f0d7af215c0",{"pageContent":"open-ended and exploratory, and challenges creative thinking as well as high-level planning. \nTask setup. We sample random sentences from randomwordgenerator.com to form 100 inputs, and \nthere is no groundtruth passage for each input constraint.  As we find that GPT-4 can follow the \ninput constraints most of the time, we focus on evaluating passage coherency in two ways: using a \nGPT-4 zero-shot prompt to provide a 1-10 scalar score, or using human judgments to compare pairs \nof outputs from different methods. For the former, we sample 5 scores and average them for each task \noutput, and we find these 5 scores usually consistent, with a standard deviation of around 0 . 56 on \naverage across outputs. For the latter, we employ a subset of the authors in a blind study to compare \nthe coherency of CoT vs. ToT generated passage pairs, where the order of passages is random flipped \nover 100 inputs.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":6,"lines":{"from":43,"to":52}}}}],["03378bf4-4ab7-4a7a-84cb-1be958dd1336",{"pageContent":"over 100 inputs. \nBaselines. Given the creative nature of the task, both IO and CoT prompts are zero-shot. While the \nformer prompts the LM to directly generate a coherent passage given input constraints, the latter \nprompts the LM to first make a brief plan then write the passage, i.e. the plan serves as the intermediate \nthought step.  We generate 10 IO and CoT samples per task.  We also consider an iterative-refine \n( k ≤ 5 ) method on top of a random IO sample for each task, where the LM is conditioned on input \nconstraints and the last generated passage to decide if the passage is already “perfectly coherent”, \nand if not generate a refined one. \nToT setup. We build a ToT with depth 2 (and only 1 intermediate thought step) — the LM first \ngenerates k = 5 plans and votes for the best one (Figure 4), then similarly generate k = 5 passages \nbased on the best plan then vote for the best one. Here the breadth limit b = 1 , as only one choice is","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":6,"lines":{"from":52,"to":62}}}}],["c1a1fe9a-99c7-4ed9-a5aa-0df956bf9dcf",{"pageContent":"kept per step. A simple zero-shot vote prompt (“analyze choices below, then conclude which is most \npromising for the instruction”) is used to sample 5 votes at both steps. \nResults. Figure 5(a) shows average GPT-4 scores across 100 tasks, where ToT (7.56) is deemed to \ngenerate more coherent passages than IO (6.19) and CoT (6.93) on average. While such an automatic \nmetric might be noisy, Figure 5(b) confirms the finding by showing that humans prefer ToT over \nCoT in 41 out of 100 passage pairs, while only prefer CoT over ToT in 21 (other 38 pairs are found \n“similarly coherent”). Lastly, iterative-refine is more effective on this natural language task, where \n6","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":6,"lines":{"from":63,"to":70}}}}],["b652ffbe-569b-4d58-856b-feedfc9b4f25",{"pageContent":"μŗƓŤòˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòˤĵƙˤʁˤŝĎĵŗƜˤŔÊŗÊĈŗÊŔĎŝʛˤĎòˤòĮíˤŝòĮŤòĮçòˤĵƙˤòÊçĎˤŔÊŗÊĈŗÊŔĎˤĭũŝƜˤæòʝˤ ɾʛ ˤGƜˤƓŝĮ ̇ƛˤ \níđƙƙƓçũĦƜˤƘĵˤíĵˤÊˤĎÊĮíŝŤÊĮíˤđƙˤƆĵũˤĠũŝƜˤŝŤÊĮíˤĵĮˤƆĵũŗˤĎÊĮíŝʛˤ ɿʛ ˤGƜˤçÊũĈĎƜˤĎđĭˤĵƙƙˤĈũÊŗíˤƛĎÊƜˤŝŔÊçòˤŝĭòĦĦòíˤĵƙˤ \nŝòÊŗòíˤŝŤòÊģʛˤ ʀʛ ˤμĎòĮˤŝĎòˤíƓíĮ˒ƛˤĦđģòˤÊˤĈũƆˤƀĎĵˤƀÊŝˤƛŗƆđĮĈˤƘĵˤŔƓçģˤĎòŗˤũŔʜˤŝĎòˤŝŤÊŗŤòíˤũŝđĮĈˤŝƓĈĮˤĦÊĮĈũÊĈòʛˤ ʁʛ ˤ \n)ÊçĎˤŔòŗŝĵĮˤƀĎĵˤģĮĵƀŝˤƆĵũˤĎÊŝˤÊˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮˤĵƙˤƀĎĵˤƆĵũˤÊŗòʛˤ ˤ \nɾʛ ˤGĮƜŗĵíũçòˤÊĮíˤòƅŔĦÊđĮˤƛĎòˤƘòçĎĮƓŖũòˤĵƙˤ \níĵđĮĈˤÊˤĎÊĮíŝŤÊĮíˤ ɿʛ ˤƀƓŤçĎˤƘĵˤÊˤŝŤĵŗƆˤÊæĵũƜˤ \nÊĮˤÊŝƜŗĵĮÊũƜ ̇ŝˤƚđŗŝƜˤƛđĭòˤđĮˤŝŔÊçòˤ ʀʛ ˤ#òŝçŗđæòˤ \nÊˤŝƓƜũÊƜƓĵĮˤƀĎòŗòˤÊˤƀĵĭÊĮˤũŝòŝˤŝƓĈĮˤ \nĦÊĮĈũÊĈòˤƘĵˤÊsĵƓíˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤ ʁʛ ˤĎòˤ \nƚđĮÊĦˤŔÊŗÊĈŗÊŔĎˤòƅŔĦÊđĮŝˤĎĵƀˤòsòŗƆĵĮòˤĎÊŝˤ \níđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵƜĎòŗŝ \nɾʛ ˤGĮƜŗĵíũçƜƓĵĮˤƘĵˤÊĮˤũĮũŝũÊĦˤŝòĦƙˊĎòĦŔˤæĵĵģʜˤ \nĭòĮƜƓĵĮđĮĈˤÊˤĎÊĮíŝŤÊĮíˤÊŝˤÊˤĭòŤÊŔĎĵŗˤƗĵŗˤòĭæŗÊçđĮĈˤ \nçĎÊĦĦòĮĈòŝʛˤ ɿʛ ˤ#ƓŝçũŝŝˤƛĎòˤũĮòƅŔòçŤòíˤƛĎđĮĈŝˤĦòÊŗĮòíˤ \nƚŗĵĭˤÊŝƜŗĵĮÊũŤŝʜˤđĮçĦũíđĮĈˤƛĎòˤŝĭòĦĦˤĵƙˤŝŔÊçòʛˤ ʀʛ ˤ \n#òŝçŗđæòˤÊˤƀĵĭÊĮ ̇ŝˤçĦòsòŗˤƘÊçƜƓçˤƗĵŗˤÊsĵƓíđĮĈˤũĮƀÊĮŤòíˤ","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":7,"lines":{"from":1,"to":16}}}}],["0b3de08c-f303-4b7d-8a3e-04b9e4dae0c8",{"pageContent":"#òŝçŗđæòˤÊˤƀĵĭÊĮ ̇ŝˤçĦòsòŗˤƘÊçƜƓçˤƗĵŗˤÊsĵƓíđĮĈˤũĮƀÊĮŤòíˤ \nÊƜŤòĮƜƓĵĮˤÊƜˤÊˤæÊŗʛˤ ʁʛ ˤ\u001dĵĮŤòĭŔĦÊŤòˤĎĵƀˤíđƙćòŗòĮƜˤ \nŔòŗçòŔƜƓĵĮŝˤĵƙˤĵĮòŝòĦƙˤçÊĮˤŝĎÊŔòˤĵĮò ̇ŝˤƓíòĮƜƓŤƆʛ \nʱÊʲˤ \nGĮŔũƜ \nʱæʲˤ \nĦÊĮŝ \nʱʀˤĭĵŗòˤ \nĵĭƓƜŤòíʲ \nʱçʲˤ \n ́ĵŤòŝ \n\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤ \nçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓsòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤ \nòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ ̇ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤ \nŝòĦƙˊđĭŔŗĵsòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤ ʳʛʛʛʴ ˤ ĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ \nʱɽʫʂˤsĵŤòŝʲ \n\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤ \nçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓsòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤ \nòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ ̇ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤ","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":7,"lines":{"from":16,"to":34}}}}],["9fd7839c-a386-4501-82de-94ddb1946ecd",{"pageContent":"ŝòĦƙˊđĭŔŗĵsòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤ ʳʛʛʛʴ ˤ ĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ \n\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤ \nçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓsòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤ \nòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ ̇ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤ \nŝòĦƙˊđĭŔŗĵsòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤ ʳʛʛʛʴ ˤ ĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ \n\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤ \nçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓsòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤ \nòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ ̇ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤ \nŝòĦƙˊđĭŔŗĵsòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤ ʳʛʛʛʴ ˤ ĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":7,"lines":{"from":35,"to":43}}}}],["95cbdc3d-1bcd-437d-a523-4e8f8a9bf2b9",{"pageContent":"\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤ \nçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤ ʳʛʛʛʴ ˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓsòˤæƆˤũŝđĮĈˤƛĎòˤ \nŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ ̇ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤ \nŝòĦƙˊđĭŔŗĵsòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤ ʳʛʛʛʴ ˤ ĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ \nʱʀʫʂˤsĵŤòŝʲ \nʟ \nɾ ɿ \nGĮŔũƜ \nĦÊĮˤɾ \nĦÊĮˤɿ \nʟʟ \nÊŝŝÊĈò \nɾ \nÊŝŝÊĈò \nɿ \nʟʟ \n)L[\u0003FRORU\u0003\u000bE\\\u0003<XTLDQ\f \nμŗƓŤòˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòˤĵƙˤʁˤŝĎĵŗƜˤŔÊŗÊĈŗÊŔĎŝʛˤĎòˤòĮíˤŝòĮŤòĮçòˤĵƙˤòÊçĎˤŔÊŗÊĈŗÊŔĎˤĭũŝƜˤæòʝˤ ɾʛ ˤGƜˤƓŝĮ ̇ƛˤ \níđƙƙƓçũĦƜˤƘĵˤíĵˤÊˤĎÊĮíŝŤÊĮíˤđƙˤƆĵũˤĠũŝƜˤŝŤÊĮíˤĵĮˤƆĵũŗˤĎÊĮíŝʛˤ ɿʛ ˤGƜˤçÊũĈĎƜˤĎđĭˤĵƙƙˤĈũÊŗíˤƛĎÊƜˤŝŔÊçòˤŝĭòĦĦòíˤĵƙˤ \nŝòÊŗòíˤŝŤòÊģʛˤ ʀʛ ˤμĎòĮˤŝĎòˤíƓíĮ˒ƛˤĦđģòˤÊˤĈũƆˤƀĎĵˤƀÊŝˤƛŗƆđĮĈˤƘĵˤŔƓçģˤĎòŗˤũŔʜˤŝĎòˤŝŤÊŗŤòíˤũŝđĮĈˤŝƓĈĮˤĦÊĮĈũÊĈòʛˤ ʁʛ ˤ \n)ÊçĎˤŔòŗŝĵĮˤƀĎĵˤģĮĵƀŝˤƆĵũˤĎÊŝˤÊˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮˤĵƙˤƀĎĵˤƆĵũˤÊŗòʛˤ ˤ \nɾʛ ˤGĮƜŗĵíũçòˤÊĮíˤòƅŔĦÊđĮˤƛĎòˤƘòçĎĮƓŖũòˤ","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":7,"lines":{"from":44,"to":65}}}}],["d52d65d5-abe9-41e6-bd7b-457196e588fb",{"pageContent":"ɾʛ ˤGĮƜŗĵíũçòˤÊĮíˤòƅŔĦÊđĮˤƛĎòˤƘòçĎĮƓŖũòˤ \nĵƙˤíĵđĮĈˤÊˤĎÊĮíŝŤÊĮíˤ ɿʛ ˤƀƓŤçĎˤƘĵˤÊˤ \nŝŤĵŗƆˤÊæĵũƜˤÊĮˤÊŝƜŗĵĮÊũƜ ̇ŝˤƚđŗŝƜˤƛđĭòˤđĮˤ \nŝŔÊçòˤ ʀʛ ˤ#òŝçŗđæòˤÊˤŝƓƜũÊƜƓĵĮˤƀĎòŗòˤÊˤ \nƀĵĭÊĮˤũŝòŝˤŝƓĈĮˤĦÊĮĈũÊĈòˤƘĵˤÊsĵƓíˤ \nũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤ ʁʛ ˤĎòˤƚđĮÊĦˤ \nŔÊŗÊĈŗÊŔĎˤòƅŔĦÊđĮŝˤĎĵƀˤòsòŗƆĵĮòˤĎÊŝˤ \níđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵƜĎòŗŝ \nɾʛ ˤGĮƜŗĵíũçƜƓĵĮˤƘĵˤÊĮˤũĮũŝũÊĦˤŝòĦƙˊĎòĦŔˤæĵĵģʜˤ \nĭòĮƜƓĵĮđĮĈˤÊˤĎÊĮíŝŤÊĮíˤÊŝˤÊˤĭòŤÊŔĎĵŗˤƗĵŗˤ \nòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʛˤ ɿʛ ˤ#ƓŝçũŝŝˤƛĎòˤũĮòƅŔòçŤòíˤ \nƛĎđĮĈŝˤĦòÊŗĮòíˤƚŗĵĭˤÊŝƜŗĵĮÊũŤŝʜˤđĮçĦũíđĮĈˤƛĎòˤŝĭòĦĦˤĵƙˤ \nŝŔÊçòʛˤ ʀʛ ˤ#òŝçŗđæòˤÊˤƀĵĭÊĮ ̇ŝˤçĦòsòŗˤƘÊçƜƓçˤƗĵŗˤÊsĵƓíđĮĈˤ \nũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤÊƜˤÊˤæÊŗʛˤ ʁʛ ˤ\u001dĵĮŤòĭŔĦÊŤòˤĎĵƀˤ \níđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵĮòŝòĦƙˤçÊĮˤŝĎÊŔòˤĵĮò ̇ŝˤ \nƓíòĮƜƓŤƆʛ \nʱÊʲˤ \nGĮŔũƜ \nʱæʲˤ \nĦÊĮŝ \nʱçʲˤ \n ́ĵŤòŝ \n\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤ \nçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤ ʳʛʛʛʴ ˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓsòˤæƆˤũŝđĮĈˤƛĎòˤ","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":7,"lines":{"from":65,"to":88}}}}],["5c3bfac1-6794-499c-96c6-2e1d9a54e67c",{"pageContent":"ŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ ̇ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤ \nŝòĦƙˊđĭŔŗĵsòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤ ʳʛʛʛʴ ˤ ĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ \nGĮŔũƜ \nĦÊĮˤɾ \nˤĦÊĮˤɿ ˤˤ \nʟʟ \nÊŝŝÊĈò \nɾ \nÊŝŝÊĈò \nɿ \nʟʟ \nɽʫʂˤsĵŤòŝ \nĦÊĮˤɾ ˤ ˤˤ \nʟʛ \nʟʛ \nɾʟʛ \nɿʟ \nʟ \nʀʫʂˤsĵŤòŝ \nĦÊĮˤʀˁʂ ˤ ˤˤ \n8VH\u0003UHG\u0012JUHHQ\u0003WR\u0003VKRZ\u0003ILQDO\u0003FKRLFH \nĮʫʂˤsĵŤòŝ \nĦÊĮˤɿ ˤ ˤˤ \n\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤ \nçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤ ʳʛʛʛʴ ˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓsòˤæƆˤũŝđĮĈˤƛĎòˤ \nŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ ̇ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤ \nŝòĦƙˊđĭŔŗĵsòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤ ʳʛʛʛʴ ˤ ĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ \n\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤ","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":7,"lines":{"from":89,"to":116}}}}],["618e2354-94ce-4b8b-80a8-77d7255bbe80",{"pageContent":"çĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤ ʳʛʛʛʴ ˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓsòˤæƆˤũŝđĮĈˤƛĎòˤ \nŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ ̇ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤ \nŝòĦƙˊđĭŔŗĵsòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤ ʳʛʛʛʴ ˤ ĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ \n\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤ \nçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤ ʳʛʛʛʴ ˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓsòˤæƆˤũŝđĮĈˤƛĎòˤ \nŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ ̇ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤ \nŝòĦƙˊđĭŔŗĵsòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤ ʳʛʛʛʴ ˤ ĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ \n\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤ \nçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤ ʳʛʛʛʴ ˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓsòˤæƆˤũŝđĮĈˤƛĎòˤ","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":7,"lines":{"from":113,"to":121}}}}],["2438872c-f01f-4b10-b934-e5036dfd7b36",{"pageContent":"ŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ ̇ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤ \nŝòĦƙˊđĭŔŗĵsòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤ ʳʛʛʛʴ ˤ ĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ \nFigure 4: A step of deliberate search in a randomly picked Creative Writing task. Given the input, the \nLM samples 5 different plans, then votes 5 times to decide which plan is best. The majority choice is \nused to consequently write the output passage with the same sample-vote procedure. \nIO CoT ToT IO \n+refine \nToT \n+refine \n4 \n6 \n8 \n(a) GPT-4 coherency scores \nCoT > ToT Similar ToT > CoT \n0 \n10 \n20 \n30 \n40 \n21 \n38 \n41 \n(b) Human coherency comparison \nFigure 5: Creative Writing results. \nMethod Success Rate (%) \nLetter Word  Game \nIO 38.7 14 0 \nCoT \n40.6   15.6 1 \nToT (ours) 78 60 20 \n+best state 82.4   67.5 35 \n-prune 65.4   41.5 5 \n-backtrack \n54.6 20 5 \nTable 3: Mini Crosswords results.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":7,"lines":{"from":126,"to":160}}}}],["4fb7bc6c-e84d-4d4a-9096-bc7e84126f75",{"pageContent":"-prune 65.4   41.5 5 \n-backtrack \n54.6 20 5 \nTable 3: Mini Crosswords results. \nit improves IO coherency score from 6.19 to 7.67, and ToT coherency score from 7.56 to 7.91. We \nbelieve it could be thought of as a third approach to thought generation in the ToT framework, where \nnew thoughts can arise from refining old thoughts instead of i.i.d. or sequentially generated. \n4.3    Mini crosswords \nIn Game of 24 and Creative Writing, ToT is relatively shallow — at most 3 thought steps are needed \nto reach the final output. Here we explore 5 × 5 mini crosswords as a harder search problem involving \nnatural language.  Again, the goal is not just to solve the task, as more general crosswords can be \nreadily solved with specialized NLP pipelines [ 34 ] that leverages large-scale retrieval instead of LM. \nRather, we aim to explore the limit of LM as a general problem solver that explores its own thoughts \nand guides its own exploration with deliberate reasoning as heuristics.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":7,"lines":{"from":157,"to":170}}}}],["5d1e6082-70b1-4e18-9089-fc2958e14b90",{"pageContent":"and guides its own exploration with deliberate reasoning as heuristics. \nTask setup. We scrape data from GooBix, which contains 156 games of 5 × 5 mini crosswords. As \nwe observe adjacent games contain similar clues, we use 20 games with indices 1 , 6 , ··· , 91 , 96 for \ntesting, and games 136 , 141 , 146 , 151 , 156 for prompting. For each task, the input describes the 5 \nhorizontal clues and 5 vertical clues, and the output should be a board of 5 × 5 = 25 letters to solve \nthe crosswords. For evaluation, we consider three levels of success: the portion of correct letters (25 \nper game), words (10 per game), and games. \nBaselines. We provide 5 example input-output pairs in the IO prompt, and in the CoT prompt \nadditionally include intermediate words in the order h1..5 then v1..5.  We run each prompt for 10 \nsamples and average the results. \nToT setup. We leverage a depth-first search (Algorithm 2) that keeps exploring the most promising","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":7,"lines":{"from":170,"to":180}}}}],["ecca9c1c-7842-49e6-b750-78170e159918",{"pageContent":"ToT setup. We leverage a depth-first search (Algorithm 2) that keeps exploring the most promising \nsubsequent word clue until the state is no longer promising, then backtrack to the parent state to \nexplore alternative thoughts. To make search tractable, subsequent thoughts are constrained not to \nchange any filled words or letters, so that the ToT has at most 10 intermediate steps.  For thought \ngeneration, at each state we translate all existing thoughts (e.g. “h2.motor; h1.tasks” for the state \nin Figure 6(a)) into letter constraints for remaining clues (e.g. “v1.To heap: tm ;...”) and prompt \na proposal prompt 5 times to come up with candidates for where and what to fill in the next word. \nImportantly, we also prompt the LM to give a confidence level for different thoughts, and aggregate \n7","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":7,"lines":{"from":180,"to":188}}}}],["bd25929b-ac04-4625-bff5-39eff1c16f80",{"pageContent":">\u000b\nY\u0016\u0011\u0003HORSH\n\u000f\u0003\u0016\u0011\u0015\f\u000f\u0003\u000b\nK\u0015\u0011\u0003YDOXH\n\u000f\u0003\u0015\u0011\u0013\f\u000f\u0003\u000b\nK\u0014\u0011\u0003SDUFK\n\u000f\u0003 \n\u0014\u0011\u001c\f\u000f\u0003\u000b\nY\u0018\u0011\u0003FRYHW\n\u000f\u0003\u0013\u0011\u0019\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0014\f\u000f\u0003\u000b\nK\u0015\u0011\u0003 \nPHULW\n\u000f\u0003\u0013\u0011\u0017\f\u000f\u0003\u000b\nY\u0014\u0011\u0003DOORZ\n\u000f\u0003\u0013\u0011\u0015\f\u000f\u0003\u000b\nY\u0015\u0011\u0003JULQG\n\u000f\u0003\u0013\u0011\u0014\f\u000f\u0003 \n\u000b\nK\u0017\u0011\u0003OHSHU\n\u000f\u0003\u0013\u0011\u0014\f@","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":8,"lines":{"from":1,"to":20}}}}],["8d2a6c8b-9d73-4d31-af1d-84f8aeb759d0",{"pageContent":"Y\u0016\u0011\u0003HORSH\n \n0XOWLSOH\u0003 \nUXQV \n3DUVH\u000f\u0003ILOWHU\u0003RXW\u0003 \nQRQ\u0010ILYH\u0010OHWWHU\u000f\u0003 \nVFRUH\u000f\u0003DJJUHJDWH \n&KRRVH\u0003 \n\u000bVRIW\u0003 \nVHOI\u0010FRQVLVWHQF\\\"\f \n\u0014\u0011 0D[ \n\u0015\u0011 0D[\u0003ZLWKRXW\u0003 \nYLRODWH \n\u0016\u0011 ')6 \nGĮŔũƜˤ\u001dĦũòŝ \nĎɿʛĭĵŤĵŗ \nĎɾʛƘÊŝģŝ \nĎʁʛŝÊĦĵĮ \nƘÊŝģŝ \nƘÊŝģŝ \nĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲ \nsʂʛˤŝŗíŗƆˤʱĦĵƀʲ \nsʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲ \nʟʟ \n7KRXJKW\u00033URSRVDOV \nÊĈĈŗòĈÊŤò \nsʀʛˤŗòŤòĮƜƓĵũŝʞˤƚĦĵƀòŗƆʝˤˈˈˈˈˈˤŝũŗò \n6WDWH\u0003(YDOXDWRU\u0003 \u000bRYHU\u0003HDFK\u0003FOXH\f \nsɾʛˤÉĵˤĎòÊŔʝˤƛĭˈŝˈˤ ʳʛʛʛʴ ˤđĭŔĵŝŝđæĦò \nsʂʛˤ#òŝƓççÊŤĵŗʞˤĭĵŗòˤíŗƆʝˤŝŗˈĮˈˤ ʳʛʛʛʴ ˤĭÊƆæò \nʟʟ \nʱæÊçģƜŗÊçģʲ \nĎʀʛĈŗÊĮí \nʟʟ \nʱŝũæƜŗòòˤŔŗũĮòíʲ \nĎʁʛˤŝÊĦĵĮ \nĎʀʛˤĈŗÊĮí \nsʀʛˤŝƜŗđĮĈ \nʟʟ \n')6\u0003 \n2UGHU \nĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲ \nsʂʛˤŝŗíŗƆˤʱĦĵƀʲ \nsʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲ \nʟʟ \n7KRXJKW\u00033URSRVDOV \nĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲ \nsʂʛˤŝŗíŗƆˤʱĦĵƀʲ \nsʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲ \nʟʟ \n7KRXJKW\u00033URSRVDOV \nĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲ \nsʂʛˤŝŗíŗƆˤʱĦĵƀʲ \nsʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲ \nʟʟ \n7KRXJKW\u00033URSRVDOV \nĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲ \nsʂʛˤŝŗíŗƆˤʱĦĵƀʲ \nsʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲ \nʟʟ \n7KRXJKW\u00033URSRVDOV \nʱÊʲ \nʱæʲ \nƛˤÊˤŝˤģˤŝ \nĭˤĵˤƛˤĵˤŗ \nˈˤˈˤˈˤˈˤˈ \nŝˤÊˤĦˤĵˤĮ \nˈˤˈˤˈˤˈˤˈ","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":8,"lines":{"from":22,"to":89}}}}],["7ef65dbd-2bc4-4471-8cb7-6d8bb9abc3a3",{"pageContent":"ʟʟ \n7KRXJKW\u00033URSRVDOV \nʱÊʲ \nʱæʲ \nƛˤÊˤŝˤģˤŝ \nĭˤĵˤƛˤĵˤŗ \nˈˤˈˤˈˤˈˤˈ \nŝˤÊˤĦˤĵˤĮ \nˈˤˈˤˈˤˈˤˈ \nFigure 6: In Mini Crosswords, (a) how thoughts are proposed and aggregated in a priority queue \nfor depth-first search (DFS), and (b) how a state is evaluated based on the possibility of filling in \neach remaining word clue, and pruned if any remaining clue is deemed not possible to fill by the LM. \nThen DFS backtracks to the parent state and explore the next promising thought for clue. \nthese across proposals to obtain a sorted list of next thoughts to explore (Figure 6(a)).  For state \nevaluations, we similarly translate each state into letter constraints for remaining clues, then evaluate \nfor each clue if it is possible to fill given the constraints. If any remaining clue is deemed “impossible” \nto fill in (e.g. “v1. To heap: tm s ”), then the exploration of the state’s subtree is pruned and DFS","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":8,"lines":{"from":81,"to":97}}}}],["a6331855-c72d-490d-9080-8ee1e6ace562",{"pageContent":"backtracks to its parent to explore the next promising thought. We limit DFS search steps to 100, and \nsimply render the deepest explored state (the first explored one if multiple) into the final output. \nResults. As shown in Table 3, IO and CoT prompting methods perform poorly with a word-level \nsuccess rate less than 16% , while ToT significantly improves all metrics, achieving a word-level \nsuccess rate of 60% and solving 4 out of 20 games. Such an improvement is not surprising, given IO \nand CoT lack mechanisms to try different clues, make changes to decisions, or backtrack. \nOracle and ablation studies. When outputting from the oracle best DFS state (instead of the \nheuristically determined best state) per task, ToT performance is even higher and actually solves \n7/20 games (Table 3, “+best state”), indicating our simple output heuristics can be readily improved. \nInterestingly, sometimes when the crosswords game is actually solved, the state evaluator might still","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":8,"lines":{"from":98,"to":107}}}}],["62a474fe-3b72-4a4b-828f-e179da7c0be2",{"pageContent":"deem some words as “impossible” and prune — possibly because 5 × 5 crosswords by design have \nsome rare or obselete words that GPT-4 cannot recognize \n2 \n. Given the state evaluation as a pruning \nheuristic is imperfect, we also explore ablating the pruning, and find the performance generally worse \n(Table 3, “-prune”). However, it could actually find the correct solution for 4/20 games (though only \noutputting 1 via heuristic), 3 of which are games ToT+pruning cannot solve within 100 steps. Thus, \nbetter heuristics for DFS pruning are critical for problem solving in this case. Lastly, we confirm the \nimportance of backtracking by running an ablation that keeps filling the most promising clue for at \nmost 20 steps, allowing overwrites. This is similar to a “greedy” BFS search with breadth limit of \nb = 1 , and performs poorly with a word level success of only 20% (Table 3, “-backtrack”). \n5    Related Work","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":8,"lines":{"from":108,"to":119}}}}],["6005f53d-063c-48db-9eb5-381804dd7dae",{"pageContent":"5    Related Work \nPlanning and decision making. Smart planning and decision making are critical to achieving \npredefined goals. As they are trained on vast amount of world knowledge and human examples, LMs \nare known to have already absorbed rich commonsense that makes it possible to propose reasonable \nplans conditioned on problem setting and environmental states [ 12 , 42 , 37 , 13 , 35 , 41 , 40 ].  Our \nproposed ToT approach extends existing planning formulations by considering multiple potentially \nfeasible plans simultaneously at each problem-solving step, and proceeding with the most promising \nones. The integration between thought sampling and value feedback organically integrates planning \nand decision-making mechanisms, enabling effective search inside a solution tree. On the other hand, \ntraditional decision-making procedures usually require training dedicated reward and policy models","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":8,"lines":{"from":119,"to":128}}}}],["b7ca19f1-ad41-4664-9048-acc6734a8029",{"pageContent":"traditional decision-making procedures usually require training dedicated reward and policy models \nas in reinforcement learning (for example CHAI [ 33 ]), whereas we use the LM itself to provide \nthe value estimates for decision making. RAP [ 9 ] is a concurrent work that treats language model \n2 \nFor example, “agend” is an obsolete form of “agendum”, but GPT-4 deems it a typo for “agenda”. External \nretrieval or web interaction could augment LM for problem solving under knowledge uncertainty. \n8","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":8,"lines":{"from":128,"to":134}}}}],["f47496a5-baf0-4423-82b9-01693e6621aa",{"pageContent":"reasoning as planning with its internal world model, and proposes a MCTS-based method similar to \nToT. However, its tasks are simpler than ours, and its framework lacks the modularity to incorporate \ndifferent tree search algorithms. \nSelf-reflection. Using LLMs to assess the viability of their own predictions is becoming an in- \ncreasingly important procedure in problem solving.  [ 28 , 20 , 24 ] introduced the “self-reflection” \nmechanism, in which LMs provide feedback to their generation candidates. [ 4 ] improves LMs code \ngeneration accuracy by injecting feedback messages generated by the LM itself based on its code \nexecution results. Similarly, [ 17 ] also introduces “critic” or review steps over the actions and states, \ndeciding the next action to take in solving computer operation tasks.  Another recent work very \nrelevant to ours is “self-eval guided decoding”   [ 39 ].  Similar to our method, self-eval decoding","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":9,"lines":{"from":1,"to":10}}}}],["60b5e96f-a85a-4ae1-b4ee-4121d099e6cc",{"pageContent":"also follows a tree-search procedure with leaves sampled from stochastic beam search decoding, \nwhich are then evaluated by LLM itself with carefully prepared self-eval prompts. Their approach \nhowever, uses the PAL formulation  [ 8 ] which represents thoughts as codes, which makes it difficult \nto tackle challenging tasks like creative writing which we consider in this paper. Our Tree-of-Thought \nformulation is thus more versatile and handles challenging tasks on which GPT-4 only achieves very \nlow accuracy with standard prompts. \nProgram-guided LLM generation. Our proposal is also related to recent advancements that organize \nLM’s behavior with systematic procedures [ 14 , 44 , 6 , 43 ] or symbolic program guidance. For example, \nSchlag et al. [27] embeds LMs in an algorithmic search procedure to help solve problems like question \nanswering step-by-step, in which the search trees are expanded by relevant paragraphs that might","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":9,"lines":{"from":11,"to":20}}}}],["4ef15520-254c-4919-af75-f2b735b460ac",{"pageContent":"answering step-by-step, in which the search trees are expanded by relevant paragraphs that might \nprovide answers. This approach however differs from ours in that trees are expanded by sampling \nexternal paragraphs instead of the LM’s own thoughts, and there is no reflection or voting steps. \nAnother approach, LLM+P [ 18 ], goes one step further and delegates the actual planning process to a \nclassical planner. \nClassical search methods. Last but not least, our approach can be treated as a modern rendition \nof classical search methods for problem solving.  For example it can be considered as a heuristic \nsearch algorithm like A* [ 10 ], in which the heuristic at each search node is provided by the LM’s self- \nassessment. From this perspective, our method is also related to NeuroLogic A*esque decoding [ 19 ], \nwhich is inspired by A* search but introduces look-ahead heuristics that are efficient for LMs to","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":9,"lines":{"from":20,"to":29}}}}],["a6fe5ea8-2ce5-4cf0-97e0-a8270526c019",{"pageContent":"which is inspired by A* search but introduces look-ahead heuristics that are efficient for LMs to \nimprove the beam-search or top-k sampling decoding.   This method however is constrained to \nsentence generation tasks, whereas our framework are designed for complex, multi-step problem \nsolving guarded by value feedback. \n6    Discussion \nLimitations and future directions. Deliberate search such as ToT might not be necessary for many \nexisting tasks that GPT-4 already excels at (see Appendix B.1), and as an initial step this work only \nexplores three relatively simple tasks that challenges GPT-4 (see Appendix B.2 for some GPT-3.5 \nexperiment results) and calls of better search and planning abilities incorporated with LMs. However, \nas we begin to deploy LMs for more real-world decision making applications (e.g. coding, data \nanalysis, robotics, etc.), more complex tasks could emerge and present new opportunities to study","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":9,"lines":{"from":29,"to":39}}}}],["25384b49-6a2a-419b-a7ac-4311c53f12b7",{"pageContent":"analysis, robotics, etc.), more complex tasks could emerge and present new opportunities to study \nthese research questions. Also, search methods like ToT requires more resources (e.g. GPT-4 API \ncost) than sampling methods in order to improve task performances, but the modular flexibility of \nToT allows users to customize such performance-cost tradeoffs, and ongoing open-source efforts [ 32 ] \nshould readily reduce such costs in the near future.  More details about cost and efficiency are in \nAppendix B.3. Lastly, this work focuses on using an off-the-shelf LM, and fine-tuning LMs using \na ToT-style high-level counterfactual decision making (e.g. deliberating over potential choices for \nthe next paragraph, instead of predicting the next token) might present opportunities to enhance the \nproblem-solving capabilities of LMs. \nConclusion. The associative “System 1” of LMs can be beneficially augmented by a “System 2”","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":9,"lines":{"from":39,"to":48}}}}],["38999075-bd1e-4ca7-b6b7-5ff8362bac75",{"pageContent":"Conclusion. The associative “System 1” of LMs can be beneficially augmented by a “System 2” \nbased on searching a tree of possible paths to the solution to a problem.  The Tree of Thoughts \nframework provides a way to translate classical insights about problem-solving into actionable \nmethods for contemporary LMs.  At the same time, LMs address a weakness of these classical \nmethods, providing a way to solve complex problems that are not easily formalized, such as creative \nwriting. We see this intersection of LMs with classical approaches to AI as an exciting direction. \n9","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":9,"lines":{"from":48,"to":54}}}}],["8ba4a82e-d5e9-4a34-9258-856145cf4a1c",{"pageContent":"Broader Impact \nToT is a framework that empowers LMs to more autonomously and intelligently make decisions \nand solve problems.   While current tasks are limited to reasoning and search problems,  future \napplications involving interaction with external environments or humans could bring potential danger, \ne.g. facilitating harmful uses of LMs.  On the other hand, ToT also improves the interpretability \nof model decisions and the opportunity for human alignment, as the resulting representations are \nreadable, high-level language reasoning instead of implicit, low-level token values. \nAcknowledgements \nSY and KN acknowledge support from an Oracle Collaborative Research award and the National \nScience Foundation under Grant No. 2239363. Any opinions, findings, conclusions, or recommenda- \ntions expressed in this material are those of the author(s) and do not necessarily reflect the views of \nthe National Science Foundation. SY is also supported by the Harold W. Dodds Fellowship from","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":10,"lines":{"from":1,"to":12}}}}],["15b73d6b-9efc-4a86-946e-f887ce687ebd",{"pageContent":"the National Science Foundation. SY is also supported by the Harold W. Dodds Fellowship from \nPrinceton. \nReferences \n[1] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, \nG. Sastry,  A. Askell,  et al.   Language models are few-shot learners. Advances in neural \ninformation processing systems , 33:1877–1901, 2020. \n[2] \nC. Browne, E. J. Powley, D. Whitehouse, S. M. M. Lucas, P. I. Cowling, P. Rohlfshagen, \nS. Tavener, D. P. Liebana, S. Samothrakis, and S. Colton. A survey of monte carlo tree search \nmethods. IEEE Transactions on Computational Intelligence and AI in Games , 4:1–43, 2012. \n[3] M. Campbell, A. J. Hoane Jr, and F.-h. Hsu. Deep blue. Artificial intelligence , 134(1-2):57–83, \n2002. \n[4] X. Chen, M. Lin, N. Sch \n ̈ \narli, and D. Zhou. Teaching large language models to self-debug, 2023. \n[5] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":10,"lines":{"from":12,"to":27}}}}],["8d89faba-df12-4fe3-a4b0-2143e8e074fd",{"pageContent":"[5] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. \nChung, C. Sutton, S. Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv \npreprint arXiv:2204.02311 , 2022. \n[6] A. Creswell and M. Shanahan. Faithful reasoning using large language models. arXiv preprint \narXiv:2208.14271 , 2022. \n[7] N. D. Daw, Y. Niv, and P. Dayan.   Uncertainty-based competition between prefrontal and \ndorsolateral striatal systems for behavioral control. Nature neuroscience , 8(12):1704–1711, \n2005. \n[8] \nL. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y. Yang, J. Callan, and G. Neubig. Pal: Program- \naided language models, 2023. \n[9] S. Hao, Y. Gu, H. Ma, J. J. Hong, Z. Wang, D. Z. Wang, and Z. Hu. Reasoning with language \nmodel is planning with world model. arXiv preprint arXiv:2305.14992 , 2023. \n[10] P. E. Hart, N. J. Nilsson, and B. Raphael.  A formal basis for the heuristic determination of","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":10,"lines":{"from":27,"to":40}}}}],["4b3623c9-9629-460e-8091-b40a2268a7f6",{"pageContent":"[10] P. E. Hart, N. J. Nilsson, and B. Raphael.  A formal basis for the heuristic determination of \nminimum cost paths. IEEE Transactions on Systems Science and Cybernetics , 4(2):100–107, \n1968. doi: 10.1109/TSSC.1968.300136. \n[11] \nP. E. Hart, N. J. Nilsson, and B. Raphael.  A formal basis for the heuristic determination of \nminimum cost paths. IEEE transactions on Systems Science and Cybernetics , 4(2):100–107, \n1968. \n[12] \nW. Huang, P. Abbeel, D. Pathak, and I. Mordatch.  Language models as zero-shot planners: \nExtracting actionable knowledge for embodied agents, 2022. \n[13] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Florence, A. Zeng, J. Tompson, I. Mordatch, \nY. Chebotar, et al.  Inner monologue:  Embodied reasoning through planning with language \nmodels. arXiv preprint arXiv:2207.05608 , 2022. \n10","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":10,"lines":{"from":40,"to":53}}}}],["db01c997-2b34-4a5f-8cf3-29c84360a364",{"pageContent":"[14] J. Jung, L. Qin, S. Welleck, F. Brahman, C. Bhagavatula, R. L. Bras, and Y. Choi.  Maieu- \ntic prompting:  Logically consistent reasoning with recursive explanations. arXiv preprint \narXiv:2205.11822 , 2022. \n[15]  D. Kahneman. Thinking, fast and slow . Macmillan, 2011. \n[16] D. Kahneman, S. Frederick, et al. Representativeness revisited: Attribute substitution in intuitive \njudgment. Heuristics and biases: The psychology of intuitive judgment , 49(49-81):74, 2002. \n[17]  G. Kim, P. Baldi, and S. McAleer. Language models can solve computer tasks, 2023. \n[18] \nB. Liu, Y. Jiang, X. Zhang, Q. Liu, S. Zhang, J. Biswas, and P. Stone.  Llm+p: Empowering \nlarge language models with optimal planning proficiency, 2023. \n[19] X.  Lu,  S.  Welleck,  P.  West,  L.  Jiang,  J.  Kasai,  D.  Khashabi,  R.  L.  Bras,  L.  Qin,  Y.  Yu, \nR. Zellers, N. A. Smith, and Y. Choi. Neurologic a*esque decoding: Constrained text generation","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":11,"lines":{"from":1,"to":12}}}}],["c3be96cd-4fbd-4c53-b7b5-cd0c4c555eb6",{"pageContent":"R. Zellers, N. A. Smith, and Y. Choi. Neurologic a*esque decoding: Constrained text generation \nwith lookahead heuristics. In North American Chapter of the Association for Computational \nLinguistics , 2021. \n[20] \nA.  Madaan,  N.  Tandon,  P.  Gupta,  S.  Hallinan,  L.  Gao,  S.  Wiegreffe,  U.  Alon,  N.  Dziri, \nS. Prabhumoye, Y. Yang, S. Welleck, B. P. Majumder, S. Gupta, A. Yazdanbakhsh, and P. Clark. \nSelf-refine: Iterative refinement with self-feedback, 2023. \n[21] A. Newell, J. C. Shaw, and H. A. Simon. Report on a general problem solving program. In IFIP \ncongress , volume 256, page 64. Pittsburgh, PA, 1959. \n[22]  A. Newell, H. A. Simon, et al. Human problem solving . Prentice-Hall, 1972. \n[23]  OpenAI. Gpt-4 technical report. ArXiv , abs/2303.08774, 2023. \n[24] \nD. Paul, M. Ismayilzada, M. Peyrard, B. Borges, A. Bosselut, R. West, and B. Faltings. Refiner: \nReasoning feedback on intermediate representations, 2023.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":11,"lines":{"from":12,"to":25}}}}],["9b7da567-3cb3-41ed-9948-42cdf05629ca",{"pageContent":"Reasoning feedback on intermediate representations, 2023. \n[25] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever, et al. Improving language understanding \nby generative pre-training. OpenAI blog , 2018. \n[26] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al.  Language models are \nunsupervised multitask learners. OpenAI blog , 1(8):9, 2019. \n[27] \nI. Schlag, S. Sukhbaatar, A. Celikyilmaz, W. tau Yih, J. Weston, J. Schmidhuber, and X. Li. \nLarge language model programs, 2023. \n[28] N. Shinn, B. Labash, and A. Gopinath. Reflexion: an autonomous agent with dynamic memory \nand self-reflection, 2023. \n[29] \nD. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker, \nM. Lai, A. Bolton, et al.  Mastering the game of go without human knowledge. nature , 550 \n(7676):354–359, 2017. \n[30] \nS. A. Sloman. The empirical case for two systems of reasoning. Psychological bulletin , 119(1): \n3, 1996. \n[31]","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":11,"lines":{"from":25,"to":42}}}}],["52d5f79a-8b61-4ded-a08a-26be48333661",{"pageContent":"3, 1996. \n[31] \nK. E. Stanovich. Who is rational? Studies of individual differences in reasoning . Psychology \nPress, 1999. \n[32] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozi \n` \nere, N. Goyal, \nE. Hambro, F. Azhar, et al.  Llama:  Open and efficient foundation language models. arXiv \npreprint arXiv:2302.13971 , 2023. \n[33] S. Verma, J. Fu, S. Yang, and S. Levine.  Chai: A chatbot ai for task-oriented dialogue with \noffline reinforcement learning. In Proceedings of the 2022 Conference of the North American \nChapter of the Association for Computational Linguistics:  Human Language Technologies , \npages 4471–4491, 2022. \n11","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":11,"lines":{"from":41,"to":54}}}}],["4349b1d4-ab12-46d6-b345-3701363db9fb",{"pageContent":"[34] E. Wallace, N. Tomlin, A. Xu, K. Yang, E. Pathak, M. Ginsberg, and D. Klein.  Automated \ncrossword solving. arXiv preprint arXiv:2205.09665 , 2022. \n[35] L. Wang, W. Xu, Y. Lan, Z. Hu, Y. Lan, R. K.-W. Lee, and E.-P. Lim. Plan-and-solve prompting: \nImproving zero-shot chain-of-thought reasoning by large language models, 2023. \n[36] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, and D. Zhou. Self-consistency improves chain \nof thought reasoning in language models. arXiv preprint arXiv:2203.11171 , 2022. \n[37] Z. Wang, S. Cai, A. Liu, X. Ma, and Y. Liang. Describe, explain, plan and select: Interactive \nplanning with large language models enables open-world multi-task agents, 2023. \n[38] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi, Q. Le, and D. Zhou.  Chain of thought \nprompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903 , 2022. \n[39] Y. Xie, K. Kawaguchi, Y. Zhao, X. Zhao, M.-Y. Kan, J. He, and Q. Xie.   Decomposition","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":12,"lines":{"from":1,"to":11}}}}],["c915a4dc-3b02-4fe2-9300-c4c848470888",{"pageContent":"[39] Y. Xie, K. Kawaguchi, Y. Zhao, X. Zhao, M.-Y. Kan, J. He, and Q. Xie.   Decomposition \nenhances reasoning via self-evaluation guided decoding, 2023. \n[40] S. Yang, O. Nachum, Y. Du, J. Wei, P. Abbeel, and D. Schuurmans.  Foundation models for \ndecision making: Problems, methods, and opportunities, 2023. \n[41] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y. Cao.  ReAct: Synergizing \nreasoning and acting in language models. arXiv preprint arXiv:2210.03629 , 2022. \n[42] S. Zhang, Z. Chen, Y. Shen, M. Ding, J. B. Tenenbaum, and C. Gan.  Planning with large \nlanguage models for code generation. In The Eleventh International Conference on Learning \nRepresentations , 2023. URL https://openreview.net/forum?id=Lr8cOOtYbfL . \n[43] D. Zhou, N. Sch \n ̈ \narli, L. Hou, J. Wei, N. Scales, X. Wang, D. Schuurmans, C. Cui, O. Bousquet, \nQ. Le, et al.  Least-to-most prompting enables complex reasoning in large language models. \narXiv preprint arXiv:2205.10625 , 2022.","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":12,"lines":{"from":11,"to":24}}}}],["99922763-4a56-4870-b319-2db4e9aa0ec4",{"pageContent":"arXiv preprint arXiv:2205.10625 , 2022. \n[44] X. Zhu, J. Wang, L. Zhang, Y. Zhang, R. Gan, J. Zhang, and Y. Yang.  Solving math word \nproblem via cooperative reasoning induced language models. arXiv preprint arXiv:2210.16257 , \n2022. \n12","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":12,"lines":{"from":24,"to":28}}}}],["df60b12a-a657-4b2c-b5c6-e446a8964a4c",{"pageContent":"A    Code, Prompts, Trajectories \nAll code is available at https://github.com/princeton-nlp/tree-of-thought-llm . \nAll prompts are available at https://github.com/princeton-nlp/tree-of-thought-llm/ \ntree/master/src/tot/prompts . \nTrajectories are available at https://github.com/princeton-nlp/tree-of-thought-llm/ \ntree/master/logs . \nB    Additional Experiment Results \nGiven the motivation of exploring and extending the capability frontier of language models, our \nexperiments in the main paper have focused on a setup with the state-of-the-art language model \n(GPT-4), and three hard tasks invented to challenge it. Here, we report additional experiments with \nweaker LLM or easier tasks, and discuss cost and efficiency. \nGSM8K StrategyQA \nIO 51 73 \nCoT 86 82 \nToT 90 83 \nTable 4: New tasks with \nzero-shot ToT and GPT-4. \nGPT-4 GPT-3.5 \nIO 7.3% 6% \nCoT 4.0% 3% \nToT 74% 19% \nTable 5: Game of 24 with \nGPT-4 vs GPT-3.5. \nGPT-4 GPT-3.5 \nIO 6.19 4.47 \nCoT 6.93 5.16 \nToT 7.56 6.62","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":13,"lines":{"from":1,"to":27}}}}],["e1d361d4-5c43-4550-966a-34b80c549635",{"pageContent":"GPT-4 vs GPT-3.5. \nGPT-4 GPT-3.5 \nIO 6.19 4.47 \nCoT 6.93 5.16 \nToT 7.56 6.62 \nTable 6: Creative Writing with \nGPT-4 vs. GPT-3.5. \nB.1    Extension to new tasks (GSM8k, StrategyQA) with zero-shot ToT \nWhile more common NLP tasks might be too easy for GPT-4 and do not require ToT (which is why \nwe considered harder new tasks), we believe applying ToT to new tasks could be straightforward. \nFor example, we implemented a simple and generic zero-shot ToT-BFS similar to creative writing \n(sample 5 problem solving strategies then vote for the best one; then sample 5 solutions based on the \nbest strategy then vote for the best one) for GSM8K and StrategyQA with few extra lines of code: \n# define the answer format of new tasks \ngsm8k_format = ‘\"the answer is n\" where n is a number’ \nstrategyqa_format = ‘either \"the answer is yes\" or \"the answer is no\"’ \n# define zero-shot io prompting \nstandard_prompt = ‘Answer the following question with {format}: {input}’","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":13,"lines":{"from":23,"to":40}}}}],["8d12efc5-dd28-40f8-824b-0bb310d71534",{"pageContent":"standard_prompt = ‘Answer the following question with {format}: {input}’ \n# define thought format for zero-shot cot and zero-shot tot \ncot_prompt = ‘‘‘Answer the following question: {input} \nMake a strategy then write. Your output should be of the following format: \nStrategy: \nYour strategy about how to answer the question. \nAnswer: \nYour answer to the question. It should end with {format}. \n’’’ \n# define zero-shot voting used for zero-shot tot \nvote_prompt = ‘‘‘Given an instruction and several choices, \ndecide which choice is most promising. \nAnalyze each choice in detail, then conclude in the last line \n\"The best choice is {s}\", where s the integer id of the choice. \n’’’ \n13","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":13,"lines":{"from":40,"to":55}}}}],["e6142d16-5aae-4386-8d60-6abb9646930a",{"pageContent":"We evaluated on a subset of 100 random GSM8K test and StrategyQA dev questions.  As shown \nin Table 4 and as expected, ToT improves over CoT on both tasks (but only slightly, given GPT-4 \n+ CoT is already very good on such tasks, and StrategyQA’s bottleneck is external knowledge, not \nreasoning).  Considering computational costs, it is more suitable to try smaller LLMs + ToT for \ntraditional NLP tasks, or GPT-4 + ToT for hard tasks that challenge GPT-4 + CoT’s reasoning. \nB.2    Extension to new LMs (GPT-3.5) \nTo understand how ToT works with other LLMs, we also ran GPT-3.5-turbo for Creative Writing \n(Table 6) and Game of 24 (Table 5). On both tasks, “ToT > CoT > IO” remains true for GPT-3.5. On \nCreative Writing, we find GPT-3.5+ToT outperform GPT-4+IO, and similar to GPT-4+CoT, which \nsuggests ToT could also work well on weaker language models. \nOn Game of 24 (we changed 1-shot proposal prompt to 3-shot to make it work), GPT-3.5+ToT’s","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":14,"lines":{"from":1,"to":11}}}}],["abae7953-09fa-4260-84e4-9d5d9ebe98ff",{"pageContent":"On Game of 24 (we changed 1-shot proposal prompt to 3-shot to make it work), GPT-3.5+ToT’s \n19% is far worse than GPT-4+ToT’s 74%.  To further understand the importance of generation \nvs.  evaluation, we ran GPT-4 generation + GPT-3.5 evaluation (64%) and GPT-3.5 generation + \nGPT-4 evaluation (31%). This suggests the game’s bottleneck is thought generation, and different \ngeneration/evaluation language models might attain decent results while reducing costs. \nB.3    Cost and efficiency \nRunning ToT requires significantly more computations than IO or CoT prompting. For example, in \nGame of 24 (Table 7 below), solving a problem with ToT requires 5.5k completion tokens, close to \n100 CoT trials (6.7k tokens). But the performance of ToT is better than best of 100 independent CoT \ntrials. \nGame of 24 Generate/Prompt tokens Cost per case Success \nIO (best of 100) 1.8k / 1.0k $0.13 33% \nCoT (best of 100) 6.7k / 2.2k $0.47 49% \nToT 5.5k / 1.4k $0.74 74%","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":14,"lines":{"from":11,"to":24}}}}],["b4835f1c-a5ad-4f76-858b-d856655b308d",{"pageContent":"CoT (best of 100) 6.7k / 2.2k $0.47 49% \nToT 5.5k / 1.4k $0.74 74% \nTable 7: Cost analysis on Game of 24. \nOn Creative Writing (Table 8 below), we found ToT takes around 5x completion tokens and money \ncost, which is intuitive as b = 5 and most tokens are generated passages. \nCreative Writing Generate/Prompt tokens Cost per case \nIO 0.9k / 0.4k $0.06 \nCoT 0.9k / 0.4k $0.07 \nToT 4k / 2.9k $0.32 \nTable 8: Cost analysis on Game of 24. \nSo completing Game of 24 and Creative Writing’s main ToT experiments cost around 0 . 74 × 100 + \n0 . 32 × 100 = 106 \ndollars.  Crosswords’ DFS experiments should be also within 100 dollars.  In \ngeneral, cost and efficiency of ToT highly depend on the prompts and search algorithms used, and \ncould require 5-100 times more generated tokens than CoT. Some actionable insights: \n• We recommend using ToT on tasks requiring deliberate reasoning, on which CoT struggles. \n• Flexibility of ToT allows some performance-cost tradeoff, e.g., change beam size or vote","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":14,"lines":{"from":23,"to":39}}}}],["ee0d8566-8edb-4a87-92e7-ff9e5f4ec334",{"pageContent":"• Flexibility of ToT allows some performance-cost tradeoff, e.g., change beam size or vote \nnumber in BFS, few-shot vs.  zero-shot prompting, GPT-3.5 vs.  GPT-4, etc.  One could \nconfigure the setup based on some resource constraints or performance goal. \n• There is much space for improving efficiency, e.g., BFS could early stop when solution is \nfound, or trim down beam size to when some thoughts are ”impossible”. \n• We believe that more computation is indeed required in order for the model to achieve \nstronger intelligence, and this should not become a blocking issue as in the long run, (open- \nsource) LMs will become much cheaper and more efficient. It is also a great direction how \nto better train/finetune LMs for thought generation and/or evaluation. \n14","metadata":{"source":"/Users/monolith/development/caretakerai/packages/examples/qna/docs/2305.10601.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"","Subject":"","Keywords":"","Creator":"LaTeX with hyperref","Producer":"pdfTeX-1.40.25","CreationDate":"D:20231205013901Z","ModDate":"D:20231205013901Z","Trapped":{"name":"False"}},"metadata":null,"totalPages":14},"loc":{"pageNumber":14,"lines":{"from":39,"to":48}}}}]],{"0":"5a323793-6a88-468c-92bb-4788bbca583a","1":"067b4fca-9edd-42dc-8340-ff106110c4e2","2":"662b7a80-6989-4aac-9b05-462a915ced23","3":"2b1a36ad-83d9-4628-bcc4-d794a5f0e63d","4":"76b11398-cf15-4c8c-9109-51c35d9aefd4","5":"d4fa0698-cb85-4895-8274-01a0be87c027","6":"7490db50-6757-4e85-946c-4c58402ca62c","7":"93069a15-be84-4d54-9dd3-a3f8fb8fa9b2","8":"36856f99-dab0-4be8-b77a-60a7274a59f3","9":"344a3b5d-831e-444a-9db0-799e52549898","10":"a4e61888-5fc2-4fe4-a31d-8d42e1416a09","11":"46a0a88e-8bda-4398-8fbe-4a70ebabc932","12":"803eb8ab-f8fa-493d-b444-ab548ad28e6b","13":"93bc4d7d-882e-4d8b-a8e7-aba10d1d01e4","14":"8adc40d8-d6c3-4b0f-95bf-3ad3923aad27","15":"064cd279-7d12-4ef2-b083-52894ef13d3c","16":"113ec91b-d939-4cf6-bb57-f399eee6757e","17":"c2e0b5d5-3ae4-4da1-966e-726df4239762","18":"29811b1f-c7c9-4fe9-be33-03a87e516d31","19":"8785db32-edae-4eba-8c45-0796d4997eaf","20":"a1965dcc-789a-4f86-8a7e-2a569ca964dc","21":"11a179c2-86de-4ab9-b79d-9ae5c1255a8c","22":"f5f79304-2867-4af9-9b7c-316f2e802946","23":"0fa77011-d21d-49aa-abae-20a05d13e84f","24":"f8b5480c-966d-49c9-a021-125cfca89aae","25":"80b5fb94-e9d6-406c-9326-937d9a0b6a26","26":"d1f81ffc-36ad-44da-9514-9ae5a44b1004","27":"b0ed145b-69eb-43c0-9a0d-540b45847260","28":"86add572-986e-4ce5-b404-2316009f8383","29":"93bd4fc8-8ed9-4a11-aef0-52cfdfb0af5f","30":"4d947d4d-0abb-4f1f-b98f-a080820afec2","31":"09a8f71f-0ac3-4cf5-a0f3-ba3f4afc0262","32":"2dd73982-a6ad-4f67-8ed9-b17c6e547c35","33":"b8166990-0da5-4bdd-b036-bd6ac4d48f7e","34":"fe998a5d-fffe-4695-80ca-c453bc4fe1ef","35":"2eab8b28-fb42-4393-8e20-949d3fdd99a2","36":"5c5e8e1c-0936-4ac2-bb21-8e689f85e107","37":"79d9e314-88cd-4fcf-bff0-2cec9e328cf9","38":"a35418a6-2539-40ca-a176-bf17dfb5023c","39":"ecc436c1-5a38-4376-afae-d3d75f2dbb2e","40":"948f0229-29cc-486c-a7b0-7f8ed580a9d9","41":"a71c55e1-64d6-43a2-b385-34379fde9b2b","42":"b8b456a2-5e00-475d-9f25-c774df27d411","43":"9c278183-ff73-406c-86ee-a483e8ee5172","44":"89c6eb4e-3b5b-4f61-9cec-d3acc70f5462","45":"950b37ab-3de2-452e-a4dd-9ff0c5d386fd","46":"4363bc82-5e74-4087-88d9-ce1c7ee08a10","47":"313208dc-ea47-47ee-bedd-45bcf839ccb1","48":"d639d85a-3f3a-457d-8195-1e44f7eb05ef","49":"a6712d82-fe5d-41f6-aff8-c1d8d116dd09","50":"f7cfe6a0-91eb-41b0-a35a-9222d75f2ed8","51":"fc17675d-5641-4d98-accd-309151aa6ccf","52":"1c425e92-128c-4791-99e2-cdbfc6d1f76e","53":"6ea30ba8-6d5d-4ab8-b131-f89424b9db7f","54":"736511fe-84eb-4837-8543-0f5802136977","55":"a640536b-3aae-4494-ab2f-d17a74b16789","56":"eac08881-a722-4421-be89-46ae40f1f943","57":"0085e8f9-f3d3-443c-8d57-0a295b1de235","58":"ff0d9701-24da-43c9-9af4-4112d062aa90","59":"75e4e32c-a072-49a7-b96e-e76e0c11c98a","60":"0be19fbc-a744-4034-906a-985ba504d598","61":"889ebb26-2c24-4e0d-b0e6-662b809aa638","62":"50ba420c-dc4f-4167-b555-2634811f7cdf","63":"bd87a5a7-a9f9-4cf7-af8b-c2dd234f53de","64":"9b59e8b8-80bd-49dc-aa13-54d05e78f93d","65":"19fa1b8e-56ce-4aa1-81cf-89bf60182828","66":"b7194b04-a934-4d99-9690-fd537f7d6bcc","67":"0101b84a-59aa-42d7-96da-462ef2fb5869","68":"78a23e55-e209-4707-8187-680322e16db2","69":"41b20cb5-d57e-4583-8d3f-93ffc664bddd","70":"e6913cd4-6cec-4f73-a322-d4e6561da293","71":"dc994b3c-3387-4410-b772-1aba93912073","72":"259f4c54-659e-4620-8f41-0fed38eb0ea5","73":"bf1b5295-2712-4194-975f-5d149ecf91b9","74":"d56339af-d49d-42da-92a3-151051b368c5","75":"ff5f3a77-e073-467b-b307-ec87c7c7be20","76":"a0669ea8-9344-448d-b796-fece044cb641","77":"c447ac5c-53a9-45f5-97d5-548bbdd9e230","78":"33ee9602-fcf8-434b-b121-6b2fed0cf066","79":"1e68b8b3-39d6-4ad5-bec8-f0284e78b0bf","80":"abe627fd-49f8-4440-bebd-244926a57b93","81":"416e842d-1702-43be-a02f-84fa90b50e5b","82":"47f199a8-acfe-49a3-9d37-5551b89be343","83":"6abdf02a-40f0-4670-8eea-415c1b97ad18","84":"139ce0b4-ea64-45bb-8503-eb8b5e539879","85":"c389ad2e-fb6a-4206-b44c-aba0ca058813","86":"92244ba5-5a5b-4508-a7d2-d67f2ca2d064","87":"792ae62b-62be-49d7-b4f1-e579a1e65d32","88":"431213de-4885-4120-b137-9dc8574f67a9","89":"1416b2b2-7141-428e-9e31-51dc6f62ed10","90":"dfc14de6-7a7b-460e-a7ce-4815a4537900","91":"91764852-9ce8-4993-8f08-6e2e42381787","92":"ca43e7af-5ea9-4d04-8e62-eb1f7bdcec38","93":"e29c4b14-4b36-491e-b0c3-14c1685cb123","94":"df5f19fe-2405-4f84-8187-2b77e6a7ef23","95":"864f2082-b616-40de-b0c0-0d813fd13bce","96":"1af5f11a-d12b-414d-9942-b85c6cadbd62","97":"6e99f604-9011-47ac-8ccc-7761ab70f714","98":"0489f845-6dee-4fd4-a766-5dfed3415147","99":"c23a9908-50ca-47ce-9daa-8d4e037de1d9","100":"5fc0f6ec-59c9-483e-912f-e0ade31df874","101":"24b2c15d-ef24-4533-a66c-276c8db1f237","102":"e0a23f28-91e4-4b3d-baf8-c62059332725","103":"f9a2bd38-f2ee-4c2b-920e-c1729d70044f","104":"b9b4a0bc-f8b7-48d4-8831-644008597099","105":"f0a1602a-7d86-4860-8351-7a9a917d7eab","106":"ed9623f7-011c-4bd6-abe9-40546ed4f412","107":"4c35abd7-ec41-4dc3-93d8-ed082baa8fb3","108":"e07f6825-83fb-47cb-b0e6-92be1d157896","109":"18254b8f-1849-45ce-8a67-b9ee42cef750","110":"94239737-3e55-4de5-86bf-013bb3cf64f6","111":"2f55842b-0db7-46e3-bfd8-d1871823b1c5","112":"49b4b499-a492-4240-908b-dfa8fef51b64","113":"54cb2486-e1cc-41a4-a15d-4441fa9e3910","114":"b7f91d8a-f24f-41f0-b450-0ae41a942f9f","115":"cd11dd50-e82e-427b-9823-72c3dfe4774c","116":"beb5ca0d-94d5-4175-b29e-3be384f03a6d","117":"68147395-10a5-41ee-b094-fcb89767c6a5","118":"42216210-c07b-4941-b65d-46490028d8e2","119":"a0b0af3b-b8dd-44cf-91cf-0e0a78fed060","120":"e726dcb7-49ad-41c3-b4f2-d66ab0d05cc7","121":"d2c2e63f-25eb-44ee-b8da-2156eeb50fdb","122":"4008810d-5dfd-4e5b-b34e-0c64c8d01694","123":"f9e1f5e5-00d4-4d9b-a94a-ea295f3617fc","124":"b85a8d66-eafd-43f9-81e1-32789323aaa2","125":"495a3f0a-3bce-4145-8330-5286f6a641b2","126":"432bfd63-85eb-49cf-ade2-2c0d4cf4fa28","127":"cfc0c0c1-df0c-4d2f-b5e4-3dc0ea51e4d2","128":"16695463-ac13-43a5-aea7-3e25bbdc705c","129":"0d03c275-751a-4166-9594-822b9c9732e0","130":"4b1c8a96-6023-477d-a120-e2f313a94f2f","131":"689dcc64-ee65-4813-b869-b945e90553b3","132":"1a638dc1-474c-4250-a866-ecb4ff70d93f","133":"71bd5777-e2a4-4fe1-a9e9-284309d34158","134":"dbbda8f7-37a5-4d5b-9ee6-42d86b6c25ec","135":"1eb587ec-9ae1-46b4-8167-6d1e8643fbed","136":"16918ee6-5c93-4abf-9f20-00c4ab550e5f","137":"1f3aed63-0edf-4953-9622-c8882551bb47","138":"aeaa313d-32e6-41b1-a58f-5f5308a3bb6b","139":"bc8a2c4a-c399-40ca-8355-03c15a4df224","140":"098a15e0-8e84-4bda-a265-a7a6ced5a8f3","141":"8494954e-889d-4e7a-9dc2-c24b9173738f","142":"a7c24704-f52e-42cf-ab36-dde214729a3b","143":"531da685-4c31-4483-80f6-d6ed4204afe6","144":"29f1a772-cfca-4df4-aad9-c065d13c7bbd","145":"432b1704-5f1e-4de8-ab9d-489223cf653b","146":"cb4fa791-40db-44af-b601-2c50a147d6ac","147":"f41ab95d-d12a-40f1-a150-5c431bc2b0a0","148":"01649888-9ad4-43ac-a282-e708de15ef7b","149":"c3b6ddf5-bb8f-410d-92d8-a1cc80e4b3d6","150":"e0f21b0c-5674-4092-9885-5ee454b2dfc2","151":"e33b4213-26ac-4247-9853-7113cc6c29df","152":"0558e601-ee1c-4661-9903-0c5ac9dffc0d","153":"60eafbcc-ae4d-4749-a1c3-4facf855affc","154":"a2d33598-3aa0-4230-a2c8-7dbc11182cb5","155":"dff395f0-6051-497a-a35c-b87b7f02ee42","156":"4cd05642-1229-4010-beab-6ee3b8ae866c","157":"edb3f527-b3c8-443b-8a01-b962efbec6dc","158":"fc8e73c0-b950-4ee4-9d28-d94c3f2146db","159":"1e5912ef-5113-4b6d-b592-48155ea9fff5","160":"de2ce809-4529-4282-8d44-ec5d3bb46b58","161":"f2948f36-b1b9-4805-954d-c9dbf194347c","162":"0d407f55-9375-479e-a8e6-27caaf5b19bb","163":"3223d207-a446-4fa4-bd10-c44df7bcd8c1","164":"8304525d-4a2a-46d3-b58d-a20d80cd1eeb","165":"7b8ccdaf-4eb5-4b36-b4aa-a05325e3f9a9","166":"7d1612d5-ad29-45b3-b0b1-7731f73b6410","167":"d7378e9e-340e-48ca-96aa-27e30b8d926c","168":"8732565c-7c70-41c2-a7c9-831fcd88f8f2","169":"aaf7dce1-5b7d-485c-be93-c7c464964aa7","170":"9fdd0133-5403-4605-9afe-8ebcbfea3269","171":"94ad819f-9219-473b-b140-d245b205f949","172":"1d5603ec-2ea1-48a3-8301-49592fd5a3a6","173":"a62a7771-06bf-4d35-8a4f-1c884c2aff4a","174":"330b73af-fbd0-45a9-bc76-217668a69da9","175":"d6e14383-2242-464f-840f-d900cb5679de","176":"3636350b-7b65-4de9-a375-51793fc46786","177":"85f91455-2b0c-453f-b9cc-710b6300f1bd","178":"f1e95be9-c449-48bf-b604-f83a9a0fcca1","179":"356a3f42-4a23-45e8-b2f6-65af0ecf596b","180":"3851fbab-cdbc-4697-a2a1-a825fb5aa97b","181":"738c8b1c-9bcf-4016-bb37-3161f52452db","182":"063a5ee2-6351-4d73-b3f0-a94f0cb1f142","183":"40e4d3fd-b064-46d9-a7e5-29ccfd898d12","184":"6d7afa8c-a9f1-4ac2-9e38-451949a35f49","185":"a79a6e77-94da-496b-be48-60e82603c8f7","186":"3ee957fc-96da-4293-aae1-27c43219e9ec","187":"0dc73ab2-0a0c-40e1-a225-5d16d5d2bd85","188":"388c28d3-6917-4d1d-a3ce-768c225ce41b","189":"c3608c33-b465-40d6-88af-e7daf31d3317","190":"db5b9415-71cd-4d23-a513-f5ed2f48a300","191":"3d998731-7d63-47b3-85af-695a04e33b5f","192":"4e47ce75-fd55-41d8-8c9f-a11914516621","193":"63584635-e5af-478c-93e9-eeff87693400","194":"da1ee6d5-1047-4d8d-b3dc-aee788b680bb","195":"b96e1b93-8ddd-4228-9dc2-374ddbc4b4f0","196":"8eac6495-4940-403f-9630-3d60716c0b31","197":"7b27dcbd-b4c1-43b4-bcf7-e65f2a426d32","198":"b97341fd-ce48-41d7-b44f-2f9bdb72aa39","199":"7075ab72-b28b-4e6d-9b13-a998234cce1e","200":"10a00462-77bf-44f8-9977-6494f649a359","201":"d0b4959d-f636-48f6-a95a-6f0d7af215c0","202":"03378bf4-4ab7-4a7a-84cb-1be958dd1336","203":"c1a1fe9a-99c7-4ed9-a5aa-0df956bf9dcf","204":"b652ffbe-569b-4d58-856b-feedfc9b4f25","205":"0b3de08c-f303-4b7d-8a3e-04b9e4dae0c8","206":"9fd7839c-a386-4501-82de-94ddb1946ecd","207":"95cbdc3d-1bcd-437d-a523-4e8f8a9bf2b9","208":"d52d65d5-abe9-41e6-bd7b-457196e588fb","209":"5c3bfac1-6794-499c-96c6-2e1d9a54e67c","210":"618e2354-94ce-4b8b-80a8-77d7255bbe80","211":"2438872c-f01f-4b10-b934-e5036dfd7b36","212":"4fb7bc6c-e84d-4d4a-9096-bc7e84126f75","213":"5d1e6082-70b1-4e18-9089-fc2958e14b90","214":"ecca9c1c-7842-49e6-b750-78170e159918","215":"bd25929b-ac04-4625-bff5-39eff1c16f80","216":"8d2a6c8b-9d73-4d31-af1d-84f8aeb759d0","217":"7ef65dbd-2bc4-4471-8cb7-6d8bb9abc3a3","218":"a6331855-c72d-490d-9080-8ee1e6ace562","219":"62a474fe-3b72-4a4b-828f-e179da7c0be2","220":"6005f53d-063c-48db-9eb5-381804dd7dae","221":"b7ca19f1-ad41-4664-9048-acc6734a8029","222":"f47496a5-baf0-4423-82b9-01693e6621aa","223":"60b5e96f-a85a-4ae1-b4ee-4121d099e6cc","224":"4ef15520-254c-4919-af75-f2b735b460ac","225":"a6fe5ea8-2ce5-4cf0-97e0-a8270526c019","226":"25384b49-6a2a-419b-a7ac-4311c53f12b7","227":"38999075-bd1e-4ca7-b6b7-5ff8362bac75","228":"8ba4a82e-d5e9-4a34-9258-856145cf4a1c","229":"15b73d6b-9efc-4a86-946e-f887ce687ebd","230":"8d89faba-df12-4fe3-a4b0-2143e8e074fd","231":"4b3623c9-9629-460e-8091-b40a2268a7f6","232":"db01c997-2b34-4a5f-8cf3-29c84360a364","233":"c3be96cd-4fbd-4c53-b7b5-cd0c4c555eb6","234":"9b7da567-3cb3-41ed-9948-42cdf05629ca","235":"52d5f79a-8b61-4ded-a08a-26be48333661","236":"4349b1d4-ab12-46d6-b345-3701363db9fb","237":"c915a4dc-3b02-4fe2-9300-c4c848470888","238":"99922763-4a56-4870-b319-2db4e9aa0ec4","239":"df60b12a-a657-4b2c-b5c6-e446a8964a4c","240":"e1d361d4-5c43-4550-966a-34b80c549635","241":"8d12efc5-dd28-40f8-824b-0bb310d71534","242":"e6142d16-5aae-4386-8d60-6abb9646930a","243":"abae7953-09fa-4260-84e4-9d5d9ebe98ff","244":"b4835f1c-a5ad-4f76-858b-d856655b308d","245":"ee0d8566-8edb-4a87-92e7-ff9e5f4ec334"}]